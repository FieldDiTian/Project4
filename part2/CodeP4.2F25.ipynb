{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0, 10.0, 200.0, 24.3], [1.0, 10.0, 200.0, 24.3], [2.0, 10.0, 200.0, 24.3], [0.0, 10.0, 200.0, 51.8], [1.0, 10.0, 200.0, 51.8], [2.0, 10.0, 200.0, 51.8], [0.0, 10.0, 200.0, 96.2], [1.0, 10.0, 200.0, 96.2], [2.0, 10.0, 200.0, 96.1], [0.0, 10.0, 200.0, 170.1], [1.0, 10.0, 200.0, 170.1], [2.0, 10.0, 200.0, 170.1], [0.0, 10.0, 500.0, 7.0], [1.0, 10.0, 500.0, 7.0], [2.0, 10.0, 500.0, 7.0], [0.0, 10.0, 500.0, 21.2], [1.0, 10.0, 500.0, 21.2], [2.0, 10.0, 500.0, 21.2], [0.0, 10.0, 500.0, 43.2], [1.0, 10.0, 500.0, 43.2], [1.0, 10.0, 700.0, 4.9], [2.0, 10.0, 700.0, 4.9], [0.0, 10.0, 700.0, 14.3], [1.0, 10.0, 700.0, 14.3], [2.0, 10.0, 700.0, 14.3], [2.0, 10.0, 500.0, 43.2], [0.0, 10.0, 500.0, 79.1], [1.0, 10.0, 500.0, 79.1], [2.0, 10.0, 500.0, 79.1], [0.0, 10.0, 700.0, 4.8], [0.0, 10.0, 700.0, 29.7], [1.0, 10.0, 700.0, 29.7], [2.0, 10.0, 700.0, 29.7], [0.0, 10.0, 700.0, 55.3], [1.0, 10.0, 700.0, 55.3], [2.0, 10.0, 700.0, 55.3], [0.0, 10.0, 1000.0, 3.92], [1.0, 10.0, 1000.0, 3.92], [2.0, 10.0, 1000.0, 3.92], [0.0, 10.0, 1000.0, 11.7], [1.0, 10.0, 1000.0, 11.7], [2.0, 10.0, 1000.0, 11.7], [0.0, 10.0, 1000.0, 25.2], [1.0, 10.0, 1000.0, 25.2], [2.0, 10.0, 1000.0, 25.2], [0.0, 10.0, 1000.0, 41.6], [1.0, 10.0, 1000.0, 41.6], [2.0, 10.0, 1000.0, 41.6]]\n",
      "[[   0.     10.    200.     24.3 ]\n",
      " [   1.     10.    200.     24.3 ]\n",
      " [   2.     10.    200.     24.3 ]\n",
      " [   0.     10.    200.     51.8 ]\n",
      " [   1.     10.    200.     51.8 ]\n",
      " [   2.     10.    200.     51.8 ]\n",
      " [   0.     10.    200.     96.2 ]\n",
      " [   1.     10.    200.     96.2 ]\n",
      " [   2.     10.    200.     96.1 ]\n",
      " [   0.     10.    200.    170.1 ]\n",
      " [   1.     10.    200.    170.1 ]\n",
      " [   2.     10.    200.    170.1 ]\n",
      " [   0.     10.    500.      7.  ]\n",
      " [   1.     10.    500.      7.  ]\n",
      " [   2.     10.    500.      7.  ]\n",
      " [   0.     10.    500.     21.2 ]\n",
      " [   1.     10.    500.     21.2 ]\n",
      " [   2.     10.    500.     21.2 ]\n",
      " [   0.     10.    500.     43.2 ]\n",
      " [   1.     10.    500.     43.2 ]\n",
      " [   1.     10.    700.      4.9 ]\n",
      " [   2.     10.    700.      4.9 ]\n",
      " [   0.     10.    700.     14.3 ]\n",
      " [   1.     10.    700.     14.3 ]\n",
      " [   2.     10.    700.     14.3 ]\n",
      " [   2.     10.    500.     43.2 ]\n",
      " [   0.     10.    500.     79.1 ]\n",
      " [   1.     10.    500.     79.1 ]\n",
      " [   2.     10.    500.     79.1 ]\n",
      " [   0.     10.    700.      4.8 ]\n",
      " [   0.     10.    700.     29.7 ]\n",
      " [   1.     10.    700.     29.7 ]\n",
      " [   2.     10.    700.     29.7 ]\n",
      " [   0.     10.    700.     55.3 ]\n",
      " [   1.     10.    700.     55.3 ]\n",
      " [   2.     10.    700.     55.3 ]\n",
      " [   0.     10.   1000.      3.92]\n",
      " [   1.     10.   1000.      3.92]\n",
      " [   2.     10.   1000.      3.92]\n",
      " [   0.     10.   1000.     11.7 ]\n",
      " [   1.     10.   1000.     11.7 ]\n",
      " [   2.     10.   1000.     11.7 ]\n",
      " [   0.     10.   1000.     25.2 ]\n",
      " [   1.     10.   1000.     25.2 ]\n",
      " [   2.     10.   1000.     25.2 ]\n",
      " [   0.     10.   1000.     41.6 ]\n",
      " [   1.     10.   1000.     41.6 ]\n",
      " [   2.     10.   1000.     41.6 ]]\n",
      "[[46.0, 87.3], [27.9, 64.2], [27.9, 32.1], [46.0, 40.9], [92.1, 163.9], [59.5, 68.5], [46.0, 22.0], [92.1, 88.2], [110.6, 127.2], [46.0, 12.4], [92.1, 49.9], [184.2, 199.6], [48.4, 335.3], [20.8, 124.3], [20.8, 62.1], [48.4, 110.7], [96.8, 442.9], [63.1, 188.2], [48.4, 54.3], [96.9, 217.3], [128.7, 383.6], [48.4, 29.6], [96.8, 118.7], [193.7, 474.8], [49.3, 496.1], [20.4, 171.2], [20.4, 85.6], [49.3, 169.9], [98.6, 679.9], [59.7, 249.8], [49.3, 81.8], [98.6, 327.4], [124.1, 518.9], [49.305, 43.9], [98.6, 175.8], [197.2, 703.3], [50.8, 658.9], [23.1, 272.9], [23.1, 136.4], [50.8, 220.7], [101.6, 883.1], [69.0, 407.2], [50.8, 102.5], [101.6, 410.0], [148.6, 877.2], [50.8, 62.0], [101.6, 248.3], [203.2, 993.5]]\n",
      "[[ 46.     87.3  ]\n",
      " [ 27.9    64.2  ]\n",
      " [ 27.9    32.1  ]\n",
      " [ 46.     40.9  ]\n",
      " [ 92.1   163.9  ]\n",
      " [ 59.5    68.5  ]\n",
      " [ 46.     22.   ]\n",
      " [ 92.1    88.2  ]\n",
      " [110.6   127.2  ]\n",
      " [ 46.     12.4  ]\n",
      " [ 92.1    49.9  ]\n",
      " [184.2   199.6  ]\n",
      " [ 48.4   335.3  ]\n",
      " [ 20.8   124.3  ]\n",
      " [ 20.8    62.1  ]\n",
      " [ 48.4   110.7  ]\n",
      " [ 96.8   442.9  ]\n",
      " [ 63.1   188.2  ]\n",
      " [ 48.4    54.3  ]\n",
      " [ 96.9   217.3  ]\n",
      " [128.7   383.6  ]\n",
      " [ 48.4    29.6  ]\n",
      " [ 96.8   118.7  ]\n",
      " [193.7   474.8  ]\n",
      " [ 49.3   496.1  ]\n",
      " [ 20.4   171.2  ]\n",
      " [ 20.4    85.6  ]\n",
      " [ 49.3   169.9  ]\n",
      " [ 98.6   679.9  ]\n",
      " [ 59.7   249.8  ]\n",
      " [ 49.3    81.8  ]\n",
      " [ 98.6   327.4  ]\n",
      " [124.1   518.9  ]\n",
      " [ 49.305  43.9  ]\n",
      " [ 98.6   175.8  ]\n",
      " [197.2   703.3  ]\n",
      " [ 50.8   658.9  ]\n",
      " [ 23.1   272.9  ]\n",
      " [ 23.1   136.4  ]\n",
      " [ 50.8   220.7  ]\n",
      " [101.6   883.1  ]\n",
      " [ 69.    407.2  ]\n",
      " [ 50.8   102.5  ]\n",
      " [101.6   410.   ]\n",
      " [148.6   877.2  ]\n",
      " [ 50.8    62.   ]\n",
      " [101.6   248.3  ]\n",
      " [203.2   993.5  ]]\n",
      "Training samples: 32, Validation samples: 16\n",
      "Training set shape: (32, 4)\n",
      "Validation set shape: (16, 4)\n"
     ]
    }
   ],
   "source": [
    "'''>>>>> start CodeP4.2F25\n",
    "    V.P. Carey ME249, Fall 2025 \n",
    "\n",
    "Intro to Neural Network Modeling \n",
    "Keras model for PV power system'''\n",
    "\n",
    "#import useful packages\n",
    "import keras\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "import keras.backend as kb\n",
    "import tensorflow as tf\n",
    "#the following 2 lines are only needed for Mac OS machines\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "# Import normalized data from CodeP4.3F25.ipynb\n",
    "# Run CodeP4.3F25.ipynb to load and normalize data\n",
    "%run CodeP4.3F25.ipynb\n",
    "\n",
    "# Data loaded from CodeP4.3F25.ipynb:\n",
    "# xarray, yarray (training set - normalized)\n",
    "# xarray_val, yarray_val (validation set - normalized)\n",
    "# Tamed, IDmed, RLmed, VLmed, Wdmed (median values for denormalization)\n",
    "\n",
    "print(f'Training set shape: {xarray.shape}')\n",
    "print(f'Validation set shape: {xarray_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">216</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">350</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_37 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m40\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_38 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │           \u001b[38;5;34m216\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_39 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)             │           \u001b[38;5;34m350\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_40 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m30\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">636</span> (2.48 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m636\u001b[0m (2.48 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">636</span> (2.48 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m636\u001b[0m (2.48 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# (c) Define neural network model\n",
    "\n",
    "# Network architecture based on Task 4.1.1 experience:\n",
    "# - 3 hidden layers (optimal for small datasets)\n",
    "# - 8-14-8 structure (moderate complexity to avoid overfitting)\n",
    "# - ELU activation for hidden layers\n",
    "# - Linear activation for output layer (regression task)\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "# Initialize weights with values between -0.2 and 0.5\n",
    "initializer = keras.initializers.RandomUniform(minval=-0.2, maxval=0.5)\n",
    "\n",
    "# Input: 4 features [M, T_air_norm, I_D_norm, R_L_norm]\n",
    "# Output: 2 parameters [V_L_norm, W_dot_norm]\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(8, activation='elu', input_shape=[4], kernel_initializer=initializer),\n",
    "    keras.layers.Dense(24, activation='elu', kernel_initializer=initializer),\n",
    "    keras.layers.Dense(14, activation='elu', kernel_initializer=initializer),\n",
    "    keras.layers.Dense(2, kernel_initializer=initializer)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We're using RMSprop as our optimizer here. RMSprop stands for Root Mean Square Propagation. \n",
    "#It's one of the most popular gradient descent optimization algorithms for deep learning networks. \n",
    "#RMSprop is an optimizer that's reliable and fast.\n",
    "#We're compiling the mode using the model.compile function. The loss function used here \n",
    "#is mean absolute error. After the compilation of the model, we'll use the fit method with ~500 epochs.\n",
    "#Number of epochs can be varied.\n",
    "\n",
    "#from tf.keras import optimizers\n",
    "rms = keras.optimizers.RMSprop(0.0006)\n",
    "model.compile(loss='mean_absolute_error', optimizer=rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 4.4909\n",
      "Epoch 1: val_loss improved from None to 4.22466, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - loss: 4.4909 - val_loss: 4.2247\n",
      "Epoch 2/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.1443\n",
      "Epoch 2: val_loss improved from 4.22466 to 3.97065, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 4.1443 - val_loss: 3.9706\n",
      "Epoch 3/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.9062\n",
      "Epoch 3: val_loss improved from 3.97065 to 3.76597, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 3.9062 - val_loss: 3.7660\n",
      "Epoch 4/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.7144\n",
      "Epoch 4: val_loss improved from 3.76597 to 3.58994, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 3.7144 - val_loss: 3.5899\n",
      "Epoch 5/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.5495\n",
      "Epoch 5: val_loss improved from 3.58994 to 3.43827, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 3.5495 - val_loss: 3.4383\n",
      "Epoch 6/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.4025\n",
      "Epoch 6: val_loss improved from 3.43827 to 3.30151, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 3.4025 - val_loss: 3.3015\n",
      "Epoch 7/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.2685\n",
      "Epoch 7: val_loss improved from 3.30151 to 3.17835, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 3.2685 - val_loss: 3.1784\n",
      "Epoch 8/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.1445\n",
      "Epoch 8: val_loss improved from 3.17835 to 3.06566, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 3.1445 - val_loss: 3.0657\n",
      "Epoch 9/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.0283\n",
      "Epoch 9: val_loss improved from 3.06566 to 2.95923, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 3.0283 - val_loss: 2.9592\n",
      "Epoch 10/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.9195\n",
      "Epoch 10: val_loss improved from 2.95923 to 2.86130, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 2.9195 - val_loss: 2.8613\n",
      "Epoch 11/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.8219\n",
      "Epoch 11: val_loss improved from 2.86130 to 2.76726, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 2.8219 - val_loss: 2.7673\n",
      "Epoch 12/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.7282\n",
      "Epoch 12: val_loss improved from 2.76726 to 2.67662, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 2.7282 - val_loss: 2.6766\n",
      "Epoch 13/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.6380\n",
      "Epoch 13: val_loss improved from 2.67662 to 2.58900, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 2.6380 - val_loss: 2.5890\n",
      "Epoch 14/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.5507\n",
      "Epoch 14: val_loss improved from 2.58900 to 2.50408, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 2.5507 - val_loss: 2.5041\n",
      "Epoch 15/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.4662\n",
      "Epoch 15: val_loss improved from 2.50408 to 2.42160, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 2.4662 - val_loss: 2.4216\n",
      "Epoch 16/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.3841\n",
      "Epoch 16: val_loss improved from 2.42160 to 2.34381, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 2.3841 - val_loss: 2.3438\n",
      "Epoch 17/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.3042\n",
      "Epoch 17: val_loss improved from 2.34381 to 2.26837, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 2.3042 - val_loss: 2.2684\n",
      "Epoch 18/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.2264\n",
      "Epoch 18: val_loss improved from 2.26837 to 2.19473, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 2.2264 - val_loss: 2.1947\n",
      "Epoch 19/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.1504\n",
      "Epoch 19: val_loss improved from 2.19473 to 2.12484, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.1504 - val_loss: 2.1248\n",
      "Epoch 20/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.0762\n",
      "Epoch 20: val_loss improved from 2.12484 to 2.06083, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.0762 - val_loss: 2.0608\n",
      "Epoch 21/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.0036\n",
      "Epoch 21: val_loss improved from 2.06083 to 2.00239, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.0036 - val_loss: 2.0024\n",
      "Epoch 22/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.9326\n",
      "Epoch 22: val_loss improved from 2.00239 to 1.95294, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.9326 - val_loss: 1.9529\n",
      "Epoch 23/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.8630\n",
      "Epoch 23: val_loss improved from 1.95294 to 1.90661, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.8630 - val_loss: 1.9066\n",
      "Epoch 24/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7951\n",
      "Epoch 24: val_loss improved from 1.90661 to 1.86365, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.7951 - val_loss: 1.8636\n",
      "Epoch 25/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7345\n",
      "Epoch 25: val_loss improved from 1.86365 to 1.82229, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.7345 - val_loss: 1.8223\n",
      "Epoch 26/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6769\n",
      "Epoch 26: val_loss improved from 1.82229 to 1.78135, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.6769 - val_loss: 1.7814\n",
      "Epoch 27/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6200\n",
      "Epoch 27: val_loss improved from 1.78135 to 1.74084, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.6200 - val_loss: 1.7408\n",
      "Epoch 28/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5637\n",
      "Epoch 28: val_loss improved from 1.74084 to 1.70077, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.5637 - val_loss: 1.7008\n",
      "Epoch 29/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5082\n",
      "Epoch 29: val_loss improved from 1.70077 to 1.66114, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.5082 - val_loss: 1.6611\n",
      "Epoch 30/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4534\n",
      "Epoch 30: val_loss improved from 1.66114 to 1.62195, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.4534 - val_loss: 1.6219\n",
      "Epoch 31/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3993\n",
      "Epoch 31: val_loss improved from 1.62195 to 1.58320, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.3993 - val_loss: 1.5832\n",
      "Epoch 32/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3465\n",
      "Epoch 32: val_loss improved from 1.58320 to 1.54532, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.3465 - val_loss: 1.5453\n",
      "Epoch 33/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2968\n",
      "Epoch 33: val_loss improved from 1.54532 to 1.50847, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.2968 - val_loss: 1.5085\n",
      "Epoch 34/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2488\n",
      "Epoch 34: val_loss improved from 1.50847 to 1.47317, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.2488 - val_loss: 1.4732\n",
      "Epoch 35/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2033\n",
      "Epoch 35: val_loss improved from 1.47317 to 1.44291, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 1.2033 - val_loss: 1.4429\n",
      "Epoch 36/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1638\n",
      "Epoch 36: val_loss improved from 1.44291 to 1.41995, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 1.1638 - val_loss: 1.4200\n",
      "Epoch 37/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1311\n",
      "Epoch 37: val_loss improved from 1.41995 to 1.39832, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.1311 - val_loss: 1.3983\n",
      "Epoch 38/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1024\n",
      "Epoch 38: val_loss improved from 1.39832 to 1.38021, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.1024 - val_loss: 1.3802\n",
      "Epoch 39/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0754\n",
      "Epoch 39: val_loss improved from 1.38021 to 1.36481, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.0754 - val_loss: 1.3648\n",
      "Epoch 40/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0486\n",
      "Epoch 40: val_loss improved from 1.36481 to 1.35003, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.0486 - val_loss: 1.3500\n",
      "Epoch 41/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0229\n",
      "Epoch 41: val_loss improved from 1.35003 to 1.33514, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.0229 - val_loss: 1.3351\n",
      "Epoch 42/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9976\n",
      "Epoch 42: val_loss improved from 1.33514 to 1.32061, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.9976 - val_loss: 1.3206\n",
      "Epoch 43/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9732\n",
      "Epoch 43: val_loss improved from 1.32061 to 1.30925, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.9732 - val_loss: 1.3092\n",
      "Epoch 44/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9497\n",
      "Epoch 44: val_loss improved from 1.30925 to 1.29910, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.9497 - val_loss: 1.2991\n",
      "Epoch 45/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.9283\n",
      "Epoch 45: val_loss improved from 1.29910 to 1.28926, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.9283 - val_loss: 1.2893\n",
      "Epoch 46/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9083\n",
      "Epoch 46: val_loss improved from 1.28926 to 1.28017, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.9083 - val_loss: 1.2802\n",
      "Epoch 47/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8892\n",
      "Epoch 47: val_loss improved from 1.28017 to 1.27262, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.8892 - val_loss: 1.2726\n",
      "Epoch 48/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8757\n",
      "Epoch 48: val_loss improved from 1.27262 to 1.26492, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.8757 - val_loss: 1.2649\n",
      "Epoch 49/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8620\n",
      "Epoch 49: val_loss improved from 1.26492 to 1.25708, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.8620 - val_loss: 1.2571\n",
      "Epoch 50/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8483\n",
      "Epoch 50: val_loss improved from 1.25708 to 1.24969, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.8483 - val_loss: 1.2497\n",
      "Epoch 51/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.8349\n",
      "Epoch 51: val_loss improved from 1.24969 to 1.24216, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.8349 - val_loss: 1.2422\n",
      "Epoch 52/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8213\n",
      "Epoch 52: val_loss improved from 1.24216 to 1.23471, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.8213 - val_loss: 1.2347\n",
      "Epoch 53/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8089\n",
      "Epoch 53: val_loss improved from 1.23471 to 1.22863, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.8089 - val_loss: 1.2286\n",
      "Epoch 54/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.7975\n",
      "Epoch 54: val_loss improved from 1.22863 to 1.22243, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.7975 - val_loss: 1.2224\n",
      "Epoch 55/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.7859\n",
      "Epoch 55: val_loss improved from 1.22243 to 1.21612, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.7859 - val_loss: 1.2161\n",
      "Epoch 56/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.7742\n",
      "Epoch 56: val_loss improved from 1.21612 to 1.21015, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.7742 - val_loss: 1.2102\n",
      "Epoch 57/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.7624\n",
      "Epoch 57: val_loss improved from 1.21015 to 1.20421, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.7624 - val_loss: 1.2042\n",
      "Epoch 58/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.7511\n",
      "Epoch 58: val_loss improved from 1.20421 to 1.19910, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.7511 - val_loss: 1.1991\n",
      "Epoch 59/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.7414\n",
      "Epoch 59: val_loss improved from 1.19910 to 1.19427, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.7414 - val_loss: 1.1943\n",
      "Epoch 60/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7317\n",
      "Epoch 60: val_loss improved from 1.19427 to 1.18936, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.7317 - val_loss: 1.1894\n",
      "Epoch 61/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.7220\n",
      "Epoch 61: val_loss improved from 1.18936 to 1.18437, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.7220 - val_loss: 1.1844\n",
      "Epoch 62/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.7121\n",
      "Epoch 62: val_loss improved from 1.18437 to 1.17932, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.7121 - val_loss: 1.1793\n",
      "Epoch 63/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.7021\n",
      "Epoch 63: val_loss improved from 1.17932 to 1.17420, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.7021 - val_loss: 1.1742\n",
      "Epoch 64/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6920\n",
      "Epoch 64: val_loss improved from 1.17420 to 1.16903, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.6920 - val_loss: 1.1690\n",
      "Epoch 65/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6818\n",
      "Epoch 65: val_loss improved from 1.16903 to 1.16380, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.6818 - val_loss: 1.1638\n",
      "Epoch 66/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6719\n",
      "Epoch 66: val_loss improved from 1.16380 to 1.15907, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.6719 - val_loss: 1.1591\n",
      "Epoch 67/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6630\n",
      "Epoch 67: val_loss improved from 1.15907 to 1.15487, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.6630 - val_loss: 1.1549\n",
      "Epoch 68/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6539\n",
      "Epoch 68: val_loss improved from 1.15487 to 1.15213, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.6539 - val_loss: 1.1521\n",
      "Epoch 69/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6452\n",
      "Epoch 69: val_loss improved from 1.15213 to 1.15028, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.6452 - val_loss: 1.1503\n",
      "Epoch 70/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6376\n",
      "Epoch 70: val_loss improved from 1.15028 to 1.14843, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.6376 - val_loss: 1.1484\n",
      "Epoch 71/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6299\n",
      "Epoch 71: val_loss improved from 1.14843 to 1.14658, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.6299 - val_loss: 1.1466\n",
      "Epoch 72/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6222\n",
      "Epoch 72: val_loss improved from 1.14658 to 1.14508, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.6222 - val_loss: 1.1451\n",
      "Epoch 73/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6147\n",
      "Epoch 73: val_loss improved from 1.14508 to 1.14403, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.6147 - val_loss: 1.1440\n",
      "Epoch 74/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6087\n",
      "Epoch 74: val_loss improved from 1.14403 to 1.14167, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.6087 - val_loss: 1.1417\n",
      "Epoch 75/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6030\n",
      "Epoch 75: val_loss improved from 1.14167 to 1.14113, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.6030 - val_loss: 1.1411\n",
      "Epoch 76/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5983\n",
      "Epoch 76: val_loss improved from 1.14113 to 1.14061, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.5983 - val_loss: 1.1406\n",
      "Epoch 77/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5936\n",
      "Epoch 77: val_loss improved from 1.14061 to 1.13895, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.5936 - val_loss: 1.1389\n",
      "Epoch 78/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5896\n",
      "Epoch 78: val_loss improved from 1.13895 to 1.13881, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.5896 - val_loss: 1.1388\n",
      "Epoch 79/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5854\n",
      "Epoch 79: val_loss improved from 1.13881 to 1.13711, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.5854 - val_loss: 1.1371\n",
      "Epoch 80/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5812\n",
      "Epoch 80: val_loss did not improve from 1.13711\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5812 - val_loss: 1.1375\n",
      "Epoch 81/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5772\n",
      "Epoch 81: val_loss improved from 1.13711 to 1.13576, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.5772 - val_loss: 1.1358\n",
      "Epoch 82/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5729\n",
      "Epoch 82: val_loss improved from 1.13576 to 1.13452, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.5729 - val_loss: 1.1345\n",
      "Epoch 83/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5688\n",
      "Epoch 83: val_loss did not improve from 1.13452\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5688 - val_loss: 1.1351\n",
      "Epoch 84/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5648\n",
      "Epoch 84: val_loss improved from 1.13452 to 1.13238, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.5648 - val_loss: 1.1324\n",
      "Epoch 85/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5606\n",
      "Epoch 85: val_loss improved from 1.13238 to 1.13219, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.5606 - val_loss: 1.1322\n",
      "Epoch 86/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5569\n",
      "Epoch 86: val_loss did not improve from 1.13219\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5569 - val_loss: 1.1329\n",
      "Epoch 87/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5541\n",
      "Epoch 87: val_loss improved from 1.13219 to 1.13085, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.5541 - val_loss: 1.1309\n",
      "Epoch 88/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5512\n",
      "Epoch 88: val_loss did not improve from 1.13085\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5512 - val_loss: 1.1311\n",
      "Epoch 89/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5486\n",
      "Epoch 89: val_loss improved from 1.13085 to 1.13021, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.5486 - val_loss: 1.1302\n",
      "Epoch 90/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5466\n",
      "Epoch 90: val_loss did not improve from 1.13021\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5466 - val_loss: 1.1319\n",
      "Epoch 91/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5449\n",
      "Epoch 91: val_loss did not improve from 1.13021\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.5449 - val_loss: 1.1311\n",
      "Epoch 92/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5432\n",
      "Epoch 92: val_loss did not improve from 1.13021\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5432 - val_loss: 1.1330\n",
      "Epoch 93/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5417\n",
      "Epoch 93: val_loss did not improve from 1.13021\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5417 - val_loss: 1.1321\n",
      "Epoch 94/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5398\n",
      "Epoch 94: val_loss did not improve from 1.13021\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5398 - val_loss: 1.1313\n",
      "Epoch 95/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5382\n",
      "Epoch 95: val_loss did not improve from 1.13021\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5382 - val_loss: 1.1334\n",
      "Epoch 96/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5363\n",
      "Epoch 96: val_loss improved from 1.13021 to 1.12928, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.5363 - val_loss: 1.1293\n",
      "Epoch 97/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5353\n",
      "Epoch 97: val_loss did not improve from 1.12928\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.5353 - val_loss: 1.1315\n",
      "Epoch 98/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5328\n",
      "Epoch 98: val_loss did not improve from 1.12928\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.5328 - val_loss: 1.1339\n",
      "Epoch 99/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5327\n",
      "Epoch 99: val_loss improved from 1.12928 to 1.12727, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.5327 - val_loss: 1.1273\n",
      "Epoch 100/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5317\n",
      "Epoch 100: val_loss did not improve from 1.12727\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5317 - val_loss: 1.1315\n",
      "Epoch 101/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5297\n",
      "Epoch 101: val_loss did not improve from 1.12727\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5297 - val_loss: 1.1327\n",
      "Epoch 102/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5283\n",
      "Epoch 102: val_loss did not improve from 1.12727\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5283 - val_loss: 1.1280\n",
      "Epoch 103/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5282\n",
      "Epoch 103: val_loss did not improve from 1.12727\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5282 - val_loss: 1.1326\n",
      "Epoch 104/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5267\n",
      "Epoch 104: val_loss improved from 1.12727 to 1.12533, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.5267 - val_loss: 1.1253\n",
      "Epoch 105/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5278\n",
      "Epoch 105: val_loss did not improve from 1.12533\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.5278 - val_loss: 1.1304\n",
      "Epoch 106/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5250\n",
      "Epoch 106: val_loss did not improve from 1.12533\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5250 - val_loss: 1.1296\n",
      "Epoch 107/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5250\n",
      "Epoch 107: val_loss did not improve from 1.12533\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5250 - val_loss: 1.1356\n",
      "Epoch 108/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5262\n",
      "Epoch 108: val_loss improved from 1.12533 to 1.12233, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.5262 - val_loss: 1.1223\n",
      "Epoch 109/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5271\n",
      "Epoch 109: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5271 - val_loss: 1.1293\n",
      "Epoch 110/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5240\n",
      "Epoch 110: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5240 - val_loss: 1.1349\n",
      "Epoch 111/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5255\n",
      "Epoch 111: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.5255 - val_loss: 1.1261\n",
      "Epoch 112/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5252\n",
      "Epoch 112: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.5252 - val_loss: 1.1315\n",
      "Epoch 113/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5234\n",
      "Epoch 113: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.5234 - val_loss: 1.1317\n",
      "Epoch 114/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5231\n",
      "Epoch 114: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.5231 - val_loss: 1.1319\n",
      "Epoch 115/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5229\n",
      "Epoch 115: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.5229 - val_loss: 1.1340\n",
      "Epoch 116/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5228\n",
      "Epoch 116: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.5228 - val_loss: 1.1305\n",
      "Epoch 117/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5233\n",
      "Epoch 117: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5233 - val_loss: 1.1372\n",
      "Epoch 118/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5233\n",
      "Epoch 118: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.5233 - val_loss: 1.1270\n",
      "Epoch 119/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5244\n",
      "Epoch 119: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5244 - val_loss: 1.1334\n",
      "Epoch 120/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5219\n",
      "Epoch 120: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.5219 - val_loss: 1.1401\n",
      "Epoch 121/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5235\n",
      "Epoch 121: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.5235 - val_loss: 1.1272\n",
      "Epoch 122/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5241\n",
      "Epoch 122: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5241 - val_loss: 1.1332\n",
      "Epoch 123/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5218\n",
      "Epoch 123: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.5218 - val_loss: 1.1395\n",
      "Epoch 124/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5211\n",
      "Epoch 124: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.5211 - val_loss: 1.1363\n",
      "Epoch 125/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5208\n",
      "Epoch 125: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.5208 - val_loss: 1.1388\n",
      "Epoch 126/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5203\n",
      "Epoch 126: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.5203 - val_loss: 1.1393\n",
      "Epoch 127/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5200\n",
      "Epoch 127: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.5200 - val_loss: 1.1420\n",
      "Epoch 128/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5199\n",
      "Epoch 128: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.5199 - val_loss: 1.1383\n",
      "Epoch 129/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5198\n",
      "Epoch 129: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.5198 - val_loss: 1.1463\n",
      "Epoch 130/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5211\n",
      "Epoch 130: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.5211 - val_loss: 1.1318\n",
      "Epoch 131/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5223\n",
      "Epoch 131: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.5223 - val_loss: 1.1436\n",
      "Epoch 132/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5193\n",
      "Epoch 132: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.5193 - val_loss: 1.1508\n",
      "Epoch 133/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5197\n",
      "Epoch 133: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.5197 - val_loss: 1.1293\n",
      "Epoch 134/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5228\n",
      "Epoch 134: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.5228 - val_loss: 1.1381\n",
      "Epoch 135/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5193\n",
      "Epoch 135: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.5193 - val_loss: 1.1475\n",
      "Epoch 136/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.5182\n",
      "Epoch 136: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.5182 - val_loss: 1.1387\n",
      "Epoch 137/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5199\n",
      "Epoch 137: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.5199 - val_loss: 1.1482\n",
      "Epoch 138/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5179\n",
      "Epoch 138: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.5179 - val_loss: 1.1446\n",
      "Epoch 139/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5176\n",
      "Epoch 139: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.5176 - val_loss: 1.1507\n",
      "Epoch 140/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5176\n",
      "Epoch 140: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.5176 - val_loss: 1.1419\n",
      "Epoch 141/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5181\n",
      "Epoch 141: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.5181 - val_loss: 1.1523\n",
      "Epoch 142/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5181\n",
      "Epoch 142: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.5181 - val_loss: 1.1351\n",
      "Epoch 143/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5212\n",
      "Epoch 143: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.5212 - val_loss: 1.1443\n",
      "Epoch 144/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5177\n",
      "Epoch 144: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.5177 - val_loss: 1.1539\n",
      "Epoch 145/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5178\n",
      "Epoch 145: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.5178 - val_loss: 1.1439\n",
      "Epoch 146/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5176\n",
      "Epoch 146: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5176 - val_loss: 1.1495\n",
      "Epoch 147/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5163\n",
      "Epoch 147: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5163 - val_loss: 1.1538\n",
      "Epoch 148/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5171\n",
      "Epoch 148: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5171 - val_loss: 1.1439\n",
      "Epoch 149/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5176\n",
      "Epoch 149: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5176 - val_loss: 1.1496\n",
      "Epoch 150/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5163\n",
      "Epoch 150: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5163 - val_loss: 1.1539\n",
      "Epoch 151/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5165\n",
      "Epoch 151: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5165 - val_loss: 1.1371\n",
      "Epoch 152/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5200\n",
      "Epoch 152: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.5200 - val_loss: 1.1468\n",
      "Epoch 153/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5167\n",
      "Epoch 153: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.5167 - val_loss: 1.1524\n",
      "Epoch 154/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5156\n",
      "Epoch 154: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.5156 - val_loss: 1.1510\n",
      "Epoch 155/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5154\n",
      "Epoch 155: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.5154 - val_loss: 1.1512\n",
      "Epoch 156/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5156\n",
      "Epoch 156: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.5156 - val_loss: 1.1475\n",
      "Epoch 157/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5171\n",
      "Epoch 157: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5171 - val_loss: 1.1437\n",
      "Epoch 158/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5168\n",
      "Epoch 158: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5168 - val_loss: 1.1501\n",
      "Epoch 159/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5154\n",
      "Epoch 159: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5154 - val_loss: 1.1548\n",
      "Epoch 160/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5161\n",
      "Epoch 160: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5161 - val_loss: 1.1439\n",
      "Epoch 161/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5167\n",
      "Epoch 161: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5167 - val_loss: 1.1504\n",
      "Epoch 162/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5152\n",
      "Epoch 162: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5152 - val_loss: 1.1551\n",
      "Epoch 163/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5157\n",
      "Epoch 163: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5157 - val_loss: 1.1360\n",
      "Epoch 164/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5198\n",
      "Epoch 164: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.5198 - val_loss: 1.1467\n",
      "Epoch 165/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5156\n",
      "Epoch 165: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.5156 - val_loss: 1.1576\n",
      "Epoch 166/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5178\n",
      "Epoch 166: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.5178 - val_loss: 1.1364\n",
      "Epoch 167/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5193\n",
      "Epoch 167: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5193 - val_loss: 1.1452\n",
      "Epoch 168/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5159\n",
      "Epoch 168: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5159 - val_loss: 1.1545\n",
      "Epoch 169/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5152\n",
      "Epoch 169: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5152 - val_loss: 1.1448\n",
      "Epoch 170/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5158\n",
      "Epoch 170: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.5158 - val_loss: 1.1542\n",
      "Epoch 171/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5157\n",
      "Epoch 171: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.5157 - val_loss: 1.1409\n",
      "Epoch 172/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5179\n",
      "Epoch 172: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5179 - val_loss: 1.1497\n",
      "Epoch 173/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5150\n",
      "Epoch 173: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5150 - val_loss: 1.1537\n",
      "Epoch 174/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5147\n",
      "Epoch 174: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5147 - val_loss: 1.1439\n",
      "Epoch 175/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5158\n",
      "Epoch 175: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.5158 - val_loss: 1.1533\n",
      "Epoch 176/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5143\n",
      "Epoch 176: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5143 - val_loss: 1.1486\n",
      "Epoch 177/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5144\n",
      "Epoch 177: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5144 - val_loss: 1.1546\n",
      "Epoch 178/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5153\n",
      "Epoch 178: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.5153 - val_loss: 1.1425\n",
      "Epoch 179/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5159\n",
      "Epoch 179: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5159 - val_loss: 1.1522\n",
      "Epoch 180/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5157\n",
      "Epoch 180: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5157 - val_loss: 1.1431\n",
      "Epoch 181/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5167\n",
      "Epoch 181: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.5167 - val_loss: 1.1525\n",
      "Epoch 182/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5142\n",
      "Epoch 182: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5142 - val_loss: 1.1474\n",
      "Epoch 183/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5141\n",
      "Epoch 183: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5141 - val_loss: 1.1576\n",
      "Epoch 184/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5161\n",
      "Epoch 184: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.5161 - val_loss: 1.1343\n",
      "Epoch 185/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5192\n",
      "Epoch 185: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.5192 - val_loss: 1.1415\n",
      "Epoch 186/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5164\n",
      "Epoch 186: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.5164 - val_loss: 1.1493\n",
      "Epoch 187/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5136\n",
      "Epoch 187: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.5136 - val_loss: 1.1482\n",
      "Epoch 188/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5137\n",
      "Epoch 188: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.5137 - val_loss: 1.1556\n",
      "Epoch 189/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5139\n",
      "Epoch 189: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.5139 - val_loss: 1.1464\n",
      "Epoch 190/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5146\n",
      "Epoch 190: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5146 - val_loss: 1.1553\n",
      "Epoch 191/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5136\n",
      "Epoch 191: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5136 - val_loss: 1.1478\n",
      "Epoch 192/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5144\n",
      "Epoch 192: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5144 - val_loss: 1.1570\n",
      "Epoch 193/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5140\n",
      "Epoch 193: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.5140 - val_loss: 1.1479\n",
      "Epoch 194/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5141\n",
      "Epoch 194: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5141 - val_loss: 1.1534\n",
      "Epoch 195/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5132\n",
      "Epoch 195: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5132 - val_loss: 1.1521\n",
      "Epoch 196/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5130\n",
      "Epoch 196: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5130 - val_loss: 1.1507\n",
      "Epoch 197/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5131\n",
      "Epoch 197: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5131 - val_loss: 1.1570\n",
      "Epoch 198/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5142\n",
      "Epoch 198: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5142 - val_loss: 1.1384\n",
      "Epoch 199/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5171\n",
      "Epoch 199: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5171 - val_loss: 1.1476\n",
      "Epoch 200/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5138\n",
      "Epoch 200: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5138 - val_loss: 1.1530\n",
      "Epoch 201/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5129\n",
      "Epoch 201: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5129 - val_loss: 1.1517\n",
      "Epoch 202/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5127\n",
      "Epoch 202: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5127 - val_loss: 1.1503\n",
      "Epoch 203/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5128\n",
      "Epoch 203: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5128 - val_loss: 1.1566\n",
      "Epoch 204/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5135\n",
      "Epoch 204: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5135 - val_loss: 1.1394\n",
      "Epoch 205/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5165\n",
      "Epoch 205: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.5165 - val_loss: 1.1493\n",
      "Epoch 206/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5129\n",
      "Epoch 206: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.5129 - val_loss: 1.1552\n",
      "Epoch 207/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5126\n",
      "Epoch 207: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5126 - val_loss: 1.1444\n",
      "Epoch 208/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5144\n",
      "Epoch 208: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5144 - val_loss: 1.1550\n",
      "Epoch 209/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5129\n",
      "Epoch 209: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5129 - val_loss: 1.1436\n",
      "Epoch 210/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5156\n",
      "Epoch 210: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.5156 - val_loss: 1.1529\n",
      "Epoch 211/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5129\n",
      "Epoch 211: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.5129 - val_loss: 1.1492\n",
      "Epoch 212/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5127\n",
      "Epoch 212: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.5127 - val_loss: 1.1535\n",
      "Epoch 213/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5121\n",
      "Epoch 213: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5121 - val_loss: 1.1500\n",
      "Epoch 214/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5123\n",
      "Epoch 214: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5123 - val_loss: 1.1565\n",
      "Epoch 215/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5127\n",
      "Epoch 215: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.5127 - val_loss: 1.1393\n",
      "Epoch 216/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5162\n",
      "Epoch 216: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5162 - val_loss: 1.1486\n",
      "Epoch 217/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5127\n",
      "Epoch 217: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5127 - val_loss: 1.1543\n",
      "Epoch 218/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5121\n",
      "Epoch 218: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5121 - val_loss: 1.1451\n",
      "Epoch 219/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5144\n",
      "Epoch 219: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5144 - val_loss: 1.1555\n",
      "Epoch 220/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5118\n",
      "Epoch 220: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5118 - val_loss: 1.1558\n",
      "Epoch 221/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5119\n",
      "Epoch 221: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5119 - val_loss: 1.1428\n",
      "Epoch 222/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5145\n",
      "Epoch 222: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5145 - val_loss: 1.1534\n",
      "Epoch 223/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5114\n",
      "Epoch 223: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5114 - val_loss: 1.1520\n",
      "Epoch 224/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5114\n",
      "Epoch 224: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5114 - val_loss: 1.1524\n",
      "Epoch 225/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5114\n",
      "Epoch 225: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5114 - val_loss: 1.1486\n",
      "Epoch 226/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5133\n",
      "Epoch 226: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5133 - val_loss: 1.1541\n",
      "Epoch 227/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5119\n",
      "Epoch 227: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5119 - val_loss: 1.1386\n",
      "Epoch 228/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5147\n",
      "Epoch 228: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.5147 - val_loss: 1.1487\n",
      "Epoch 229/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5140\n",
      "Epoch 229: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5140 - val_loss: 1.1387\n",
      "Epoch 230/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5158\n",
      "Epoch 230: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.5158 - val_loss: 1.1474\n",
      "Epoch 231/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5122\n",
      "Epoch 231: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.5122 - val_loss: 1.1573\n",
      "Epoch 232/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5126\n",
      "Epoch 232: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.5126 - val_loss: 1.1485\n",
      "Epoch 233/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5122\n",
      "Epoch 233: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.5122 - val_loss: 1.1583\n",
      "Epoch 234/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5125\n",
      "Epoch 234: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.5125 - val_loss: 1.1401\n",
      "Epoch 235/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5155\n",
      "Epoch 235: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5155 - val_loss: 1.1472\n",
      "Epoch 236/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5123\n",
      "Epoch 236: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5123 - val_loss: 1.1559\n",
      "Epoch 237/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5123\n",
      "Epoch 237: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5123 - val_loss: 1.1454\n",
      "Epoch 238/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5135\n",
      "Epoch 238: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5135 - val_loss: 1.1539\n",
      "Epoch 239/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5110\n",
      "Epoch 239: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.5110 - val_loss: 1.1541\n",
      "Epoch 240/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5107\n",
      "Epoch 240: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.5107 - val_loss: 1.1512\n",
      "Epoch 241/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5108\n",
      "Epoch 241: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5108 - val_loss: 1.1613\n",
      "Epoch 242/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5140\n",
      "Epoch 242: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.5140 - val_loss: 1.1416\n",
      "Epoch 243/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5140\n",
      "Epoch 243: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5140 - val_loss: 1.1498\n",
      "Epoch 244/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5115\n",
      "Epoch 244: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5115 - val_loss: 1.1528\n",
      "Epoch 245/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5108\n",
      "Epoch 245: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.5108 - val_loss: 1.1512\n",
      "Epoch 246/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5118\n",
      "Epoch 246: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5118 - val_loss: 1.1557\n",
      "Epoch 247/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5107\n",
      "Epoch 247: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5107 - val_loss: 1.1491\n",
      "Epoch 248/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5120\n",
      "Epoch 248: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.5120 - val_loss: 1.1588\n",
      "Epoch 249/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5109\n",
      "Epoch 249: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.5109 - val_loss: 1.1412\n",
      "Epoch 250/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5145\n",
      "Epoch 250: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.5145 - val_loss: 1.1490\n",
      "Epoch 251/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5114\n",
      "Epoch 251: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.5114 - val_loss: 1.1538\n",
      "Epoch 252/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5106\n",
      "Epoch 252: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.5106 - val_loss: 1.1459\n",
      "Epoch 253/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5130\n",
      "Epoch 253: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5130 - val_loss: 1.1549\n",
      "Epoch 254/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5104\n",
      "Epoch 254: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5104 - val_loss: 1.1551\n",
      "Epoch 255/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5104\n",
      "Epoch 255: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5104 - val_loss: 1.1484\n",
      "Epoch 256/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5119\n",
      "Epoch 256: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5119 - val_loss: 1.1583\n",
      "Epoch 257/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5106\n",
      "Epoch 257: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5106 - val_loss: 1.1435\n",
      "Epoch 258/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5143\n",
      "Epoch 258: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5143 - val_loss: 1.1508\n",
      "Epoch 259/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5108\n",
      "Epoch 259: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.5108 - val_loss: 1.1605\n",
      "Epoch 260/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5120\n",
      "Epoch 260: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5120 - val_loss: 1.1497\n",
      "Epoch 261/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5121\n",
      "Epoch 261: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5121 - val_loss: 1.1533\n",
      "Epoch 262/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5101\n",
      "Epoch 262: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5101 - val_loss: 1.1577\n",
      "Epoch 263/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5114\n",
      "Epoch 263: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5114 - val_loss: 1.1494\n",
      "Epoch 264/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5113\n",
      "Epoch 264: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.5113 - val_loss: 1.1593\n",
      "Epoch 265/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5105\n",
      "Epoch 265: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.5105 - val_loss: 1.1494\n",
      "Epoch 266/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5112\n",
      "Epoch 266: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.5112 - val_loss: 1.1594\n",
      "Epoch 267/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5107\n",
      "Epoch 267: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.5107 - val_loss: 1.1440\n",
      "Epoch 268/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5137\n",
      "Epoch 268: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.5137 - val_loss: 1.1516\n",
      "Epoch 269/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5104\n",
      "Epoch 269: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.5104 - val_loss: 1.1570\n",
      "Epoch 270/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5099\n",
      "Epoch 270: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.5099 - val_loss: 1.1519\n",
      "Epoch 271/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5104\n",
      "Epoch 271: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5104 - val_loss: 1.1564\n",
      "Epoch 272/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5103\n",
      "Epoch 272: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5103 - val_loss: 1.1479\n",
      "Epoch 273/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5117\n",
      "Epoch 273: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.5117 - val_loss: 1.1582\n",
      "Epoch 274/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5097\n",
      "Epoch 274: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5097 - val_loss: 1.1435\n",
      "Epoch 275/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5127\n",
      "Epoch 275: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5127 - val_loss: 1.1531\n",
      "Epoch 276/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5098\n",
      "Epoch 276: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5098 - val_loss: 1.1515\n",
      "Epoch 277/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5106\n",
      "Epoch 277: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5106 - val_loss: 1.1561\n",
      "Epoch 278/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5096\n",
      "Epoch 278: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5096 - val_loss: 1.1479\n",
      "Epoch 279/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5119\n",
      "Epoch 279: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5119 - val_loss: 1.1578\n",
      "Epoch 280/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5092\n",
      "Epoch 280: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.5092 - val_loss: 1.1486\n",
      "Epoch 281/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5105\n",
      "Epoch 281: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.5105 - val_loss: 1.1595\n",
      "Epoch 282/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5113\n",
      "Epoch 282: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5113 - val_loss: 1.1502\n",
      "Epoch 283/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5105\n",
      "Epoch 283: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.5105 - val_loss: 1.1608\n",
      "Epoch 284/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5104\n",
      "Epoch 284: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5104 - val_loss: 1.1447\n",
      "Epoch 285/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5129\n",
      "Epoch 285: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5129 - val_loss: 1.1527\n",
      "Epoch 286/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5095\n",
      "Epoch 286: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5095 - val_loss: 1.1564\n",
      "Epoch 287/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5090\n",
      "Epoch 287: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.5090 - val_loss: 1.1546\n",
      "Epoch 288/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5089\n",
      "Epoch 288: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5089 - val_loss: 1.1558\n",
      "Epoch 289/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5091\n",
      "Epoch 289: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.5091 - val_loss: 1.1473\n",
      "Epoch 290/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5118\n",
      "Epoch 290: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.5118 - val_loss: 1.1574\n",
      "Epoch 291/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5088\n",
      "Epoch 291: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5088 - val_loss: 1.1629\n",
      "Epoch 292/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5117\n",
      "Epoch 292: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.5117 - val_loss: 1.1442\n",
      "Epoch 293/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5119\n",
      "Epoch 293: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.5119 - val_loss: 1.1539\n",
      "Epoch 294/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5095\n",
      "Epoch 294: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.5095 - val_loss: 1.1523\n",
      "Epoch 295/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5098\n",
      "Epoch 295: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.5098 - val_loss: 1.1570\n",
      "Epoch 296/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5091\n",
      "Epoch 296: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5091 - val_loss: 1.1487\n",
      "Epoch 297/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5111\n",
      "Epoch 297: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5111 - val_loss: 1.1587\n",
      "Epoch 298/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5085\n",
      "Epoch 298: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5085 - val_loss: 1.1532\n",
      "Epoch 299/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5097\n",
      "Epoch 299: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5097 - val_loss: 1.1580\n",
      "Epoch 300/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5087\n",
      "Epoch 300: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5087 - val_loss: 1.1495\n",
      "Epoch 301/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5108\n",
      "Epoch 301: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5108 - val_loss: 1.1601\n",
      "Epoch 302/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5097\n",
      "Epoch 302: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.5097 - val_loss: 1.1485\n",
      "Epoch 303/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5102\n",
      "Epoch 303: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5102 - val_loss: 1.1591\n",
      "Epoch 304/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5097\n",
      "Epoch 304: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5097 - val_loss: 1.1504\n",
      "Epoch 305/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5102\n",
      "Epoch 305: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5102 - val_loss: 1.1607\n",
      "Epoch 306/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5090\n",
      "Epoch 306: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5090 - val_loss: 1.1533\n",
      "Epoch 307/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5093\n",
      "Epoch 307: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5093 - val_loss: 1.1581\n",
      "Epoch 308/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5084\n",
      "Epoch 308: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5084 - val_loss: 1.1506\n",
      "Epoch 309/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5097\n",
      "Epoch 309: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5097 - val_loss: 1.1619\n",
      "Epoch 310/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5103\n",
      "Epoch 310: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5103 - val_loss: 1.1453\n",
      "Epoch 311/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5122\n",
      "Epoch 311: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5122 - val_loss: 1.1532\n",
      "Epoch 312/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5086\n",
      "Epoch 312: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.5086 - val_loss: 1.1633\n",
      "Epoch 313/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5099\n",
      "Epoch 313: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.5099 - val_loss: 1.1549\n",
      "Epoch 314/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5087\n",
      "Epoch 314: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.5087 - val_loss: 1.1593\n",
      "Epoch 315/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5083\n",
      "Epoch 315: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.5083 - val_loss: 1.1522\n",
      "Epoch 316/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5091\n",
      "Epoch 316: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.5091 - val_loss: 1.1629\n",
      "Epoch 317/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5099\n",
      "Epoch 317: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.5099 - val_loss: 1.1465\n",
      "Epoch 318/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5108\n",
      "Epoch 318: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5108 - val_loss: 1.1558\n",
      "Epoch 319/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5081\n",
      "Epoch 319: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5081 - val_loss: 1.1563\n",
      "Epoch 320/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5081\n",
      "Epoch 320: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.5081 - val_loss: 1.1609\n",
      "Epoch 321/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5088\n",
      "Epoch 321: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.5088 - val_loss: 1.1522\n",
      "Epoch 322/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5092\n",
      "Epoch 322: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5092 - val_loss: 1.1628\n",
      "Epoch 323/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5091\n",
      "Epoch 323: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5091 - val_loss: 1.1479\n",
      "Epoch 324/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5101\n",
      "Epoch 324: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5101 - val_loss: 1.1577\n",
      "Epoch 325/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5080\n",
      "Epoch 325: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.5080 - val_loss: 1.1561\n",
      "Epoch 326/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5083\n",
      "Epoch 326: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5083 - val_loss: 1.1608\n",
      "Epoch 327/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5080\n",
      "Epoch 327: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5080 - val_loss: 1.1524\n",
      "Epoch 328/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5093\n",
      "Epoch 328: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5093 - val_loss: 1.1626\n",
      "Epoch 329/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5084\n",
      "Epoch 329: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5084 - val_loss: 1.1483\n",
      "Epoch 330/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5102\n",
      "Epoch 330: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5102 - val_loss: 1.1576\n",
      "Epoch 331/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5073\n",
      "Epoch 331: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5073 - val_loss: 1.1578\n",
      "Epoch 332/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5078\n",
      "Epoch 332: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5078 - val_loss: 1.1627\n",
      "Epoch 333/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5085\n",
      "Epoch 333: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5085 - val_loss: 1.1538\n",
      "Epoch 334/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5086\n",
      "Epoch 334: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5086 - val_loss: 1.1584\n",
      "Epoch 335/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5069\n",
      "Epoch 335: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5069 - val_loss: 1.1575\n",
      "Epoch 336/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5068\n",
      "Epoch 336: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5068 - val_loss: 1.1632\n",
      "Epoch 337/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5081\n",
      "Epoch 337: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5081 - val_loss: 1.1471\n",
      "Epoch 338/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5110\n",
      "Epoch 338: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5110 - val_loss: 1.1557\n",
      "Epoch 339/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5072\n",
      "Epoch 339: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.5072 - val_loss: 1.1645\n",
      "Epoch 340/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5087\n",
      "Epoch 340: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5087 - val_loss: 1.1553\n",
      "Epoch 341/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5080\n",
      "Epoch 341: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5080 - val_loss: 1.1602\n",
      "Epoch 342/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5070\n",
      "Epoch 342: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5070 - val_loss: 1.1525\n",
      "Epoch 343/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5085\n",
      "Epoch 343: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5085 - val_loss: 1.1636\n",
      "Epoch 344/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5079\n",
      "Epoch 344: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5079 - val_loss: 1.1490\n",
      "Epoch 345/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5096\n",
      "Epoch 345: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5096 - val_loss: 1.1591\n",
      "Epoch 346/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5066\n",
      "Epoch 346: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5066 - val_loss: 1.1582\n",
      "Epoch 347/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5065\n",
      "Epoch 347: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5065 - val_loss: 1.1636\n",
      "Epoch 348/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5072\n",
      "Epoch 348: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5072 - val_loss: 1.1495\n",
      "Epoch 349/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5098\n",
      "Epoch 349: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.5098 - val_loss: 1.1591\n",
      "Epoch 350/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5065\n",
      "Epoch 350: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.5065 - val_loss: 1.1581\n",
      "Epoch 351/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5064\n",
      "Epoch 351: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.5064 - val_loss: 1.1636\n",
      "Epoch 352/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5066\n",
      "Epoch 352: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5066 - val_loss: 1.1560\n",
      "Epoch 353/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5083\n",
      "Epoch 353: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5083 - val_loss: 1.1607\n",
      "Epoch 354/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5063\n",
      "Epoch 354: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5063 - val_loss: 1.1597\n",
      "Epoch 355/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5061\n",
      "Epoch 355: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5061 - val_loss: 1.1586\n",
      "Epoch 356/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5060\n",
      "Epoch 356: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5060 - val_loss: 1.1651\n",
      "Epoch 357/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5077\n",
      "Epoch 357: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5077 - val_loss: 1.1490\n",
      "Epoch 358/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5095\n",
      "Epoch 358: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5095 - val_loss: 1.1594\n",
      "Epoch 359/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5075\n",
      "Epoch 359: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5075 - val_loss: 1.1567\n",
      "Epoch 360/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5070\n",
      "Epoch 360: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5070 - val_loss: 1.1685\n",
      "Epoch 361/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5083\n",
      "Epoch 361: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5083 - val_loss: 1.1540\n",
      "Epoch 362/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5088\n",
      "Epoch 362: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5088 - val_loss: 1.1625\n",
      "Epoch 363/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5061\n",
      "Epoch 363: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5061 - val_loss: 1.1570\n",
      "Epoch 364/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5070\n",
      "Epoch 364: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.5070 - val_loss: 1.1677\n",
      "Epoch 365/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5070\n",
      "Epoch 365: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5070 - val_loss: 1.1599\n",
      "Epoch 366/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5066\n",
      "Epoch 366: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5066 - val_loss: 1.1650\n",
      "Epoch 367/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5064\n",
      "Epoch 367: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5064 - val_loss: 1.1571\n",
      "Epoch 368/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5066\n",
      "Epoch 368: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5066 - val_loss: 1.1622\n",
      "Epoch 369/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5057\n",
      "Epoch 369: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5057 - val_loss: 1.1543\n",
      "Epoch 370/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5071\n",
      "Epoch 370: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.5071 - val_loss: 1.1661\n",
      "Epoch 371/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5077\n",
      "Epoch 371: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.5077 - val_loss: 1.1470\n",
      "Epoch 372/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5100\n",
      "Epoch 372: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5100 - val_loss: 1.1550\n",
      "Epoch 373/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5064\n",
      "Epoch 373: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.5064 - val_loss: 1.1615\n",
      "Epoch 374/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5053\n",
      "Epoch 374: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.5053 - val_loss: 1.1606\n",
      "Epoch 375/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5054\n",
      "Epoch 375: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.5054 - val_loss: 1.1656\n",
      "Epoch 376/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5056\n",
      "Epoch 376: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5056 - val_loss: 1.1526\n",
      "Epoch 377/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5084\n",
      "Epoch 377: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5084 - val_loss: 1.1613\n",
      "Epoch 378/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5052\n",
      "Epoch 378: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.5052 - val_loss: 1.1663\n",
      "Epoch 379/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5053\n",
      "Epoch 379: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5053 - val_loss: 1.1632\n",
      "Epoch 380/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5052\n",
      "Epoch 380: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5052 - val_loss: 1.1663\n",
      "Epoch 381/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5058\n",
      "Epoch 381: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5058 - val_loss: 1.1581\n",
      "Epoch 382/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5060\n",
      "Epoch 382: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5060 - val_loss: 1.1698\n",
      "Epoch 383/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5075\n",
      "Epoch 383: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5075 - val_loss: 1.1513\n",
      "Epoch 384/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5089\n",
      "Epoch 384: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5089 - val_loss: 1.1588\n",
      "Epoch 385/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5055\n",
      "Epoch 385: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5055 - val_loss: 1.1634\n",
      "Epoch 386/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5048\n",
      "Epoch 386: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5048 - val_loss: 1.1625\n",
      "Epoch 387/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5047\n",
      "Epoch 387: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.5047 - val_loss: 1.1616\n",
      "Epoch 388/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5048\n",
      "Epoch 388: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5048 - val_loss: 1.1668\n",
      "Epoch 389/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5047\n",
      "Epoch 389: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5047 - val_loss: 1.1658\n",
      "Epoch 390/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5045\n",
      "Epoch 390: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5045 - val_loss: 1.1647\n",
      "Epoch 391/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5044\n",
      "Epoch 391: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5044 - val_loss: 1.1637\n",
      "Epoch 392/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5042\n",
      "Epoch 392: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.5042 - val_loss: 1.1746\n",
      "Epoch 393/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5086\n",
      "Epoch 393: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.5086 - val_loss: 1.1557\n",
      "Epoch 394/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5066\n",
      "Epoch 394: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5066 - val_loss: 1.1663\n",
      "Epoch 395/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5056\n",
      "Epoch 395: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5056 - val_loss: 1.1638\n",
      "Epoch 396/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5046\n",
      "Epoch 396: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5046 - val_loss: 1.1694\n",
      "Epoch 397/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5055\n",
      "Epoch 397: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.5055 - val_loss: 1.1543\n",
      "Epoch 398/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5066\n",
      "Epoch 398: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5066 - val_loss: 1.1649\n",
      "Epoch 399/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5049\n",
      "Epoch 399: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.5049 - val_loss: 1.1628\n",
      "Epoch 400/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5044\n",
      "Epoch 400: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5044 - val_loss: 1.1681\n",
      "Epoch 401/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5046\n",
      "Epoch 401: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5046 - val_loss: 1.1599\n",
      "Epoch 402/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5047\n",
      "Epoch 402: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5047 - val_loss: 1.1714\n",
      "Epoch 403/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5063\n",
      "Epoch 403: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5063 - val_loss: 1.1540\n",
      "Epoch 404/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5071\n",
      "Epoch 404: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5071 - val_loss: 1.1627\n",
      "Epoch 405/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5041\n",
      "Epoch 405: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5041 - val_loss: 1.1675\n",
      "Epoch 406/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5038\n",
      "Epoch 406: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5038 - val_loss: 1.1666\n",
      "Epoch 407/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5037\n",
      "Epoch 407: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5037 - val_loss: 1.1655\n",
      "Epoch 408/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5035\n",
      "Epoch 408: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.5035 - val_loss: 1.1645\n",
      "Epoch 409/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5036\n",
      "Epoch 409: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5036 - val_loss: 1.1702\n",
      "Epoch 410/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5040\n",
      "Epoch 410: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5040 - val_loss: 1.1610\n",
      "Epoch 411/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5043\n",
      "Epoch 411: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.5043 - val_loss: 1.1666\n",
      "Epoch 412/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5032\n",
      "Epoch 412: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.5032 - val_loss: 1.1654\n",
      "Epoch 413/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5034\n",
      "Epoch 413: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5034 - val_loss: 1.1715\n",
      "Epoch 414/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5033\n",
      "Epoch 414: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5033 - val_loss: 1.1662\n",
      "Epoch 415/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5045\n",
      "Epoch 415: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5045 - val_loss: 1.1705\n",
      "Epoch 416/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5035\n",
      "Epoch 416: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5035 - val_loss: 1.1624\n",
      "Epoch 417/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5048\n",
      "Epoch 417: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5048 - val_loss: 1.1741\n",
      "Epoch 418/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5051\n",
      "Epoch 418: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.5051 - val_loss: 1.1568\n",
      "Epoch 419/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5064\n",
      "Epoch 419: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5064 - val_loss: 1.1674\n",
      "Epoch 420/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5034\n",
      "Epoch 420: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5034 - val_loss: 1.1656\n",
      "Epoch 421/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5029\n",
      "Epoch 421: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5029 - val_loss: 1.1708\n",
      "Epoch 422/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5031\n",
      "Epoch 422: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5031 - val_loss: 1.1626\n",
      "Epoch 423/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5032\n",
      "Epoch 423: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5032 - val_loss: 1.1743\n",
      "Epoch 424/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5050\n",
      "Epoch 424: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5050 - val_loss: 1.1571\n",
      "Epoch 425/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5056\n",
      "Epoch 425: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5056 - val_loss: 1.1655\n",
      "Epoch 426/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5027\n",
      "Epoch 426: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5027 - val_loss: 1.1704\n",
      "Epoch 427/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5024\n",
      "Epoch 427: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5024 - val_loss: 1.1694\n",
      "Epoch 428/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5022\n",
      "Epoch 428: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5022 - val_loss: 1.1684\n",
      "Epoch 429/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5020\n",
      "Epoch 429: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.5020 - val_loss: 1.1673\n",
      "Epoch 430/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5022\n",
      "Epoch 430: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.5022 - val_loss: 1.1731\n",
      "Epoch 431/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5026\n",
      "Epoch 431: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5026 - val_loss: 1.1621\n",
      "Epoch 432/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5037\n",
      "Epoch 432: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5037 - val_loss: 1.1743\n",
      "Epoch 433/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5030\n",
      "Epoch 433: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5030 - val_loss: 1.1656\n",
      "Epoch 434/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5021\n",
      "Epoch 434: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5021 - val_loss: 1.1771\n",
      "Epoch 435/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5044\n",
      "Epoch 435: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5044 - val_loss: 1.1599\n",
      "Epoch 436/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5036\n",
      "Epoch 436: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5036 - val_loss: 1.1700\n",
      "Epoch 437/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5022\n",
      "Epoch 437: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5022 - val_loss: 1.1679\n",
      "Epoch 438/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5016\n",
      "Epoch 438: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.5016 - val_loss: 1.1692\n",
      "Epoch 439/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5013\n",
      "Epoch 439: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5013 - val_loss: 1.1742\n",
      "Epoch 440/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5024\n",
      "Epoch 440: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5024 - val_loss: 1.1635\n",
      "Epoch 441/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5025\n",
      "Epoch 441: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5025 - val_loss: 1.1723\n",
      "Epoch 442/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5018\n",
      "Epoch 442: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5018 - val_loss: 1.1695\n",
      "Epoch 443/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5013\n",
      "Epoch 443: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5013 - val_loss: 1.1710\n",
      "Epoch 444/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5010\n",
      "Epoch 444: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5010 - val_loss: 1.1700\n",
      "Epoch 445/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5010\n",
      "Epoch 445: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5010 - val_loss: 1.1756\n",
      "Epoch 446/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5015\n",
      "Epoch 446: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5015 - val_loss: 1.1657\n",
      "Epoch 447/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5029\n",
      "Epoch 447: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5029 - val_loss: 1.1772\n",
      "Epoch 448/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5017\n",
      "Epoch 448: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.5017 - val_loss: 1.1633\n",
      "Epoch 449/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5031\n",
      "Epoch 449: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.5031 - val_loss: 1.1747\n",
      "Epoch 450/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5018\n",
      "Epoch 450: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5018 - val_loss: 1.1721\n",
      "Epoch 451/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5006\n",
      "Epoch 451: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5006 - val_loss: 1.1711\n",
      "Epoch 452/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5004\n",
      "Epoch 452: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5004 - val_loss: 1.1701\n",
      "Epoch 453/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5005\n",
      "Epoch 453: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5005 - val_loss: 1.1754\n",
      "Epoch 454/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5007\n",
      "Epoch 454: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5007 - val_loss: 1.1658\n",
      "Epoch 455/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5023\n",
      "Epoch 455: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5023 - val_loss: 1.1770\n",
      "Epoch 456/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5006\n",
      "Epoch 456: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5006 - val_loss: 1.1682\n",
      "Epoch 457/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5008\n",
      "Epoch 457: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.5008 - val_loss: 1.1796\n",
      "Epoch 458/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5018\n",
      "Epoch 458: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5018 - val_loss: 1.1630\n",
      "Epoch 459/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5023\n",
      "Epoch 459: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5023 - val_loss: 1.1745\n",
      "Epoch 460/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5004\n",
      "Epoch 460: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5004 - val_loss: 1.1722\n",
      "Epoch 461/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4998\n",
      "Epoch 461: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4998 - val_loss: 1.1735\n",
      "Epoch 462/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4996\n",
      "Epoch 462: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4996 - val_loss: 1.1725\n",
      "Epoch 463/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4997\n",
      "Epoch 463: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4997 - val_loss: 1.1776\n",
      "Epoch 464/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5002\n",
      "Epoch 464: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5002 - val_loss: 1.1672\n",
      "Epoch 465/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5010\n",
      "Epoch 465: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.5010 - val_loss: 1.1751\n",
      "Epoch 466/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4992\n",
      "Epoch 466: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4992 - val_loss: 1.1742\n",
      "Epoch 467/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4993\n",
      "Epoch 467: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.4993 - val_loss: 1.1793\n",
      "Epoch 468/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5001\n",
      "Epoch 468: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5001 - val_loss: 1.1676\n",
      "Epoch 469/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5012\n",
      "Epoch 469: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5012 - val_loss: 1.1795\n",
      "Epoch 470/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5007\n",
      "Epoch 470: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5007 - val_loss: 1.1764\n",
      "Epoch 471/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4988\n",
      "Epoch 471: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4988 - val_loss: 1.1754\n",
      "Epoch 472/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4988\n",
      "Epoch 472: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4988 - val_loss: 1.1806\n",
      "Epoch 473/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4995\n",
      "Epoch 473: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4995 - val_loss: 1.1704\n",
      "Epoch 474/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5002\n",
      "Epoch 474: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5002 - val_loss: 1.1781\n",
      "Epoch 475/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4984\n",
      "Epoch 475: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4984 - val_loss: 1.1771\n",
      "Epoch 476/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4983\n",
      "Epoch 476: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4983 - val_loss: 1.1823\n",
      "Epoch 477/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4994\n",
      "Epoch 477: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4994 - val_loss: 1.1715\n",
      "Epoch 478/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5008\n",
      "Epoch 478: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5008 - val_loss: 1.1855\n",
      "Epoch 479/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5007\n",
      "Epoch 479: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5007 - val_loss: 1.1710\n",
      "Epoch 480/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4992\n",
      "Epoch 480: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4992 - val_loss: 1.1754\n",
      "Epoch 481/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4983\n",
      "Epoch 481: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4983 - val_loss: 1.1800\n",
      "Epoch 482/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4978\n",
      "Epoch 482: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4978 - val_loss: 1.1790\n",
      "Epoch 483/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4976\n",
      "Epoch 483: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.4976 - val_loss: 1.1840\n",
      "Epoch 484/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4986\n",
      "Epoch 484: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.4986 - val_loss: 1.1744\n",
      "Epoch 485/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5002\n",
      "Epoch 485: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.5002 - val_loss: 1.1853\n",
      "Epoch 486/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4988\n",
      "Epoch 486: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.4988 - val_loss: 1.1720\n",
      "Epoch 487/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4990\n",
      "Epoch 487: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.4990 - val_loss: 1.1830\n",
      "Epoch 488/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4985\n",
      "Epoch 488: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4985 - val_loss: 1.1804\n",
      "Epoch 489/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4972\n",
      "Epoch 489: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.4972 - val_loss: 1.1794\n",
      "Epoch 490/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4970\n",
      "Epoch 490: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4970 - val_loss: 1.1842\n",
      "Epoch 491/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4980\n",
      "Epoch 491: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4980 - val_loss: 1.1704\n",
      "Epoch 492/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4993\n",
      "Epoch 492: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4993 - val_loss: 1.1809\n",
      "Epoch 493/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4981\n",
      "Epoch 493: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4981 - val_loss: 1.1765\n",
      "Epoch 494/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4970\n",
      "Epoch 494: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4970 - val_loss: 1.1806\n",
      "Epoch 495/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4974\n",
      "Epoch 495: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4974 - val_loss: 1.1744\n",
      "Epoch 496/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4976\n",
      "Epoch 496: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4976 - val_loss: 1.1840\n",
      "Epoch 497/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4968\n",
      "Epoch 497: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4968 - val_loss: 1.1809\n",
      "Epoch 498/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4966\n",
      "Epoch 498: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.4966 - val_loss: 1.1831\n",
      "Epoch 499/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4967\n",
      "Epoch 499: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4967 - val_loss: 1.1759\n",
      "Epoch 500/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4971\n",
      "Epoch 500: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4971 - val_loss: 1.1804\n",
      "Epoch 501/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4962\n",
      "Epoch 501: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4962 - val_loss: 1.1857\n",
      "Epoch 502/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4964\n",
      "Epoch 502: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4964 - val_loss: 1.1748\n",
      "Epoch 503/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4992\n",
      "Epoch 503: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.4992 - val_loss: 1.1849\n",
      "Epoch 504/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4974\n",
      "Epoch 504: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.4974 - val_loss: 1.1813\n",
      "Epoch 505/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4957\n",
      "Epoch 505: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4957 - val_loss: 1.1794\n",
      "Epoch 506/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4960\n",
      "Epoch 506: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.4960 - val_loss: 1.1841\n",
      "Epoch 507/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4956\n",
      "Epoch 507: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.4956 - val_loss: 1.1755\n",
      "Epoch 508/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4966\n",
      "Epoch 508: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4966 - val_loss: 1.1801\n",
      "Epoch 509/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4957\n",
      "Epoch 509: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.4957 - val_loss: 1.1850\n",
      "Epoch 510/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4957\n",
      "Epoch 510: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4957 - val_loss: 1.1760\n",
      "Epoch 511/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4987\n",
      "Epoch 511: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.4987 - val_loss: 1.1883\n",
      "Epoch 512/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.4966\n",
      "Epoch 512: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.4966 - val_loss: 1.1789\n",
      "Epoch 513/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4956\n",
      "Epoch 513: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4956 - val_loss: 1.1834\n",
      "Epoch 514/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4948\n",
      "Epoch 514: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4948 - val_loss: 1.1799\n",
      "Epoch 515/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4952\n",
      "Epoch 515: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4952 - val_loss: 1.1848\n",
      "Epoch 516/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4950\n",
      "Epoch 516: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4950 - val_loss: 1.1731\n",
      "Epoch 517/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4983\n",
      "Epoch 517: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4983 - val_loss: 1.1821\n",
      "Epoch 518/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4963\n",
      "Epoch 518: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4963 - val_loss: 1.1786\n",
      "Epoch 519/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4951\n",
      "Epoch 519: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4951 - val_loss: 1.1828\n",
      "Epoch 520/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4951\n",
      "Epoch 520: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4951 - val_loss: 1.1809\n",
      "Epoch 521/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4946\n",
      "Epoch 521: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4946 - val_loss: 1.1861\n",
      "Epoch 522/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4950\n",
      "Epoch 522: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4950 - val_loss: 1.1730\n",
      "Epoch 523/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4986\n",
      "Epoch 523: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4986 - val_loss: 1.1824\n",
      "Epoch 524/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4956\n",
      "Epoch 524: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4956 - val_loss: 1.1840\n",
      "Epoch 525/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4947\n",
      "Epoch 525: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.4947 - val_loss: 1.1800\n",
      "Epoch 526/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4947\n",
      "Epoch 526: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4947 - val_loss: 1.1841\n",
      "Epoch 527/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4940\n",
      "Epoch 527: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4940 - val_loss: 1.1873\n",
      "Epoch 528/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4948\n",
      "Epoch 528: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4948 - val_loss: 1.1754\n",
      "Epoch 529/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4960\n",
      "Epoch 529: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.4960 - val_loss: 1.1826\n",
      "Epoch 530/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4947\n",
      "Epoch 530: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4947 - val_loss: 1.1839\n",
      "Epoch 531/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4940\n",
      "Epoch 531: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4940 - val_loss: 1.1799\n",
      "Epoch 532/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4943\n",
      "Epoch 532: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4943 - val_loss: 1.1876\n",
      "Epoch 533/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4938\n",
      "Epoch 533: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4938 - val_loss: 1.1805\n",
      "Epoch 534/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4937\n",
      "Epoch 534: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4937 - val_loss: 1.1858\n",
      "Epoch 535/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4938\n",
      "Epoch 535: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4938 - val_loss: 1.1755\n",
      "Epoch 536/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4954\n",
      "Epoch 536: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4954 - val_loss: 1.1803\n",
      "Epoch 537/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4942\n",
      "Epoch 537: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4942 - val_loss: 1.1817\n",
      "Epoch 538/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4933\n",
      "Epoch 538: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4933 - val_loss: 1.1881\n",
      "Epoch 539/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4939\n",
      "Epoch 539: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4939 - val_loss: 1.1762\n",
      "Epoch 540/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4964\n",
      "Epoch 540: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4964 - val_loss: 1.1850\n",
      "Epoch 541/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4943\n",
      "Epoch 541: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4943 - val_loss: 1.1811\n",
      "Epoch 542/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4929\n",
      "Epoch 542: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4929 - val_loss: 1.1877\n",
      "Epoch 543/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4935\n",
      "Epoch 543: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4935 - val_loss: 1.1766\n",
      "Epoch 544/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4945\n",
      "Epoch 544: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4945 - val_loss: 1.1806\n",
      "Epoch 545/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4934\n",
      "Epoch 545: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.4934 - val_loss: 1.1832\n",
      "Epoch 546/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4924\n",
      "Epoch 546: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4924 - val_loss: 1.1902\n",
      "Epoch 547/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4936\n",
      "Epoch 547: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.4936 - val_loss: 1.1776\n",
      "Epoch 548/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4956\n",
      "Epoch 548: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4956 - val_loss: 1.1891\n",
      "Epoch 549/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4933\n",
      "Epoch 549: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4933 - val_loss: 1.1792\n",
      "Epoch 550/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4927\n",
      "Epoch 550: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4927 - val_loss: 1.1879\n",
      "Epoch 551/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4927\n",
      "Epoch 551: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4927 - val_loss: 1.1801\n",
      "Epoch 552/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4922\n",
      "Epoch 552: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4922 - val_loss: 1.1865\n",
      "Epoch 553/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4926\n",
      "Epoch 553: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4926 - val_loss: 1.1744\n",
      "Epoch 554/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4945\n",
      "Epoch 554: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.4945 - val_loss: 1.1830\n",
      "Epoch 555/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4931\n",
      "Epoch 555: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4931 - val_loss: 1.1859\n",
      "Epoch 556/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4921\n",
      "Epoch 556: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4921 - val_loss: 1.1898\n",
      "Epoch 557/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4929\n",
      "Epoch 557: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4929 - val_loss: 1.1759\n",
      "Epoch 558/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4936\n",
      "Epoch 558: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4936 - val_loss: 1.1830\n",
      "Epoch 559/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4918\n",
      "Epoch 559: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4918 - val_loss: 1.1789\n",
      "Epoch 560/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4921\n",
      "Epoch 560: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4921 - val_loss: 1.1879\n",
      "Epoch 561/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4917\n",
      "Epoch 561: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.4917 - val_loss: 1.1798\n",
      "Epoch 562/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4915\n",
      "Epoch 562: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.4915 - val_loss: 1.1893\n",
      "Epoch 563/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4927\n",
      "Epoch 563: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4927 - val_loss: 1.1739\n",
      "Epoch 564/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4929\n",
      "Epoch 564: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4929 - val_loss: 1.1795\n",
      "Epoch 565/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4920\n",
      "Epoch 565: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4920 - val_loss: 1.1820\n",
      "Epoch 566/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4909\n",
      "Epoch 566: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4909 - val_loss: 1.1890\n",
      "Epoch 567/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4921\n",
      "Epoch 567: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4921 - val_loss: 1.1749\n",
      "Epoch 568/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4932\n",
      "Epoch 568: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4932 - val_loss: 1.1811\n",
      "Epoch 569/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4915\n",
      "Epoch 569: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4915 - val_loss: 1.1846\n",
      "Epoch 570/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4905\n",
      "Epoch 570: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4905 - val_loss: 1.1778\n",
      "Epoch 571/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4915\n",
      "Epoch 571: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4915 - val_loss: 1.1862\n",
      "Epoch 572/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4909\n",
      "Epoch 572: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4909 - val_loss: 1.1744\n",
      "Epoch 573/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4924\n",
      "Epoch 573: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4924 - val_loss: 1.1793\n",
      "Epoch 574/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4908\n",
      "Epoch 574: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4908 - val_loss: 1.1829\n",
      "Epoch 575/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4900\n",
      "Epoch 575: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4900 - val_loss: 1.1842\n",
      "Epoch 576/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4903\n",
      "Epoch 576: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.4903 - val_loss: 1.1885\n",
      "Epoch 577/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4907\n",
      "Epoch 577: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.4907 - val_loss: 1.1809\n",
      "Epoch 578/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4905\n",
      "Epoch 578: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4905 - val_loss: 1.1851\n",
      "Epoch 579/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4897\n",
      "Epoch 579: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4897 - val_loss: 1.1753\n",
      "Epoch 580/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4921\n",
      "Epoch 580: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4921 - val_loss: 1.1859\n",
      "Epoch 581/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4903\n",
      "Epoch 581: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4903 - val_loss: 1.1768\n",
      "Epoch 582/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4906\n",
      "Epoch 582: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4906 - val_loss: 1.1864\n",
      "Epoch 583/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4899\n",
      "Epoch 583: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4899 - val_loss: 1.1769\n",
      "Epoch 584/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4898\n",
      "Epoch 584: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4898 - val_loss: 1.1847\n",
      "Epoch 585/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4890\n",
      "Epoch 585: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.4890 - val_loss: 1.1734\n",
      "Epoch 586/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4920\n",
      "Epoch 586: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4920 - val_loss: 1.1842\n",
      "Epoch 587/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4904\n",
      "Epoch 587: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.4904 - val_loss: 1.1885\n",
      "Epoch 588/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4894\n",
      "Epoch 588: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4894 - val_loss: 1.1737\n",
      "Epoch 589/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4917\n",
      "Epoch 589: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4917 - val_loss: 1.1814\n",
      "Epoch 590/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4897\n",
      "Epoch 590: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.4897 - val_loss: 1.1852\n",
      "Epoch 591/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4889\n",
      "Epoch 591: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4889 - val_loss: 1.1808\n",
      "Epoch 592/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4891\n",
      "Epoch 592: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4891 - val_loss: 1.1907\n",
      "Epoch 593/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4897\n",
      "Epoch 593: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4897 - val_loss: 1.1751\n",
      "Epoch 594/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4909\n",
      "Epoch 594: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4909 - val_loss: 1.1838\n",
      "Epoch 595/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4886\n",
      "Epoch 595: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4886 - val_loss: 1.1873\n",
      "Epoch 596/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4889\n",
      "Epoch 596: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4889 - val_loss: 1.1734\n",
      "Epoch 597/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4909\n",
      "Epoch 597: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4909 - val_loss: 1.1799\n",
      "Epoch 598/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4888\n",
      "Epoch 598: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4888 - val_loss: 1.1835\n",
      "Epoch 599/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4878\n",
      "Epoch 599: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4878 - val_loss: 1.1814\n",
      "Epoch 600/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4885\n",
      "Epoch 600: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.4885 - val_loss: 1.1851\n",
      "Epoch 601/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4879\n",
      "Epoch 601: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4879 - val_loss: 1.1721\n",
      "Epoch 602/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4908\n",
      "Epoch 602: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4908 - val_loss: 1.1776\n",
      "Epoch 603/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4887\n",
      "Epoch 603: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4887 - val_loss: 1.1812\n",
      "Epoch 604/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4876\n",
      "Epoch 604: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4876 - val_loss: 1.1883\n",
      "Epoch 605/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4882\n",
      "Epoch 605: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.4882 - val_loss: 1.1737\n",
      "Epoch 606/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4900\n",
      "Epoch 606: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.4900 - val_loss: 1.1844\n",
      "Epoch 607/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4877\n",
      "Epoch 607: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.4877 - val_loss: 1.1800\n",
      "Epoch 608/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4875\n",
      "Epoch 608: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4875 - val_loss: 1.1868\n",
      "Epoch 609/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4873\n",
      "Epoch 609: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4873 - val_loss: 1.1786\n",
      "Epoch 610/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4875\n",
      "Epoch 610: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4875 - val_loss: 1.1886\n",
      "Epoch 611/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4881\n",
      "Epoch 611: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4881 - val_loss: 1.1724\n",
      "Epoch 612/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4888\n",
      "Epoch 612: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4888 - val_loss: 1.1808\n",
      "Epoch 613/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4878\n",
      "Epoch 613: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4878 - val_loss: 1.1846\n",
      "Epoch 614/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4865\n",
      "Epoch 614: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.4865 - val_loss: 1.1885\n",
      "Epoch 615/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4876\n",
      "Epoch 615: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.4876 - val_loss: 1.1758\n",
      "Epoch 616/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4875\n",
      "Epoch 616: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4875 - val_loss: 1.1810\n",
      "Epoch 617/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4867\n",
      "Epoch 617: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4867 - val_loss: 1.1847\n",
      "Epoch 618/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4864\n",
      "Epoch 618: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4864 - val_loss: 1.1829\n",
      "Epoch 619/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4864\n",
      "Epoch 619: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.4864 - val_loss: 1.1868\n",
      "Epoch 620/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.4868\n",
      "Epoch 620: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.4868 - val_loss: 1.1714\n",
      "Epoch 621/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4891\n",
      "Epoch 621: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4891 - val_loss: 1.1828\n",
      "Epoch 622/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4863\n",
      "Epoch 622: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.4863 - val_loss: 1.1782\n",
      "Epoch 623/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4861\n",
      "Epoch 623: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.4861 - val_loss: 1.1885\n",
      "Epoch 624/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4862\n",
      "Epoch 624: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4862 - val_loss: 1.1753\n",
      "Epoch 625/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4861\n",
      "Epoch 625: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4861 - val_loss: 1.1860\n",
      "Epoch 626/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4859\n",
      "Epoch 626: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4859 - val_loss: 1.1716\n",
      "Epoch 627/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4868\n",
      "Epoch 627: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4868 - val_loss: 1.1794\n",
      "Epoch 628/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4862\n",
      "Epoch 628: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4862 - val_loss: 1.1833\n",
      "Epoch 629/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4849\n",
      "Epoch 629: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4849 - val_loss: 1.1744\n",
      "Epoch 630/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4859\n",
      "Epoch 630: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4859 - val_loss: 1.1889\n",
      "Epoch 631/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4866\n",
      "Epoch 631: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4866 - val_loss: 1.1710\n",
      "Epoch 632/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4865\n",
      "Epoch 632: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4865 - val_loss: 1.1748\n",
      "Epoch 633/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4854\n",
      "Epoch 633: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4854 - val_loss: 1.1788\n",
      "Epoch 634/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4847\n",
      "Epoch 634: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4847 - val_loss: 1.1899\n",
      "Epoch 635/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4865\n",
      "Epoch 635: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4865 - val_loss: 1.1711\n",
      "Epoch 636/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4861\n",
      "Epoch 636: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4861 - val_loss: 1.1821\n",
      "Epoch 637/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4852\n",
      "Epoch 637: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.4852 - val_loss: 1.1861\n",
      "Epoch 638/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.4845\n",
      "Epoch 638: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.4845 - val_loss: 1.1773\n",
      "Epoch 639/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4842\n",
      "Epoch 639: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4842 - val_loss: 1.1884\n",
      "Epoch 640/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4855\n",
      "Epoch 640: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4855 - val_loss: 1.1702\n",
      "Epoch 641/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4856\n",
      "Epoch 641: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4856 - val_loss: 1.1777\n",
      "Epoch 642/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4845\n",
      "Epoch 642: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4845 - val_loss: 1.1817\n",
      "Epoch 643/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4833\n",
      "Epoch 643: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4833 - val_loss: 1.1763\n",
      "Epoch 644/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4837\n",
      "Epoch 644: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4837 - val_loss: 1.1806\n",
      "Epoch 645/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4841\n",
      "Epoch 645: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4841 - val_loss: 1.1739\n",
      "Epoch 646/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4846\n",
      "Epoch 646: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4846 - val_loss: 1.1776\n",
      "Epoch 647/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4832\n",
      "Epoch 647: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4832 - val_loss: 1.1859\n",
      "Epoch 648/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4839\n",
      "Epoch 648: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4839 - val_loss: 1.1685\n",
      "Epoch 649/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4863\n",
      "Epoch 649: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4863 - val_loss: 1.1819\n",
      "Epoch 650/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4834\n",
      "Epoch 650: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.4834 - val_loss: 1.1775\n",
      "Epoch 651/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4830\n",
      "Epoch 651: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4830 - val_loss: 1.1848\n",
      "Epoch 652/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4829\n",
      "Epoch 652: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.4829 - val_loss: 1.1759\n",
      "Epoch 653/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4828\n",
      "Epoch 653: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4828 - val_loss: 1.1906\n",
      "Epoch 654/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4847\n",
      "Epoch 654: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4847 - val_loss: 1.1719\n",
      "Epoch 655/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4843\n",
      "Epoch 655: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4843 - val_loss: 1.1819\n",
      "Epoch 656/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4822\n",
      "Epoch 656: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4822 - val_loss: 1.1786\n",
      "Epoch 657/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4823\n",
      "Epoch 657: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4823 - val_loss: 1.1880\n",
      "Epoch 658/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4827\n",
      "Epoch 658: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4827 - val_loss: 1.1754\n",
      "Epoch 659/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4823\n",
      "Epoch 659: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4823 - val_loss: 1.1827\n",
      "Epoch 660/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4816\n",
      "Epoch 660: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4816 - val_loss: 1.1709\n",
      "Epoch 661/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4828\n",
      "Epoch 661: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4828 - val_loss: 1.1767\n",
      "Epoch 662/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4817\n",
      "Epoch 662: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4817 - val_loss: 1.1808\n",
      "Epoch 663/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4819\n",
      "Epoch 663: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4819 - val_loss: 1.1826\n",
      "Epoch 664/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4816\n",
      "Epoch 664: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4816 - val_loss: 1.1871\n",
      "Epoch 665/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4829\n",
      "Epoch 665: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.4829 - val_loss: 1.1688\n",
      "Epoch 666/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4834\n",
      "Epoch 666: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.4834 - val_loss: 1.1793\n",
      "Epoch 667/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4816\n",
      "Epoch 667: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.4816 - val_loss: 1.1836\n",
      "Epoch 668/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4808\n",
      "Epoch 668: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4808 - val_loss: 1.1751\n",
      "Epoch 669/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4812\n",
      "Epoch 669: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.4812 - val_loss: 1.1895\n",
      "Epoch 670/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4827\n",
      "Epoch 670: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4827 - val_loss: 1.1704\n",
      "Epoch 671/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4821\n",
      "Epoch 671: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4821 - val_loss: 1.1827\n",
      "Epoch 672/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4803\n",
      "Epoch 672: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4803 - val_loss: 1.1746\n",
      "Epoch 673/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4805\n",
      "Epoch 673: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4805 - val_loss: 1.1886\n",
      "Epoch 674/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4823\n",
      "Epoch 674: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4823 - val_loss: 1.1700\n",
      "Epoch 675/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4815\n",
      "Epoch 675: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4815 - val_loss: 1.1820\n",
      "Epoch 676/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4799\n",
      "Epoch 676: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.4799 - val_loss: 1.1779\n",
      "Epoch 677/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4799\n",
      "Epoch 677: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4799 - val_loss: 1.1848\n",
      "Epoch 678/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4805\n",
      "Epoch 678: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4805 - val_loss: 1.1705\n",
      "Epoch 679/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4803\n",
      "Epoch 679: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4803 - val_loss: 1.1772\n",
      "Epoch 680/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4793\n",
      "Epoch 680: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4793 - val_loss: 1.1808\n",
      "Epoch 681/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4804\n",
      "Epoch 681: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.4804 - val_loss: 1.1750\n",
      "Epoch 682/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4802\n",
      "Epoch 682: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4802 - val_loss: 1.1784\n",
      "Epoch 683/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4789\n",
      "Epoch 683: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4789 - val_loss: 1.1737\n",
      "Epoch 684/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4793\n",
      "Epoch 684: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4793 - val_loss: 1.1778\n",
      "Epoch 685/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4790\n",
      "Epoch 685: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4790 - val_loss: 1.1721\n",
      "Epoch 686/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4802\n",
      "Epoch 686: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4802 - val_loss: 1.1753\n",
      "Epoch 687/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4787\n",
      "Epoch 687: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4787 - val_loss: 1.1797\n",
      "Epoch 688/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4787\n",
      "Epoch 688: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4787 - val_loss: 1.1831\n",
      "Epoch 689/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4789\n",
      "Epoch 689: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4789 - val_loss: 1.1764\n",
      "Epoch 690/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4792\n",
      "Epoch 690: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4792 - val_loss: 1.1944\n",
      "Epoch 691/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4827\n",
      "Epoch 691: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4827 - val_loss: 1.1702\n",
      "Epoch 692/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4797\n",
      "Epoch 692: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4797 - val_loss: 1.1853\n",
      "Epoch 693/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4798\n",
      "Epoch 693: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.4798 - val_loss: 1.1689\n",
      "Epoch 694/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.4789\n",
      "Epoch 694: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.4789 - val_loss: 1.1744\n",
      "Epoch 695/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4779\n",
      "Epoch 695: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4779 - val_loss: 1.1808\n",
      "Epoch 696/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4778\n",
      "Epoch 696: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4778 - val_loss: 1.1674\n",
      "Epoch 697/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4791\n",
      "Epoch 697: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4791 - val_loss: 1.1785\n",
      "Epoch 698/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4771\n",
      "Epoch 698: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4771 - val_loss: 1.1710\n",
      "Epoch 699/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4777\n",
      "Epoch 699: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4777 - val_loss: 1.1846\n",
      "Epoch 700/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4788\n",
      "Epoch 700: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4788 - val_loss: 1.1671\n",
      "Epoch 701/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4793\n",
      "Epoch 701: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4793 - val_loss: 1.1817\n",
      "Epoch 702/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4771\n",
      "Epoch 702: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4771 - val_loss: 1.1748\n",
      "Epoch 703/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4770\n",
      "Epoch 703: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4770 - val_loss: 1.1812\n",
      "Epoch 704/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4773\n",
      "Epoch 704: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4773 - val_loss: 1.1660\n",
      "Epoch 705/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4787\n",
      "Epoch 705: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4787 - val_loss: 1.1790\n",
      "Epoch 706/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4763\n",
      "Epoch 706: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4763 - val_loss: 1.1824\n",
      "Epoch 707/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4775\n",
      "Epoch 707: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4775 - val_loss: 1.1690\n",
      "Epoch 708/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4774\n",
      "Epoch 708: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4774 - val_loss: 1.1801\n",
      "Epoch 709/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4762\n",
      "Epoch 709: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4762 - val_loss: 1.1676\n",
      "Epoch 710/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4780\n",
      "Epoch 710: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4780 - val_loss: 1.1811\n",
      "Epoch 711/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4772\n",
      "Epoch 711: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4772 - val_loss: 1.1651\n",
      "Epoch 712/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4774\n",
      "Epoch 712: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4774 - val_loss: 1.1823\n",
      "Epoch 713/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4766\n",
      "Epoch 713: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4766 - val_loss: 1.1673\n",
      "Epoch 714/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4770\n",
      "Epoch 714: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4770 - val_loss: 1.1771\n",
      "Epoch 715/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4754\n",
      "Epoch 715: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4754 - val_loss: 1.1702\n",
      "Epoch 716/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4756\n",
      "Epoch 716: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.4756 - val_loss: 1.1794\n",
      "Epoch 717/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4757\n",
      "Epoch 717: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4757 - val_loss: 1.1642\n",
      "Epoch 718/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4772\n",
      "Epoch 718: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4772 - val_loss: 1.1805\n",
      "Epoch 719/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4764\n",
      "Epoch 719: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4764 - val_loss: 1.1651\n",
      "Epoch 720/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4760\n",
      "Epoch 720: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4760 - val_loss: 1.1790\n",
      "Epoch 721/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4752\n",
      "Epoch 721: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4752 - val_loss: 1.1645\n",
      "Epoch 722/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4764\n",
      "Epoch 722: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4764 - val_loss: 1.1776\n",
      "Epoch 723/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4746\n",
      "Epoch 723: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4746 - val_loss: 1.1801\n",
      "Epoch 724/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4751\n",
      "Epoch 724: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4751 - val_loss: 1.1638\n",
      "Epoch 725/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4763\n",
      "Epoch 725: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4763 - val_loss: 1.1769\n",
      "Epoch 726/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4744\n",
      "Epoch 726: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4744 - val_loss: 1.1789\n",
      "Epoch 727/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4742\n",
      "Epoch 727: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4742 - val_loss: 1.1692\n",
      "Epoch 728/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4743\n",
      "Epoch 728: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.4743 - val_loss: 1.1750\n",
      "Epoch 729/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4737\n",
      "Epoch 729: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4737 - val_loss: 1.1675\n",
      "Epoch 730/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4742\n",
      "Epoch 730: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4742 - val_loss: 1.1775\n",
      "Epoch 731/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4737\n",
      "Epoch 731: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4737 - val_loss: 1.1639\n",
      "Epoch 732/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4752\n",
      "Epoch 732: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4752 - val_loss: 1.1824\n",
      "Epoch 733/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4758\n",
      "Epoch 733: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4758 - val_loss: 1.1613\n",
      "Epoch 734/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4750\n",
      "Epoch 734: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4750 - val_loss: 1.1754\n",
      "Epoch 735/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4734\n",
      "Epoch 735: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4734 - val_loss: 1.1717\n",
      "Epoch 736/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4728\n",
      "Epoch 736: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4728 - val_loss: 1.1811\n",
      "Epoch 737/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4735\n",
      "Epoch 737: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.4735 - val_loss: 1.1658\n",
      "Epoch 738/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4750\n",
      "Epoch 738: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.4750 - val_loss: 1.1824\n",
      "Epoch 739/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4742\n",
      "Epoch 739: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4742 - val_loss: 1.1618\n",
      "Epoch 740/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4750\n",
      "Epoch 740: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.4750 - val_loss: 1.1761\n",
      "Epoch 741/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4724\n",
      "Epoch 741: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.4724 - val_loss: 1.1764\n",
      "Epoch 742/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4725\n",
      "Epoch 742: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4725 - val_loss: 1.1700\n",
      "Epoch 743/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4725\n",
      "Epoch 743: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4725 - val_loss: 1.1806\n",
      "Epoch 744/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4729\n",
      "Epoch 744: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4729 - val_loss: 1.1663\n",
      "Epoch 745/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4733\n",
      "Epoch 745: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4733 - val_loss: 1.1819\n",
      "Epoch 746/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4735\n",
      "Epoch 746: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4735 - val_loss: 1.1667\n",
      "Epoch 747/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4727\n",
      "Epoch 747: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4727 - val_loss: 1.1783\n",
      "Epoch 748/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4719\n",
      "Epoch 748: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4719 - val_loss: 1.1667\n",
      "Epoch 749/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4724\n",
      "Epoch 749: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4724 - val_loss: 1.1767\n",
      "Epoch 750/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4713\n",
      "Epoch 750: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4713 - val_loss: 1.1701\n",
      "Epoch 751/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4710\n",
      "Epoch 751: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4710 - val_loss: 1.1790\n",
      "Epoch 752/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4720\n",
      "Epoch 752: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.4720 - val_loss: 1.1636\n",
      "Epoch 753/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.4724\n",
      "Epoch 753: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.4724 - val_loss: 1.1775\n",
      "Epoch 754/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4708\n",
      "Epoch 754: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4708 - val_loss: 1.1690\n",
      "Epoch 755/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4709\n",
      "Epoch 755: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4709 - val_loss: 1.1774\n",
      "Epoch 756/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4712\n",
      "Epoch 756: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4712 - val_loss: 1.1643\n",
      "Epoch 757/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4717\n",
      "Epoch 757: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4717 - val_loss: 1.1756\n",
      "Epoch 758/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4702\n",
      "Epoch 758: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4702 - val_loss: 1.1630\n",
      "Epoch 759/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4717\n",
      "Epoch 759: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4717 - val_loss: 1.1805\n",
      "Epoch 760/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4725\n",
      "Epoch 760: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4725 - val_loss: 1.1597\n",
      "Epoch 761/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4723\n",
      "Epoch 761: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4723 - val_loss: 1.1741\n",
      "Epoch 762/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4698\n",
      "Epoch 762: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.4698 - val_loss: 1.1703\n",
      "Epoch 763/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4699\n",
      "Epoch 763: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4699 - val_loss: 1.1684\n",
      "Epoch 764/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4695\n",
      "Epoch 764: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4695 - val_loss: 1.1740\n",
      "Epoch 765/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4690\n",
      "Epoch 765: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4690 - val_loss: 1.1643\n",
      "Epoch 766/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4702\n",
      "Epoch 766: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.4702 - val_loss: 1.1760\n",
      "Epoch 767/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4695\n",
      "Epoch 767: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4695 - val_loss: 1.1600\n",
      "Epoch 768/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4726\n",
      "Epoch 768: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4726 - val_loss: 1.1772\n",
      "Epoch 769/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4701\n",
      "Epoch 769: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4701 - val_loss: 1.1612\n",
      "Epoch 770/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4705\n",
      "Epoch 770: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4705 - val_loss: 1.1735\n",
      "Epoch 771/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4682\n",
      "Epoch 771: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4682 - val_loss: 1.1618\n",
      "Epoch 772/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4702\n",
      "Epoch 772: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4702 - val_loss: 1.1750\n",
      "Epoch 773/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4693\n",
      "Epoch 773: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4693 - val_loss: 1.1594\n",
      "Epoch 774/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4703\n",
      "Epoch 774: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4703 - val_loss: 1.1740\n",
      "Epoch 775/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4682\n",
      "Epoch 775: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.4682 - val_loss: 1.1593\n",
      "Epoch 776/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4704\n",
      "Epoch 776: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4704 - val_loss: 1.1708\n",
      "Epoch 777/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4674\n",
      "Epoch 777: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4674 - val_loss: 1.1671\n",
      "Epoch 778/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4673\n",
      "Epoch 778: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4673 - val_loss: 1.1728\n",
      "Epoch 779/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4677\n",
      "Epoch 779: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4677 - val_loss: 1.1573\n",
      "Epoch 780/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4704\n",
      "Epoch 780: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4704 - val_loss: 1.1718\n",
      "Epoch 781/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4670\n",
      "Epoch 781: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4670 - val_loss: 1.1636\n",
      "Epoch 782/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4676\n",
      "Epoch 782: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4676 - val_loss: 1.1719\n",
      "Epoch 783/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4669\n",
      "Epoch 783: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4669 - val_loss: 1.1594\n",
      "Epoch 784/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4687\n",
      "Epoch 784: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4687 - val_loss: 1.1741\n",
      "Epoch 785/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4671\n",
      "Epoch 785: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4671 - val_loss: 1.1594\n",
      "Epoch 786/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4689\n",
      "Epoch 786: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4689 - val_loss: 1.1760\n",
      "Epoch 787/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4681\n",
      "Epoch 787: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.4681 - val_loss: 1.1561\n",
      "Epoch 788/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4692\n",
      "Epoch 788: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.4692 - val_loss: 1.1677\n",
      "Epoch 789/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4658\n",
      "Epoch 789: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4658 - val_loss: 1.1708\n",
      "Epoch 790/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4661\n",
      "Epoch 790: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4661 - val_loss: 1.1716\n",
      "Epoch 791/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4663\n",
      "Epoch 791: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4663 - val_loss: 1.1704\n",
      "Epoch 792/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4652\n",
      "Epoch 792: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4652 - val_loss: 1.1646\n",
      "Epoch 793/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4656\n",
      "Epoch 793: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4656 - val_loss: 1.1799\n",
      "Epoch 794/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4690\n",
      "Epoch 794: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4690 - val_loss: 1.1570\n",
      "Epoch 795/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4692\n",
      "Epoch 795: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4692 - val_loss: 1.1711\n",
      "Epoch 796/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4660\n",
      "Epoch 796: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4660 - val_loss: 1.1666\n",
      "Epoch 797/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4650\n",
      "Epoch 797: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4650 - val_loss: 1.1652\n",
      "Epoch 798/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4648\n",
      "Epoch 798: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.4648 - val_loss: 1.1744\n",
      "Epoch 799/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4669\n",
      "Epoch 799: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4669 - val_loss: 1.1627\n",
      "Epoch 800/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4652\n",
      "Epoch 800: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.4652 - val_loss: 1.1769\n",
      "Epoch 801/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.4668\n",
      "Epoch 801: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.4668 - val_loss: 1.1582\n",
      "Epoch 802/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4675\n",
      "Epoch 802: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4675 - val_loss: 1.1761\n",
      "Epoch 803/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4672\n",
      "Epoch 803: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4672 - val_loss: 1.1607\n",
      "Epoch 804/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4651\n",
      "Epoch 804: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4651 - val_loss: 1.1729\n",
      "Epoch 805/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4654\n",
      "Epoch 805: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4654 - val_loss: 1.1583\n",
      "Epoch 806/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4658\n",
      "Epoch 806: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4658 - val_loss: 1.1699\n",
      "Epoch 807/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4640\n",
      "Epoch 807: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4640 - val_loss: 1.1622\n",
      "Epoch 808/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4646\n",
      "Epoch 808: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4646 - val_loss: 1.1731\n",
      "Epoch 809/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4642\n",
      "Epoch 809: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4642 - val_loss: 1.1583\n",
      "Epoch 810/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4665\n",
      "Epoch 810: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4665 - val_loss: 1.1726\n",
      "Epoch 811/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4643\n",
      "Epoch 811: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4643 - val_loss: 1.1625\n",
      "Epoch 812/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4641\n",
      "Epoch 812: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4641 - val_loss: 1.1731\n",
      "Epoch 813/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4635\n",
      "Epoch 813: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4635 - val_loss: 1.1594\n",
      "Epoch 814/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4664\n",
      "Epoch 814: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4664 - val_loss: 1.1753\n",
      "Epoch 815/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4652\n",
      "Epoch 815: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4652 - val_loss: 1.1577\n",
      "Epoch 816/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4650\n",
      "Epoch 816: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4650 - val_loss: 1.1702\n",
      "Epoch 817/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4629\n",
      "Epoch 817: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4629 - val_loss: 1.1629\n",
      "Epoch 818/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4632\n",
      "Epoch 818: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4632 - val_loss: 1.1736\n",
      "Epoch 819/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4634\n",
      "Epoch 819: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4634 - val_loss: 1.1545\n",
      "Epoch 820/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4678\n",
      "Epoch 820: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4678 - val_loss: 1.1732\n",
      "Epoch 821/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4642\n",
      "Epoch 821: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4642 - val_loss: 1.1585\n",
      "Epoch 822/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4634\n",
      "Epoch 822: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.4634 - val_loss: 1.1692\n",
      "Epoch 823/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4626\n",
      "Epoch 823: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4626 - val_loss: 1.1562\n",
      "Epoch 824/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4642\n",
      "Epoch 824: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.4642 - val_loss: 1.1674\n",
      "Epoch 825/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4618\n",
      "Epoch 825: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4618 - val_loss: 1.1608\n",
      "Epoch 826/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4625\n",
      "Epoch 826: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4625 - val_loss: 1.1703\n",
      "Epoch 827/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4618\n",
      "Epoch 827: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4618 - val_loss: 1.1573\n",
      "Epoch 828/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4641\n",
      "Epoch 828: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4641 - val_loss: 1.1727\n",
      "Epoch 829/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4635\n",
      "Epoch 829: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4635 - val_loss: 1.1567\n",
      "Epoch 830/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4632\n",
      "Epoch 830: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4632 - val_loss: 1.1682\n",
      "Epoch 831/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4613\n",
      "Epoch 831: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4613 - val_loss: 1.1589\n",
      "Epoch 832/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4624\n",
      "Epoch 832: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4624 - val_loss: 1.1688\n",
      "Epoch 833/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4609\n",
      "Epoch 833: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.4609 - val_loss: 1.1597\n",
      "Epoch 834/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.4621\n",
      "Epoch 834: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.4621 - val_loss: 1.1740\n",
      "Epoch 835/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4639\n",
      "Epoch 835: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.4639 - val_loss: 1.1543\n",
      "Epoch 836/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4628\n",
      "Epoch 836: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4628 - val_loss: 1.1651\n",
      "Epoch 837/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4608\n",
      "Epoch 837: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.4608 - val_loss: 1.1581\n",
      "Epoch 838/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4613\n",
      "Epoch 838: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.4613 - val_loss: 1.1682\n",
      "Epoch 839/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4608\n",
      "Epoch 839: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.4608 - val_loss: 1.1565\n",
      "Epoch 840/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4619\n",
      "Epoch 840: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4619 - val_loss: 1.1705\n",
      "Epoch 841/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4617\n",
      "Epoch 841: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.4617 - val_loss: 1.1551\n",
      "Epoch 842/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4629\n",
      "Epoch 842: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.4629 - val_loss: 1.1684\n",
      "Epoch 843/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4609\n",
      "Epoch 843: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4609 - val_loss: 1.1540\n",
      "Epoch 844/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4618\n",
      "Epoch 844: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.4618 - val_loss: 1.1646\n",
      "Epoch 845/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4594\n",
      "Epoch 845: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4594 - val_loss: 1.1575\n",
      "Epoch 846/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4607\n",
      "Epoch 846: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4607 - val_loss: 1.1677\n",
      "Epoch 847/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4593\n",
      "Epoch 847: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4593 - val_loss: 1.1584\n",
      "Epoch 848/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4605\n",
      "Epoch 848: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4605 - val_loss: 1.1765\n",
      "Epoch 849/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4644\n",
      "Epoch 849: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4644 - val_loss: 1.1525\n",
      "Epoch 850/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4625\n",
      "Epoch 850: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4625 - val_loss: 1.1694\n",
      "Epoch 851/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4607\n",
      "Epoch 851: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4607 - val_loss: 1.1551\n",
      "Epoch 852/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4603\n",
      "Epoch 852: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4603 - val_loss: 1.1636\n",
      "Epoch 853/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4585\n",
      "Epoch 853: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4585 - val_loss: 1.1572\n",
      "Epoch 854/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4597\n",
      "Epoch 854: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4597 - val_loss: 1.1666\n",
      "Epoch 855/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4586\n",
      "Epoch 855: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4586 - val_loss: 1.1552\n",
      "Epoch 856/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4607\n",
      "Epoch 856: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.4607 - val_loss: 1.1677\n",
      "Epoch 857/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4590\n",
      "Epoch 857: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.4590 - val_loss: 1.1537\n",
      "Epoch 858/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4606\n",
      "Epoch 858: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4606 - val_loss: 1.1660\n",
      "Epoch 859/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4589\n",
      "Epoch 859: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4589 - val_loss: 1.1571\n",
      "Epoch 860/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4589\n",
      "Epoch 860: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4589 - val_loss: 1.1667\n",
      "Epoch 861/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4579\n",
      "Epoch 861: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4579 - val_loss: 1.1552\n",
      "Epoch 862/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4603\n",
      "Epoch 862: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4603 - val_loss: 1.1699\n",
      "Epoch 863/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4595\n",
      "Epoch 863: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4595 - val_loss: 1.1539\n",
      "Epoch 864/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4596\n",
      "Epoch 864: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4596 - val_loss: 1.1658\n",
      "Epoch 865/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4586\n",
      "Epoch 865: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4586 - val_loss: 1.1527\n",
      "Epoch 866/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4594\n",
      "Epoch 866: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4594 - val_loss: 1.1669\n",
      "Epoch 867/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4580\n",
      "Epoch 867: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4580 - val_loss: 1.1582\n",
      "Epoch 868/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4576\n",
      "Epoch 868: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.4576 - val_loss: 1.1678\n",
      "Epoch 869/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4576\n",
      "Epoch 869: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.4576 - val_loss: 1.1536\n",
      "Epoch 870/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4613\n",
      "Epoch 870: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4613 - val_loss: 1.1678\n",
      "Epoch 871/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4584\n",
      "Epoch 871: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4584 - val_loss: 1.1544\n",
      "Epoch 872/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4580\n",
      "Epoch 872: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4580 - val_loss: 1.1640\n",
      "Epoch 873/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4567\n",
      "Epoch 873: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4567 - val_loss: 1.1576\n",
      "Epoch 874/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4568\n",
      "Epoch 874: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4568 - val_loss: 1.1672\n",
      "Epoch 875/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4568\n",
      "Epoch 875: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.4568 - val_loss: 1.1503\n",
      "Epoch 876/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4616\n",
      "Epoch 876: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4616 - val_loss: 1.1715\n",
      "Epoch 877/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4602\n",
      "Epoch 877: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4602 - val_loss: 1.1529\n",
      "Epoch 878/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4583\n",
      "Epoch 878: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4583 - val_loss: 1.1653\n",
      "Epoch 879/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4577\n",
      "Epoch 879: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4577 - val_loss: 1.1522\n",
      "Epoch 880/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4571\n",
      "Epoch 880: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.4571 - val_loss: 1.1604\n",
      "Epoch 881/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.4559\n",
      "Epoch 881: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.4559 - val_loss: 1.1545\n",
      "Epoch 882/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4562\n",
      "Epoch 882: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.4562 - val_loss: 1.1631\n",
      "Epoch 883/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4557\n",
      "Epoch 883: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4557 - val_loss: 1.1533\n",
      "Epoch 884/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4567\n",
      "Epoch 884: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4567 - val_loss: 1.1662\n",
      "Epoch 885/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4570\n",
      "Epoch 885: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4570 - val_loss: 1.1520\n",
      "Epoch 886/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4575\n",
      "Epoch 886: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.4575 - val_loss: 1.1636\n",
      "Epoch 887/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4557\n",
      "Epoch 887: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4557 - val_loss: 1.1532\n",
      "Epoch 888/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4561\n",
      "Epoch 888: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4561 - val_loss: 1.1627\n",
      "Epoch 889/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4551\n",
      "Epoch 889: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4551 - val_loss: 1.1501\n",
      "Epoch 890/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4581\n",
      "Epoch 890: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4581 - val_loss: 1.1674\n",
      "Epoch 891/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4575\n",
      "Epoch 891: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4575 - val_loss: 1.1517\n",
      "Epoch 892/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4556\n",
      "Epoch 892: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.4556 - val_loss: 1.1600\n",
      "Epoch 893/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4547\n",
      "Epoch 893: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.4547 - val_loss: 1.1522\n",
      "Epoch 894/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4551\n",
      "Epoch 894: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.4551 - val_loss: 1.1608\n",
      "Epoch 895/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4540\n",
      "Epoch 895: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4540 - val_loss: 1.1586\n",
      "Epoch 896/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4539\n",
      "Epoch 896: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4539 - val_loss: 1.1565\n",
      "Epoch 897/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4535\n",
      "Epoch 897: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4535 - val_loss: 1.1540\n",
      "Epoch 898/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4536\n",
      "Epoch 898: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4536 - val_loss: 1.1685\n",
      "Epoch 899/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4582\n",
      "Epoch 899: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4582 - val_loss: 1.1456\n",
      "Epoch 900/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4591\n",
      "Epoch 900: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4591 - val_loss: 1.1632\n",
      "Epoch 901/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4555\n",
      "Epoch 901: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.4555 - val_loss: 1.1504\n",
      "Epoch 902/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4542\n",
      "Epoch 902: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.4542 - val_loss: 1.1623\n",
      "Epoch 903/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4550\n",
      "Epoch 903: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.4550 - val_loss: 1.1491\n",
      "Epoch 904/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.4543\n",
      "Epoch 904: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.4543 - val_loss: 1.1588\n",
      "Epoch 905/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4530\n",
      "Epoch 905: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.4530 - val_loss: 1.1487\n",
      "Epoch 906/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4552\n",
      "Epoch 906: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4552 - val_loss: 1.1708\n",
      "Epoch 907/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4588\n",
      "Epoch 907: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4588 - val_loss: 1.1510\n",
      "Epoch 908/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4544\n",
      "Epoch 908: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4544 - val_loss: 1.1624\n",
      "Epoch 909/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4549\n",
      "Epoch 909: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4549 - val_loss: 1.1505\n",
      "Epoch 910/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4529\n",
      "Epoch 910: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.4529 - val_loss: 1.1595\n",
      "Epoch 911/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4532\n",
      "Epoch 911: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.4532 - val_loss: 1.1500\n",
      "Epoch 912/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4530\n",
      "Epoch 912: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4530 - val_loss: 1.1597\n",
      "Epoch 913/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4522\n",
      "Epoch 913: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4522 - val_loss: 1.1501\n",
      "Epoch 914/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4538\n",
      "Epoch 914: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.4538 - val_loss: 1.1609\n",
      "Epoch 915/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4526\n",
      "Epoch 915: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.4526 - val_loss: 1.1489\n",
      "Epoch 916/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4538\n",
      "Epoch 916: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4538 - val_loss: 1.1644\n",
      "Epoch 917/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4549\n",
      "Epoch 917: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4549 - val_loss: 1.1480\n",
      "Epoch 918/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4525\n",
      "Epoch 918: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4525 - val_loss: 1.1566\n",
      "Epoch 919/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4519\n",
      "Epoch 919: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4519 - val_loss: 1.1474\n",
      "Epoch 920/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4529\n",
      "Epoch 920: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.4529 - val_loss: 1.1616\n",
      "Epoch 921/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4524\n",
      "Epoch 921: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4524 - val_loss: 1.1518\n",
      "Epoch 922/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4516\n",
      "Epoch 922: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4516 - val_loss: 1.1589\n",
      "Epoch 923/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4531\n",
      "Epoch 923: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4531 - val_loss: 1.1472\n",
      "Epoch 924/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4539\n",
      "Epoch 924: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4539 - val_loss: 1.1605\n",
      "Epoch 925/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4524\n",
      "Epoch 925: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4524 - val_loss: 1.1460\n",
      "Epoch 926/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4529\n",
      "Epoch 926: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.4529 - val_loss: 1.1612\n",
      "Epoch 927/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4526\n",
      "Epoch 927: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.4526 - val_loss: 1.1473\n",
      "Epoch 928/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4516\n",
      "Epoch 928: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4516 - val_loss: 1.1603\n",
      "Epoch 929/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4515\n",
      "Epoch 929: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.4515 - val_loss: 1.1477\n",
      "Epoch 930/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4518\n",
      "Epoch 930: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4518 - val_loss: 1.1681\n",
      "Epoch 931/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4557\n",
      "Epoch 931: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4557 - val_loss: 1.1496\n",
      "Epoch 932/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4517\n",
      "Epoch 932: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4517 - val_loss: 1.1511\n",
      "Epoch 933/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4504\n",
      "Epoch 933: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4504 - val_loss: 1.1544\n",
      "Epoch 934/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4504\n",
      "Epoch 934: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.4504 - val_loss: 1.1470\n",
      "Epoch 935/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4503\n",
      "Epoch 935: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4503 - val_loss: 1.1546\n",
      "Epoch 936/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4496\n",
      "Epoch 936: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4496 - val_loss: 1.1525\n",
      "Epoch 937/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4492\n",
      "Epoch 937: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.4492 - val_loss: 1.1542\n",
      "Epoch 938/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4495\n",
      "Epoch 938: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.4495 - val_loss: 1.1424\n",
      "Epoch 939/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4530\n",
      "Epoch 939: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4530 - val_loss: 1.1599\n",
      "Epoch 940/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4517\n",
      "Epoch 940: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4517 - val_loss: 1.1444\n",
      "Epoch 941/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4503\n",
      "Epoch 941: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4503 - val_loss: 1.1556\n",
      "Epoch 942/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4501\n",
      "Epoch 942: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4501 - val_loss: 1.1434\n",
      "Epoch 943/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4504\n",
      "Epoch 943: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4504 - val_loss: 1.1564\n",
      "Epoch 944/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4498\n",
      "Epoch 944: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4498 - val_loss: 1.1476\n",
      "Epoch 945/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4491\n",
      "Epoch 945: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4491 - val_loss: 1.1539\n",
      "Epoch 946/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4498\n",
      "Epoch 946: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4498 - val_loss: 1.1501\n",
      "Epoch 947/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4499\n",
      "Epoch 947: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4499 - val_loss: 1.1584\n",
      "Epoch 948/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.4508\n",
      "Epoch 948: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.4508 - val_loss: 1.1416\n",
      "Epoch 949/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4518\n",
      "Epoch 949: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.4518 - val_loss: 1.1623\n",
      "Epoch 950/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4528\n",
      "Epoch 950: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4528 - val_loss: 1.1464\n",
      "Epoch 951/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4479\n",
      "Epoch 951: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4479 - val_loss: 1.1505\n",
      "Epoch 952/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4475\n",
      "Epoch 952: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4475 - val_loss: 1.1463\n",
      "Epoch 953/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4479\n",
      "Epoch 953: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4479 - val_loss: 1.1548\n",
      "Epoch 954/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4479\n",
      "Epoch 954: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4479 - val_loss: 1.1436\n",
      "Epoch 955/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4502\n",
      "Epoch 955: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4502 - val_loss: 1.1560\n",
      "Epoch 956/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4490\n",
      "Epoch 956: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4490 - val_loss: 1.1446\n",
      "Epoch 957/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4482\n",
      "Epoch 957: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4482 - val_loss: 1.1554\n",
      "Epoch 958/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4485\n",
      "Epoch 958: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4485 - val_loss: 1.1435\n",
      "Epoch 959/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4481\n",
      "Epoch 959: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4481 - val_loss: 1.1520\n",
      "Epoch 960/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4468\n",
      "Epoch 960: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4468 - val_loss: 1.1474\n",
      "Epoch 961/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4468\n",
      "Epoch 961: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.4468 - val_loss: 1.1493\n",
      "Epoch 962/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4462\n",
      "Epoch 962: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4462 - val_loss: 1.1431\n",
      "Epoch 963/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4482\n",
      "Epoch 963: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4482 - val_loss: 1.1556\n",
      "Epoch 964/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4481\n",
      "Epoch 964: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4481 - val_loss: 1.1419\n",
      "Epoch 965/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4476\n",
      "Epoch 965: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4476 - val_loss: 1.1550\n",
      "Epoch 966/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4476\n",
      "Epoch 966: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4476 - val_loss: 1.1401\n",
      "Epoch 967/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4516\n",
      "Epoch 967: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4516 - val_loss: 1.1610\n",
      "Epoch 968/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4508\n",
      "Epoch 968: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4508 - val_loss: 1.1446\n",
      "Epoch 969/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4455\n",
      "Epoch 969: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.4455 - val_loss: 1.1522\n",
      "Epoch 970/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4470\n",
      "Epoch 970: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.4470 - val_loss: 1.1441\n",
      "Epoch 971/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4454\n",
      "Epoch 971: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4454 - val_loss: 1.1527\n",
      "Epoch 972/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4459\n",
      "Epoch 972: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4459 - val_loss: 1.1446\n",
      "Epoch 973/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4454\n",
      "Epoch 973: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4454 - val_loss: 1.1503\n",
      "Epoch 974/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4451\n",
      "Epoch 974: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4451 - val_loss: 1.1444\n",
      "Epoch 975/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4461\n",
      "Epoch 975: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4461 - val_loss: 1.1526\n",
      "Epoch 976/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4465\n",
      "Epoch 976: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4465 - val_loss: 1.1407\n",
      "Epoch 977/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4453\n",
      "Epoch 977: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4453 - val_loss: 1.1556\n",
      "Epoch 978/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4469\n",
      "Epoch 978: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4469 - val_loss: 1.1437\n",
      "Epoch 979/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4457\n",
      "Epoch 979: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.4457 - val_loss: 1.1484\n",
      "Epoch 980/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.4448\n",
      "Epoch 980: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4448 - val_loss: 1.1394\n",
      "Epoch 981/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4453\n",
      "Epoch 981: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4453 - val_loss: 1.1574\n",
      "Epoch 982/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4481\n",
      "Epoch 982: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4481 - val_loss: 1.1387\n",
      "Epoch 983/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4473\n",
      "Epoch 983: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4473 - val_loss: 1.1511\n",
      "Epoch 984/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4453\n",
      "Epoch 984: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4453 - val_loss: 1.1378\n",
      "Epoch 985/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4458\n",
      "Epoch 985: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4458 - val_loss: 1.1563\n",
      "Epoch 986/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4473\n",
      "Epoch 986: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4473 - val_loss: 1.1392\n",
      "Epoch 987/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4447\n",
      "Epoch 987: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4447 - val_loss: 1.1493\n",
      "Epoch 988/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4445\n",
      "Epoch 988: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4445 - val_loss: 1.1387\n",
      "Epoch 989/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4440\n",
      "Epoch 989: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.4440 - val_loss: 1.1487\n",
      "Epoch 990/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4439\n",
      "Epoch 990: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4439 - val_loss: 1.1401\n",
      "Epoch 991/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4432\n",
      "Epoch 991: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4432 - val_loss: 1.1492\n",
      "Epoch 992/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4429\n",
      "Epoch 992: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4429 - val_loss: 1.1392\n",
      "Epoch 993/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4459\n",
      "Epoch 993: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4459 - val_loss: 1.1564\n",
      "Epoch 994/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4467\n",
      "Epoch 994: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.4467 - val_loss: 1.1424\n",
      "Epoch 995/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4425\n",
      "Epoch 995: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4425 - val_loss: 1.1429\n",
      "Epoch 996/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4427\n",
      "Epoch 996: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4427 - val_loss: 1.1435\n",
      "Epoch 997/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4422\n",
      "Epoch 997: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4422 - val_loss: 1.1452\n",
      "Epoch 998/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4420\n",
      "Epoch 998: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4420 - val_loss: 1.1397\n",
      "Epoch 999/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4420\n",
      "Epoch 999: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4420 - val_loss: 1.1511\n",
      "Epoch 1000/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4435\n",
      "Epoch 1000: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4435 - val_loss: 1.1384\n",
      "Epoch 1001/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4424\n",
      "Epoch 1001: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.4424 - val_loss: 1.1533\n",
      "Epoch 1002/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4446\n",
      "Epoch 1002: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4446 - val_loss: 1.1385\n",
      "Epoch 1003/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4439\n",
      "Epoch 1003: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4439 - val_loss: 1.1514\n",
      "Epoch 1004/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4432\n",
      "Epoch 1004: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4432 - val_loss: 1.1374\n",
      "Epoch 1005/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4437\n",
      "Epoch 1005: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4437 - val_loss: 1.1521\n",
      "Epoch 1006/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4440\n",
      "Epoch 1006: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4440 - val_loss: 1.1369\n",
      "Epoch 1007/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4413\n",
      "Epoch 1007: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4413 - val_loss: 1.1452\n",
      "Epoch 1008/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4412\n",
      "Epoch 1008: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4412 - val_loss: 1.1366\n",
      "Epoch 1009/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4415\n",
      "Epoch 1009: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.4415 - val_loss: 1.1507\n",
      "Epoch 1010/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.4426\n",
      "Epoch 1010: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.4426 - val_loss: 1.1399\n",
      "Epoch 1011/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4398\n",
      "Epoch 1011: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4398 - val_loss: 1.1479\n",
      "Epoch 1012/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4408\n",
      "Epoch 1012: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4408 - val_loss: 1.1379\n",
      "Epoch 1013/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4410\n",
      "Epoch 1013: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4410 - val_loss: 1.1528\n",
      "Epoch 1014/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4432\n",
      "Epoch 1014: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4432 - val_loss: 1.1376\n",
      "Epoch 1015/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4428\n",
      "Epoch 1015: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4428 - val_loss: 1.1446\n",
      "Epoch 1016/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4406\n",
      "Epoch 1016: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4406 - val_loss: 1.1361\n",
      "Epoch 1017/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4395\n",
      "Epoch 1017: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4395 - val_loss: 1.1485\n",
      "Epoch 1018/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4418\n",
      "Epoch 1018: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4418 - val_loss: 1.1344\n",
      "Epoch 1019/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4412\n",
      "Epoch 1019: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4412 - val_loss: 1.1478\n",
      "Epoch 1020/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4411\n",
      "Epoch 1020: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4411 - val_loss: 1.1356\n",
      "Epoch 1021/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4393\n",
      "Epoch 1021: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4393 - val_loss: 1.1463\n",
      "Epoch 1022/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4401\n",
      "Epoch 1022: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4401 - val_loss: 1.1363\n",
      "Epoch 1023/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4397\n",
      "Epoch 1023: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4397 - val_loss: 1.1460\n",
      "Epoch 1024/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4397\n",
      "Epoch 1024: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4397 - val_loss: 1.1355\n",
      "Epoch 1025/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4394\n",
      "Epoch 1025: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4394 - val_loss: 1.1484\n",
      "Epoch 1026/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4404\n",
      "Epoch 1026: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4404 - val_loss: 1.1365\n",
      "Epoch 1027/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4390\n",
      "Epoch 1027: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.4390 - val_loss: 1.1511\n",
      "Epoch 1028/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4413\n",
      "Epoch 1028: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.4413 - val_loss: 1.1371\n",
      "Epoch 1029/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4389\n",
      "Epoch 1029: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4389 - val_loss: 1.1412\n",
      "Epoch 1030/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4383\n",
      "Epoch 1030: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.4383 - val_loss: 1.1398\n",
      "Epoch 1031/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4374\n",
      "Epoch 1031: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.4374 - val_loss: 1.1407\n",
      "Epoch 1032/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4374\n",
      "Epoch 1032: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4374 - val_loss: 1.1360\n",
      "Epoch 1033/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4370\n",
      "Epoch 1033: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4370 - val_loss: 1.1455\n",
      "Epoch 1034/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4379\n",
      "Epoch 1034: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4379 - val_loss: 1.1342\n",
      "Epoch 1035/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4384\n",
      "Epoch 1035: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4384 - val_loss: 1.1529\n",
      "Epoch 1036/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4423\n",
      "Epoch 1036: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4423 - val_loss: 1.1321\n",
      "Epoch 1037/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4399\n",
      "Epoch 1037: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4399 - val_loss: 1.1494\n",
      "Epoch 1038/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4402\n",
      "Epoch 1038: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4402 - val_loss: 1.1346\n",
      "Epoch 1039/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4362\n",
      "Epoch 1039: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.4362 - val_loss: 1.1397\n",
      "Epoch 1040/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.4358\n",
      "Epoch 1040: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.4358 - val_loss: 1.1356\n",
      "Epoch 1041/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4359\n",
      "Epoch 1041: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4359 - val_loss: 1.1413\n",
      "Epoch 1042/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4373\n",
      "Epoch 1042: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4373 - val_loss: 1.1304\n",
      "Epoch 1043/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4378\n",
      "Epoch 1043: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4378 - val_loss: 1.1417\n",
      "Epoch 1044/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4372\n",
      "Epoch 1044: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4372 - val_loss: 1.1325\n",
      "Epoch 1045/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4356\n",
      "Epoch 1045: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4356 - val_loss: 1.1406\n",
      "Epoch 1046/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4357\n",
      "Epoch 1046: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4357 - val_loss: 1.1326\n",
      "Epoch 1047/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4359\n",
      "Epoch 1047: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4359 - val_loss: 1.1429\n",
      "Epoch 1048/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4370\n",
      "Epoch 1048: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4370 - val_loss: 1.1350\n",
      "Epoch 1049/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4342\n",
      "Epoch 1049: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4342 - val_loss: 1.1380\n",
      "Epoch 1050/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4344\n",
      "Epoch 1050: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4344 - val_loss: 1.1393\n",
      "Epoch 1051/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4350\n",
      "Epoch 1051: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4350 - val_loss: 1.1284\n",
      "Epoch 1052/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4384\n",
      "Epoch 1052: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4384 - val_loss: 1.1511\n",
      "Epoch 1053/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4409\n",
      "Epoch 1053: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4409 - val_loss: 1.1300\n",
      "Epoch 1054/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4372\n",
      "Epoch 1054: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4372 - val_loss: 1.1423\n",
      "Epoch 1055/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4358\n",
      "Epoch 1055: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4358 - val_loss: 1.1315\n",
      "Epoch 1056/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4339\n",
      "Epoch 1056: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4339 - val_loss: 1.1398\n",
      "Epoch 1057/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4340\n",
      "Epoch 1057: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4340 - val_loss: 1.1306\n",
      "Epoch 1058/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4356\n",
      "Epoch 1058: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4356 - val_loss: 1.1436\n",
      "Epoch 1059/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4360\n",
      "Epoch 1059: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.4360 - val_loss: 1.1301\n",
      "Epoch 1060/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4335\n",
      "Epoch 1060: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.4335 - val_loss: 1.1344\n",
      "Epoch 1061/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4326\n",
      "Epoch 1061: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4326 - val_loss: 1.1356\n",
      "Epoch 1062/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4328\n",
      "Epoch 1062: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4328 - val_loss: 1.1299\n",
      "Epoch 1063/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4330\n",
      "Epoch 1063: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4330 - val_loss: 1.1427\n",
      "Epoch 1064/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4353\n",
      "Epoch 1064: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4353 - val_loss: 1.1285\n",
      "Epoch 1065/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4352\n",
      "Epoch 1065: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4352 - val_loss: 1.1434\n",
      "Epoch 1066/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4353\n",
      "Epoch 1066: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4353 - val_loss: 1.1293\n",
      "Epoch 1067/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4344\n",
      "Epoch 1067: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4344 - val_loss: 1.1423\n",
      "Epoch 1068/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4345\n",
      "Epoch 1068: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4345 - val_loss: 1.1307\n",
      "Epoch 1069/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4315\n",
      "Epoch 1069: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.4315 - val_loss: 1.1317\n",
      "Epoch 1070/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4311\n",
      "Epoch 1070: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.4311 - val_loss: 1.1347\n",
      "Epoch 1071/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4310\n",
      "Epoch 1071: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4310 - val_loss: 1.1340\n",
      "Epoch 1072/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4315\n",
      "Epoch 1072: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4315 - val_loss: 1.1333\n",
      "Epoch 1073/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4320\n",
      "Epoch 1073: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4320 - val_loss: 1.1333\n",
      "Epoch 1074/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4307\n",
      "Epoch 1074: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4307 - val_loss: 1.1323\n",
      "Epoch 1075/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4301\n",
      "Epoch 1075: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4301 - val_loss: 1.1259\n",
      "Epoch 1076/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4334\n",
      "Epoch 1076: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4334 - val_loss: 1.1487\n",
      "Epoch 1077/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4387\n",
      "Epoch 1077: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4387 - val_loss: 1.1280\n",
      "Epoch 1078/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4324\n",
      "Epoch 1078: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4324 - val_loss: 1.1382\n",
      "Epoch 1079/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4334\n",
      "Epoch 1079: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4334 - val_loss: 1.1234\n",
      "Epoch 1080/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4326\n",
      "Epoch 1080: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4326 - val_loss: 1.1385\n",
      "Epoch 1081/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4329\n",
      "Epoch 1081: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.4329 - val_loss: 1.1248\n",
      "Epoch 1082/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.4305\n",
      "Epoch 1082: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.4305 - val_loss: 1.1337\n",
      "Epoch 1083/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4306\n",
      "Epoch 1083: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4306 - val_loss: 1.1243\n",
      "Epoch 1084/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4304\n",
      "Epoch 1084: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4304 - val_loss: 1.1335\n",
      "Epoch 1085/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4299\n",
      "Epoch 1085: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4299 - val_loss: 1.1254\n",
      "Epoch 1086/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4308\n",
      "Epoch 1086: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4308 - val_loss: 1.1355\n",
      "Epoch 1087/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4306\n",
      "Epoch 1087: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.4306 - val_loss: 1.1266\n",
      "Epoch 1088/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4291\n",
      "Epoch 1088: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4291 - val_loss: 1.1383\n",
      "Epoch 1089/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4313\n",
      "Epoch 1089: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4313 - val_loss: 1.1267\n",
      "Epoch 1090/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4289\n",
      "Epoch 1090: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4289 - val_loss: 1.1363\n",
      "Epoch 1091/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4297\n",
      "Epoch 1091: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.4297 - val_loss: 1.1254\n",
      "Epoch 1092/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4287\n",
      "Epoch 1092: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.4287 - val_loss: 1.1330\n",
      "Epoch 1093/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4287\n",
      "Epoch 1093: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4287 - val_loss: 1.1260\n",
      "Epoch 1094/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4278\n",
      "Epoch 1094: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4278 - val_loss: 1.1354\n",
      "Epoch 1095/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4289\n",
      "Epoch 1095: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4289 - val_loss: 1.1268\n",
      "Epoch 1096/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4280\n",
      "Epoch 1096: val_loss did not improve from 1.12233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4280 - val_loss: 1.1353\n",
      "Epoch 1097/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4301\n",
      "Epoch 1097: val_loss improved from 1.12233 to 1.12078, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4301 - val_loss: 1.1208\n",
      "Epoch 1098/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4307\n",
      "Epoch 1098: val_loss did not improve from 1.12078\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.4307 - val_loss: 1.1402\n",
      "Epoch 1099/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4321\n",
      "Epoch 1099: val_loss did not improve from 1.12078\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4321 - val_loss: 1.1218\n",
      "Epoch 1100/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4296\n",
      "Epoch 1100: val_loss did not improve from 1.12078\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4296 - val_loss: 1.1340\n",
      "Epoch 1101/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4286\n",
      "Epoch 1101: val_loss did not improve from 1.12078\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4286 - val_loss: 1.1232\n",
      "Epoch 1102/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4264\n",
      "Epoch 1102: val_loss did not improve from 1.12078\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4264 - val_loss: 1.1304\n",
      "Epoch 1103/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4264\n",
      "Epoch 1103: val_loss did not improve from 1.12078\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4264 - val_loss: 1.1225\n",
      "Epoch 1104/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4279\n",
      "Epoch 1104: val_loss did not improve from 1.12078\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4279 - val_loss: 1.1369\n",
      "Epoch 1105/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4299\n",
      "Epoch 1105: val_loss improved from 1.12078 to 1.12059, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4299 - val_loss: 1.1206\n",
      "Epoch 1106/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4288\n",
      "Epoch 1106: val_loss did not improve from 1.12059\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.4288 - val_loss: 1.1362\n",
      "Epoch 1107/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4293\n",
      "Epoch 1107: val_loss did not improve from 1.12059\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.4293 - val_loss: 1.1221\n",
      "Epoch 1108/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4264\n",
      "Epoch 1108: val_loss did not improve from 1.12059\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4264 - val_loss: 1.1330\n",
      "Epoch 1109/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4271\n",
      "Epoch 1109: val_loss did not improve from 1.12059\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4271 - val_loss: 1.1232\n",
      "Epoch 1110/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4259\n",
      "Epoch 1110: val_loss did not improve from 1.12059\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.4259 - val_loss: 1.1338\n",
      "Epoch 1111/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4269\n",
      "Epoch 1111: val_loss did not improve from 1.12059\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.4269 - val_loss: 1.1243\n",
      "Epoch 1112/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4250\n",
      "Epoch 1112: val_loss did not improve from 1.12059\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.4250 - val_loss: 1.1275\n",
      "Epoch 1113/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4249\n",
      "Epoch 1113: val_loss did not improve from 1.12059\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4249 - val_loss: 1.1221\n",
      "Epoch 1114/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4244\n",
      "Epoch 1114: val_loss did not improve from 1.12059\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4244 - val_loss: 1.1264\n",
      "Epoch 1115/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4238\n",
      "Epoch 1115: val_loss did not improve from 1.12059\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4238 - val_loss: 1.1223\n",
      "Epoch 1116/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4249\n",
      "Epoch 1116: val_loss did not improve from 1.12059\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4249 - val_loss: 1.1321\n",
      "Epoch 1117/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4263\n",
      "Epoch 1117: val_loss did not improve from 1.12059\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4263 - val_loss: 1.1207\n",
      "Epoch 1118/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4245\n",
      "Epoch 1118: val_loss did not improve from 1.12059\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.4245 - val_loss: 1.1357\n",
      "Epoch 1119/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.4279\n",
      "Epoch 1119: val_loss improved from 1.12059 to 1.12020, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.4279 - val_loss: 1.1202\n",
      "Epoch 1120/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4277\n",
      "Epoch 1120: val_loss did not improve from 1.12020\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.4277 - val_loss: 1.1344\n",
      "Epoch 1121/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4273\n",
      "Epoch 1121: val_loss did not improve from 1.12020\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4273 - val_loss: 1.1207\n",
      "Epoch 1122/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4257\n",
      "Epoch 1122: val_loss did not improve from 1.12020\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.4257 - val_loss: 1.1330\n",
      "Epoch 1123/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4258\n",
      "Epoch 1123: val_loss did not improve from 1.12020\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4258 - val_loss: 1.1216\n",
      "Epoch 1124/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4236\n",
      "Epoch 1124: val_loss did not improve from 1.12020\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4236 - val_loss: 1.1274\n",
      "Epoch 1125/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4237\n",
      "Epoch 1125: val_loss improved from 1.12020 to 1.11906, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.4237 - val_loss: 1.1191\n",
      "Epoch 1126/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4234\n",
      "Epoch 1126: val_loss did not improve from 1.11906\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.4234 - val_loss: 1.1302\n",
      "Epoch 1127/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4243\n",
      "Epoch 1127: val_loss did not improve from 1.11906\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4243 - val_loss: 1.1195\n",
      "Epoch 1128/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4229\n",
      "Epoch 1128: val_loss did not improve from 1.11906\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4229 - val_loss: 1.1287\n",
      "Epoch 1129/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4228\n",
      "Epoch 1129: val_loss did not improve from 1.11906\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.4228 - val_loss: 1.1208\n",
      "Epoch 1130/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4218\n",
      "Epoch 1130: val_loss did not improve from 1.11906\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4218 - val_loss: 1.1241\n",
      "Epoch 1131/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4217\n",
      "Epoch 1131: val_loss improved from 1.11906 to 1.11868, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.4217 - val_loss: 1.1187\n",
      "Epoch 1132/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4213\n",
      "Epoch 1132: val_loss did not improve from 1.11868\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.4213 - val_loss: 1.1295\n",
      "Epoch 1133/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4233\n",
      "Epoch 1133: val_loss improved from 1.11868 to 1.11686, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.4233 - val_loss: 1.1169\n",
      "Epoch 1134/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4263\n",
      "Epoch 1134: val_loss did not improve from 1.11686\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4263 - val_loss: 1.1336\n",
      "Epoch 1135/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4258\n",
      "Epoch 1135: val_loss improved from 1.11686 to 1.11548, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.4258 - val_loss: 1.1155\n",
      "Epoch 1136/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4244\n",
      "Epoch 1136: val_loss did not improve from 1.11548\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.4244 - val_loss: 1.1305\n",
      "Epoch 1137/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4235\n",
      "Epoch 1137: val_loss did not improve from 1.11548\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.4235 - val_loss: 1.1199\n",
      "Epoch 1138/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.4209\n",
      "Epoch 1138: val_loss did not improve from 1.11548\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.4209 - val_loss: 1.1240\n",
      "Epoch 1139/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4206\n",
      "Epoch 1139: val_loss did not improve from 1.11548\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4206 - val_loss: 1.1197\n",
      "Epoch 1140/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4201\n",
      "Epoch 1140: val_loss did not improve from 1.11548\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.4201 - val_loss: 1.1270\n",
      "Epoch 1141/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4206\n",
      "Epoch 1141: val_loss did not improve from 1.11548\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4206 - val_loss: 1.1190\n",
      "Epoch 1142/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4213\n",
      "Epoch 1142: val_loss did not improve from 1.11548\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4213 - val_loss: 1.1283\n",
      "Epoch 1143/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4230\n",
      "Epoch 1143: val_loss improved from 1.11548 to 1.11368, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.4230 - val_loss: 1.1137\n",
      "Epoch 1144/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4228\n",
      "Epoch 1144: val_loss did not improve from 1.11368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.4228 - val_loss: 1.1313\n",
      "Epoch 1145/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4239\n",
      "Epoch 1145: val_loss did not improve from 1.11368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.4239 - val_loss: 1.1159\n",
      "Epoch 1146/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.4208\n",
      "Epoch 1146: val_loss did not improve from 1.11368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4208 - val_loss: 1.1273\n",
      "Epoch 1147/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4206\n",
      "Epoch 1147: val_loss did not improve from 1.11368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4206 - val_loss: 1.1167\n",
      "Epoch 1148/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4194\n",
      "Epoch 1148: val_loss did not improve from 1.11368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4194 - val_loss: 1.1247\n",
      "Epoch 1149/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4193\n",
      "Epoch 1149: val_loss did not improve from 1.11368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4193 - val_loss: 1.1147\n",
      "Epoch 1150/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4196\n",
      "Epoch 1150: val_loss did not improve from 1.11368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4196 - val_loss: 1.1259\n",
      "Epoch 1151/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4198\n",
      "Epoch 1151: val_loss did not improve from 1.11368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4198 - val_loss: 1.1150\n",
      "Epoch 1152/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4219\n",
      "Epoch 1152: val_loss did not improve from 1.11368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4219 - val_loss: 1.1305\n",
      "Epoch 1153/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4225\n",
      "Epoch 1153: val_loss did not improve from 1.11368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4225 - val_loss: 1.1161\n",
      "Epoch 1154/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4191\n",
      "Epoch 1154: val_loss did not improve from 1.11368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4191 - val_loss: 1.1279\n",
      "Epoch 1155/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4200\n",
      "Epoch 1155: val_loss did not improve from 1.11368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4200 - val_loss: 1.1146\n",
      "Epoch 1156/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4196\n",
      "Epoch 1156: val_loss did not improve from 1.11368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4196 - val_loss: 1.1275\n",
      "Epoch 1157/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4193\n",
      "Epoch 1157: val_loss did not improve from 1.11368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4193 - val_loss: 1.1161\n",
      "Epoch 1158/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4181\n",
      "Epoch 1158: val_loss did not improve from 1.11368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4181 - val_loss: 1.1236\n",
      "Epoch 1159/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4177\n",
      "Epoch 1159: val_loss did not improve from 1.11368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4177 - val_loss: 1.1172\n",
      "Epoch 1160/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4170\n",
      "Epoch 1160: val_loss did not improve from 1.11368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4170 - val_loss: 1.1183\n",
      "Epoch 1161/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4167\n",
      "Epoch 1161: val_loss did not improve from 1.11368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.4167 - val_loss: 1.1201\n",
      "Epoch 1162/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4174\n",
      "Epoch 1162: val_loss did not improve from 1.11368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4174 - val_loss: 1.1192\n",
      "Epoch 1163/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4171\n",
      "Epoch 1163: val_loss did not improve from 1.11368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4171 - val_loss: 1.1218\n",
      "Epoch 1164/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.4171\n",
      "Epoch 1164: val_loss did not improve from 1.11368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.4171 - val_loss: 1.1143\n",
      "Epoch 1165/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4183\n",
      "Epoch 1165: val_loss did not improve from 1.11368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4183 - val_loss: 1.1297\n",
      "Epoch 1166/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4204\n",
      "Epoch 1166: val_loss improved from 1.11368 to 1.11239, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4204 - val_loss: 1.1124\n",
      "Epoch 1167/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4198\n",
      "Epoch 1167: val_loss did not improve from 1.11239\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.4198 - val_loss: 1.1292\n",
      "Epoch 1168/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4193\n",
      "Epoch 1168: val_loss did not improve from 1.11239\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4193 - val_loss: 1.1144\n",
      "Epoch 1169/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4186\n",
      "Epoch 1169: val_loss did not improve from 1.11239\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4186 - val_loss: 1.1252\n",
      "Epoch 1170/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4169\n",
      "Epoch 1170: val_loss did not improve from 1.11239\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4169 - val_loss: 1.1150\n",
      "Epoch 1171/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4162\n",
      "Epoch 1171: val_loss did not improve from 1.11239\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.4162 - val_loss: 1.1234\n",
      "Epoch 1172/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4175\n",
      "Epoch 1172: val_loss did not improve from 1.11239\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4175 - val_loss: 1.1148\n",
      "Epoch 1173/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4144\n",
      "Epoch 1173: val_loss did not improve from 1.11239\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.4144 - val_loss: 1.1198\n",
      "Epoch 1174/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4143\n",
      "Epoch 1174: val_loss did not improve from 1.11239\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.4143 - val_loss: 1.1156\n",
      "Epoch 1175/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4153\n",
      "Epoch 1175: val_loss did not improve from 1.11239\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4153 - val_loss: 1.1251\n",
      "Epoch 1176/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4181\n",
      "Epoch 1176: val_loss improved from 1.11239 to 1.11035, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4181 - val_loss: 1.1104\n",
      "Epoch 1177/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4171\n",
      "Epoch 1177: val_loss did not improve from 1.11035\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.4171 - val_loss: 1.1227\n",
      "Epoch 1178/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4154\n",
      "Epoch 1178: val_loss did not improve from 1.11035\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4154 - val_loss: 1.1113\n",
      "Epoch 1179/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4156\n",
      "Epoch 1179: val_loss did not improve from 1.11035\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4156 - val_loss: 1.1257\n",
      "Epoch 1180/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4167\n",
      "Epoch 1180: val_loss did not improve from 1.11035\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4167 - val_loss: 1.1126\n",
      "Epoch 1181/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4150\n",
      "Epoch 1181: val_loss did not improve from 1.11035\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.4150 - val_loss: 1.1239\n",
      "Epoch 1182/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4152\n",
      "Epoch 1182: val_loss did not improve from 1.11035\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4152 - val_loss: 1.1113\n",
      "Epoch 1183/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4156\n",
      "Epoch 1183: val_loss did not improve from 1.11035\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.4156 - val_loss: 1.1188\n",
      "Epoch 1184/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4129\n",
      "Epoch 1184: val_loss did not improve from 1.11035\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4129 - val_loss: 1.1136\n",
      "Epoch 1185/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4137\n",
      "Epoch 1185: val_loss did not improve from 1.11035\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.4137 - val_loss: 1.1236\n",
      "Epoch 1186/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4164\n",
      "Epoch 1186: val_loss improved from 1.11035 to 1.10883, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4164 - val_loss: 1.1088\n",
      "Epoch 1187/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4167\n",
      "Epoch 1187: val_loss did not improve from 1.10883\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4167 - val_loss: 1.1271\n",
      "Epoch 1188/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4168\n",
      "Epoch 1188: val_loss did not improve from 1.10883\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.4168 - val_loss: 1.1112\n",
      "Epoch 1189/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4143\n",
      "Epoch 1189: val_loss did not improve from 1.10883\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4143 - val_loss: 1.1203\n",
      "Epoch 1190/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4127\n",
      "Epoch 1190: val_loss did not improve from 1.10883\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4127 - val_loss: 1.1123\n",
      "Epoch 1191/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4133\n",
      "Epoch 1191: val_loss did not improve from 1.10883\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.4133 - val_loss: 1.1206\n",
      "Epoch 1192/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4124\n",
      "Epoch 1192: val_loss did not improve from 1.10883\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.4124 - val_loss: 1.1127\n",
      "Epoch 1193/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4118\n",
      "Epoch 1193: val_loss did not improve from 1.10883\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4118 - val_loss: 1.1144\n",
      "Epoch 1194/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4109\n",
      "Epoch 1194: val_loss did not improve from 1.10883\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4109 - val_loss: 1.1112\n",
      "Epoch 1195/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4115\n",
      "Epoch 1195: val_loss did not improve from 1.10883\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.4115 - val_loss: 1.1230\n",
      "Epoch 1196/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4139\n",
      "Epoch 1196: val_loss did not improve from 1.10883\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4139 - val_loss: 1.1122\n",
      "Epoch 1197/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4111\n",
      "Epoch 1197: val_loss did not improve from 1.10883\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4111 - val_loss: 1.1204\n",
      "Epoch 1198/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4134\n",
      "Epoch 1198: val_loss improved from 1.10883 to 1.10654, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.4134 - val_loss: 1.1065\n",
      "Epoch 1199/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4152\n",
      "Epoch 1199: val_loss did not improve from 1.10654\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4152 - val_loss: 1.1258\n",
      "Epoch 1200/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.4154\n",
      "Epoch 1200: val_loss did not improve from 1.10654\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.4154 - val_loss: 1.1095\n",
      "Epoch 1201/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4127\n",
      "Epoch 1201: val_loss did not improve from 1.10654\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4127 - val_loss: 1.1198\n",
      "Epoch 1202/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4111\n",
      "Epoch 1202: val_loss did not improve from 1.10654\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4111 - val_loss: 1.1094\n",
      "Epoch 1203/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4115\n",
      "Epoch 1203: val_loss did not improve from 1.10654\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4115 - val_loss: 1.1243\n",
      "Epoch 1204/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4147\n",
      "Epoch 1204: val_loss did not improve from 1.10654\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4147 - val_loss: 1.1083\n",
      "Epoch 1205/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4125\n",
      "Epoch 1205: val_loss did not improve from 1.10654\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.4125 - val_loss: 1.1213\n",
      "Epoch 1206/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4120\n",
      "Epoch 1206: val_loss did not improve from 1.10654\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.4120 - val_loss: 1.1110\n",
      "Epoch 1207/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.4103\n",
      "Epoch 1207: val_loss did not improve from 1.10654\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.4103 - val_loss: 1.1208\n",
      "Epoch 1208/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4097\n",
      "Epoch 1208: val_loss did not improve from 1.10654\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4097 - val_loss: 1.1164\n",
      "Epoch 1209/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4089\n",
      "Epoch 1209: val_loss did not improve from 1.10654\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4089 - val_loss: 1.1144\n",
      "Epoch 1210/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4085\n",
      "Epoch 1210: val_loss did not improve from 1.10654\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4085 - val_loss: 1.1156\n",
      "Epoch 1211/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4088\n",
      "Epoch 1211: val_loss did not improve from 1.10654\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4088 - val_loss: 1.1091\n",
      "Epoch 1212/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4104\n",
      "Epoch 1212: val_loss did not improve from 1.10654\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4104 - val_loss: 1.1171\n",
      "Epoch 1213/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4087\n",
      "Epoch 1213: val_loss improved from 1.10654 to 1.10624, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4087 - val_loss: 1.1062\n",
      "Epoch 1214/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4107\n",
      "Epoch 1214: val_loss did not improve from 1.10624\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.4107 - val_loss: 1.1202\n",
      "Epoch 1215/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4118\n",
      "Epoch 1215: val_loss did not improve from 1.10624\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4118 - val_loss: 1.1073\n",
      "Epoch 1216/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4107\n",
      "Epoch 1216: val_loss did not improve from 1.10624\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4107 - val_loss: 1.1231\n",
      "Epoch 1217/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4131\n",
      "Epoch 1217: val_loss did not improve from 1.10624\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.4131 - val_loss: 1.1088\n",
      "Epoch 1218/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4100\n",
      "Epoch 1218: val_loss did not improve from 1.10624\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.4100 - val_loss: 1.1219\n",
      "Epoch 1219/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4103\n",
      "Epoch 1219: val_loss did not improve from 1.10624\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4103 - val_loss: 1.1108\n",
      "Epoch 1220/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4088\n",
      "Epoch 1220: val_loss did not improve from 1.10624\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4088 - val_loss: 1.1173\n",
      "Epoch 1221/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4087\n",
      "Epoch 1221: val_loss did not improve from 1.10624\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.4087 - val_loss: 1.1098\n",
      "Epoch 1222/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4072\n",
      "Epoch 1222: val_loss did not improve from 1.10624\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4072 - val_loss: 1.1172\n",
      "Epoch 1223/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4071\n",
      "Epoch 1223: val_loss did not improve from 1.10624\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4071 - val_loss: 1.1081\n",
      "Epoch 1224/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4073\n",
      "Epoch 1224: val_loss did not improve from 1.10624\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4073 - val_loss: 1.1190\n",
      "Epoch 1225/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4076\n",
      "Epoch 1225: val_loss did not improve from 1.10624\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4076 - val_loss: 1.1099\n",
      "Epoch 1226/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4069\n",
      "Epoch 1226: val_loss did not improve from 1.10624\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.4069 - val_loss: 1.1137\n",
      "Epoch 1227/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4062\n",
      "Epoch 1227: val_loss did not improve from 1.10624\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.4062 - val_loss: 1.1080\n",
      "Epoch 1228/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4061\n",
      "Epoch 1228: val_loss did not improve from 1.10624\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4061 - val_loss: 1.1213\n",
      "Epoch 1229/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4101\n",
      "Epoch 1229: val_loss improved from 1.10624 to 1.10575, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4101 - val_loss: 1.1058\n",
      "Epoch 1230/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4094\n",
      "Epoch 1230: val_loss did not improve from 1.10575\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.4094 - val_loss: 1.1203\n",
      "Epoch 1231/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4098\n",
      "Epoch 1231: val_loss did not improve from 1.10575\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.4098 - val_loss: 1.1084\n",
      "Epoch 1232/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4073\n",
      "Epoch 1232: val_loss did not improve from 1.10575\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4073 - val_loss: 1.1203\n",
      "Epoch 1233/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4078\n",
      "Epoch 1233: val_loss did not improve from 1.10575\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4078 - val_loss: 1.1074\n",
      "Epoch 1234/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4070\n",
      "Epoch 1234: val_loss did not improve from 1.10575\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4070 - val_loss: 1.1145\n",
      "Epoch 1235/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4048\n",
      "Epoch 1235: val_loss did not improve from 1.10575\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4048 - val_loss: 1.1093\n",
      "Epoch 1236/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4057\n",
      "Epoch 1236: val_loss did not improve from 1.10575\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4057 - val_loss: 1.1131\n",
      "Epoch 1237/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4050\n",
      "Epoch 1237: val_loss did not improve from 1.10575\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4050 - val_loss: 1.1095\n",
      "Epoch 1238/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4037\n",
      "Epoch 1238: val_loss did not improve from 1.10575\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4037 - val_loss: 1.1074\n",
      "Epoch 1239/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4034\n",
      "Epoch 1239: val_loss did not improve from 1.10575\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4034 - val_loss: 1.1151\n",
      "Epoch 1240/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4058\n",
      "Epoch 1240: val_loss improved from 1.10575 to 1.10180, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4058 - val_loss: 1.1018\n",
      "Epoch 1241/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4087\n",
      "Epoch 1241: val_loss did not improve from 1.10180\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.4087 - val_loss: 1.1165\n",
      "Epoch 1242/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4067\n",
      "Epoch 1242: val_loss improved from 1.10180 to 1.10171, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.4067 - val_loss: 1.1017\n",
      "Epoch 1243/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.4079\n",
      "Epoch 1243: val_loss did not improve from 1.10171\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.4079 - val_loss: 1.1150\n",
      "Epoch 1244/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4053\n",
      "Epoch 1244: val_loss did not improve from 1.10171\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4053 - val_loss: 1.1042\n",
      "Epoch 1245/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4064\n",
      "Epoch 1245: val_loss did not improve from 1.10171\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.4064 - val_loss: 1.1154\n",
      "Epoch 1246/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4042\n",
      "Epoch 1246: val_loss did not improve from 1.10171\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4042 - val_loss: 1.1064\n",
      "Epoch 1247/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4045\n",
      "Epoch 1247: val_loss did not improve from 1.10171\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4045 - val_loss: 1.1111\n",
      "Epoch 1248/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4029\n",
      "Epoch 1248: val_loss did not improve from 1.10171\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4029 - val_loss: 1.1048\n",
      "Epoch 1249/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4027\n",
      "Epoch 1249: val_loss did not improve from 1.10171\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4027 - val_loss: 1.1134\n",
      "Epoch 1250/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4061\n",
      "Epoch 1250: val_loss improved from 1.10171 to 1.10014, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4061 - val_loss: 1.1001\n",
      "Epoch 1251/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4059\n",
      "Epoch 1251: val_loss did not improve from 1.10014\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.4059 - val_loss: 1.1142\n",
      "Epoch 1252/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.4054\n",
      "Epoch 1252: val_loss did not improve from 1.10014\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.4054 - val_loss: 1.1003\n",
      "Epoch 1253/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4042\n",
      "Epoch 1253: val_loss did not improve from 1.10014\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.4042 - val_loss: 1.1133\n",
      "Epoch 1254/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4043\n",
      "Epoch 1254: val_loss did not improve from 1.10014\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4043 - val_loss: 1.1031\n",
      "Epoch 1255/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4019\n",
      "Epoch 1255: val_loss did not improve from 1.10014\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.4019 - val_loss: 1.1120\n",
      "Epoch 1256/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4026\n",
      "Epoch 1256: val_loss did not improve from 1.10014\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4026 - val_loss: 1.1011\n",
      "Epoch 1257/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4032\n",
      "Epoch 1257: val_loss did not improve from 1.10014\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4032 - val_loss: 1.1139\n",
      "Epoch 1258/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4038\n",
      "Epoch 1258: val_loss did not improve from 1.10014\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.4038 - val_loss: 1.1038\n",
      "Epoch 1259/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4010\n",
      "Epoch 1259: val_loss did not improve from 1.10014\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4010 - val_loss: 1.1068\n",
      "Epoch 1260/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4008\n",
      "Epoch 1260: val_loss did not improve from 1.10014\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4008 - val_loss: 1.1039\n",
      "Epoch 1261/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3998\n",
      "Epoch 1261: val_loss did not improve from 1.10014\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3998 - val_loss: 1.1093\n",
      "Epoch 1262/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4002\n",
      "Epoch 1262: val_loss improved from 1.10014 to 1.09925, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4002 - val_loss: 1.0992\n",
      "Epoch 1263/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4028\n",
      "Epoch 1263: val_loss did not improve from 1.09925\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.4028 - val_loss: 1.1120\n",
      "Epoch 1264/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4029\n",
      "Epoch 1264: val_loss improved from 1.09925 to 1.09822, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.4029 - val_loss: 1.0982\n",
      "Epoch 1265/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4036\n",
      "Epoch 1265: val_loss did not improve from 1.09822\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.4036 - val_loss: 1.1109\n",
      "Epoch 1266/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4016\n",
      "Epoch 1266: val_loss did not improve from 1.09822\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4016 - val_loss: 1.0987\n",
      "Epoch 1267/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4017\n",
      "Epoch 1267: val_loss did not improve from 1.09822\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4017 - val_loss: 1.1090\n",
      "Epoch 1268/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4003\n",
      "Epoch 1268: val_loss did not improve from 1.09822\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.4003 - val_loss: 1.1014\n",
      "Epoch 1269/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3997\n",
      "Epoch 1269: val_loss did not improve from 1.09822\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3997 - val_loss: 1.1073\n",
      "Epoch 1270/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4002\n",
      "Epoch 1270: val_loss did not improve from 1.09822\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4002 - val_loss: 1.1000\n",
      "Epoch 1271/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3992\n",
      "Epoch 1271: val_loss did not improve from 1.09822\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3992 - val_loss: 1.1038\n",
      "Epoch 1272/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3988\n",
      "Epoch 1272: val_loss did not improve from 1.09822\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3988 - val_loss: 1.1047\n",
      "Epoch 1273/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3983\n",
      "Epoch 1273: val_loss did not improve from 1.09822\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3983 - val_loss: 1.1001\n",
      "Epoch 1274/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3980\n",
      "Epoch 1274: val_loss did not improve from 1.09822\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3980 - val_loss: 1.1106\n",
      "Epoch 1275/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4012\n",
      "Epoch 1275: val_loss improved from 1.09822 to 1.09782, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4012 - val_loss: 1.0978\n",
      "Epoch 1276/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4002\n",
      "Epoch 1276: val_loss did not improve from 1.09782\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.4002 - val_loss: 1.1137\n",
      "Epoch 1277/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4038\n",
      "Epoch 1277: val_loss did not improve from 1.09782\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.4038 - val_loss: 1.0982\n",
      "Epoch 1278/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4015\n",
      "Epoch 1278: val_loss did not improve from 1.09782\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4015 - val_loss: 1.1116\n",
      "Epoch 1279/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4015\n",
      "Epoch 1279: val_loss did not improve from 1.09782\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4015 - val_loss: 1.1008\n",
      "Epoch 1280/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3974\n",
      "Epoch 1280: val_loss did not improve from 1.09782\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3974 - val_loss: 1.1065\n",
      "Epoch 1281/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3989\n",
      "Epoch 1281: val_loss improved from 1.09782 to 1.09780, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3989 - val_loss: 1.0978\n",
      "Epoch 1282/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3974\n",
      "Epoch 1282: val_loss did not improve from 1.09780\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3974 - val_loss: 1.1066\n",
      "Epoch 1283/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3978\n",
      "Epoch 1283: val_loss improved from 1.09780 to 1.09593, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3978 - val_loss: 1.0959\n",
      "Epoch 1284/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3992\n",
      "Epoch 1284: val_loss did not improve from 1.09593\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3992 - val_loss: 1.1102\n",
      "Epoch 1285/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4000\n",
      "Epoch 1285: val_loss did not improve from 1.09593\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.4000 - val_loss: 1.1002\n",
      "Epoch 1286/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3961\n",
      "Epoch 1286: val_loss did not improve from 1.09593\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3961 - val_loss: 1.1054\n",
      "Epoch 1287/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3956\n",
      "Epoch 1287: val_loss did not improve from 1.09593\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3956 - val_loss: 1.1070\n",
      "Epoch 1288/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3960\n",
      "Epoch 1288: val_loss did not improve from 1.09593\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3960 - val_loss: 1.1031\n",
      "Epoch 1289/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3949\n",
      "Epoch 1289: val_loss did not improve from 1.09593\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3949 - val_loss: 1.1061\n",
      "Epoch 1290/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3965\n",
      "Epoch 1290: val_loss did not improve from 1.09593\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3965 - val_loss: 1.1011\n",
      "Epoch 1291/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3970\n",
      "Epoch 1291: val_loss did not improve from 1.09593\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3970 - val_loss: 1.1114\n",
      "Epoch 1292/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3995\n",
      "Epoch 1292: val_loss did not improve from 1.09593\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.3995 - val_loss: 1.0970\n",
      "Epoch 1293/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3983\n",
      "Epoch 1293: val_loss did not improve from 1.09593\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.3983 - val_loss: 1.1039\n",
      "Epoch 1294/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3944\n",
      "Epoch 1294: val_loss improved from 1.09593 to 1.09571, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3944 - val_loss: 1.0957\n",
      "Epoch 1295/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3976\n",
      "Epoch 1295: val_loss did not improve from 1.09571\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3976 - val_loss: 1.1122\n",
      "Epoch 1296/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3997\n",
      "Epoch 1296: val_loss did not improve from 1.09571\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3997 - val_loss: 1.0980\n",
      "Epoch 1297/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3959\n",
      "Epoch 1297: val_loss did not improve from 1.09571\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3959 - val_loss: 1.1060\n",
      "Epoch 1298/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3958\n",
      "Epoch 1298: val_loss improved from 1.09571 to 1.09534, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3958 - val_loss: 1.0953\n",
      "Epoch 1299/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3974\n",
      "Epoch 1299: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3974 - val_loss: 1.1111\n",
      "Epoch 1300/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3993\n",
      "Epoch 1300: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3993 - val_loss: 1.0988\n",
      "Epoch 1301/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3964\n",
      "Epoch 1301: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3964 - val_loss: 1.1130\n",
      "Epoch 1302/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3987\n",
      "Epoch 1302: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3987 - val_loss: 1.0999\n",
      "Epoch 1303/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3943\n",
      "Epoch 1303: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3943 - val_loss: 1.1039\n",
      "Epoch 1304/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3934\n",
      "Epoch 1304: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3934 - val_loss: 1.1080\n",
      "Epoch 1305/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3948\n",
      "Epoch 1305: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3948 - val_loss: 1.0979\n",
      "Epoch 1306/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3956\n",
      "Epoch 1306: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3956 - val_loss: 1.1078\n",
      "Epoch 1307/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3936\n",
      "Epoch 1307: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3936 - val_loss: 1.0989\n",
      "Epoch 1308/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3959\n",
      "Epoch 1308: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3959 - val_loss: 1.1151\n",
      "Epoch 1309/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3989\n",
      "Epoch 1309: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3989 - val_loss: 1.1009\n",
      "Epoch 1310/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3936\n",
      "Epoch 1310: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3936 - val_loss: 1.1065\n",
      "Epoch 1311/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3933\n",
      "Epoch 1311: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3933 - val_loss: 1.1051\n",
      "Epoch 1312/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3925\n",
      "Epoch 1312: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3925 - val_loss: 1.1020\n",
      "Epoch 1313/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3913\n",
      "Epoch 1313: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3913 - val_loss: 1.1089\n",
      "Epoch 1314/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3919\n",
      "Epoch 1314: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3919 - val_loss: 1.1006\n",
      "Epoch 1315/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3950\n",
      "Epoch 1315: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3950 - val_loss: 1.1180\n",
      "Epoch 1316/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4005\n",
      "Epoch 1316: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4005 - val_loss: 1.1012\n",
      "Epoch 1317/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3931\n",
      "Epoch 1317: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3931 - val_loss: 1.1097\n",
      "Epoch 1318/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3933\n",
      "Epoch 1318: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3933 - val_loss: 1.1005\n",
      "Epoch 1319/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3926\n",
      "Epoch 1319: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3926 - val_loss: 1.1134\n",
      "Epoch 1320/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3966\n",
      "Epoch 1320: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3966 - val_loss: 1.1014\n",
      "Epoch 1321/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3914\n",
      "Epoch 1321: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3914 - val_loss: 1.1094\n",
      "Epoch 1322/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3918\n",
      "Epoch 1322: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3918 - val_loss: 1.1011\n",
      "Epoch 1323/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3922\n",
      "Epoch 1323: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3922 - val_loss: 1.1130\n",
      "Epoch 1324/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3954\n",
      "Epoch 1324: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3954 - val_loss: 1.1010\n",
      "Epoch 1325/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3915\n",
      "Epoch 1325: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3915 - val_loss: 1.1121\n",
      "Epoch 1326/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3941\n",
      "Epoch 1326: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3941 - val_loss: 1.1032\n",
      "Epoch 1327/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3902\n",
      "Epoch 1327: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3902 - val_loss: 1.1070\n",
      "Epoch 1328/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3916\n",
      "Epoch 1328: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3916 - val_loss: 1.1074\n",
      "Epoch 1329/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3893\n",
      "Epoch 1329: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3893 - val_loss: 1.1054\n",
      "Epoch 1330/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.3898\n",
      "Epoch 1330: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.3898 - val_loss: 1.1089\n",
      "Epoch 1331/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3906\n",
      "Epoch 1331: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3906 - val_loss: 1.1063\n",
      "Epoch 1332/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3918\n",
      "Epoch 1332: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3918 - val_loss: 1.1104\n",
      "Epoch 1333/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3906\n",
      "Epoch 1333: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3906 - val_loss: 1.1002\n",
      "Epoch 1334/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3947\n",
      "Epoch 1334: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3947 - val_loss: 1.1191\n",
      "Epoch 1335/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3983\n",
      "Epoch 1335: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3983 - val_loss: 1.1023\n",
      "Epoch 1336/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3903\n",
      "Epoch 1336: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3903 - val_loss: 1.1145\n",
      "Epoch 1337/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3935\n",
      "Epoch 1337: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3935 - val_loss: 1.1033\n",
      "Epoch 1338/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3899\n",
      "Epoch 1338: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3899 - val_loss: 1.1141\n",
      "Epoch 1339/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3923\n",
      "Epoch 1339: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3923 - val_loss: 1.1036\n",
      "Epoch 1340/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3893\n",
      "Epoch 1340: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3893 - val_loss: 1.1130\n",
      "Epoch 1341/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3906\n",
      "Epoch 1341: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3906 - val_loss: 1.1055\n",
      "Epoch 1342/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3884\n",
      "Epoch 1342: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3884 - val_loss: 1.1126\n",
      "Epoch 1343/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3926\n",
      "Epoch 1343: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3926 - val_loss: 1.1009\n",
      "Epoch 1344/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3899\n",
      "Epoch 1344: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3899 - val_loss: 1.1121\n",
      "Epoch 1345/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3913\n",
      "Epoch 1345: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3913 - val_loss: 1.1014\n",
      "Epoch 1346/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3893\n",
      "Epoch 1346: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3893 - val_loss: 1.1148\n",
      "Epoch 1347/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3933\n",
      "Epoch 1347: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3933 - val_loss: 1.1043\n",
      "Epoch 1348/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3874\n",
      "Epoch 1348: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3874 - val_loss: 1.1081\n",
      "Epoch 1349/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3877\n",
      "Epoch 1349: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3877 - val_loss: 1.1130\n",
      "Epoch 1350/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3896\n",
      "Epoch 1350: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3896 - val_loss: 1.1027\n",
      "Epoch 1351/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3889\n",
      "Epoch 1351: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3889 - val_loss: 1.1129\n",
      "Epoch 1352/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3887\n",
      "Epoch 1352: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3887 - val_loss: 1.1028\n",
      "Epoch 1353/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3918\n",
      "Epoch 1353: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3918 - val_loss: 1.1182\n",
      "Epoch 1354/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3932\n",
      "Epoch 1354: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3932 - val_loss: 1.1036\n",
      "Epoch 1355/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3882\n",
      "Epoch 1355: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3882 - val_loss: 1.1160\n",
      "Epoch 1356/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3909\n",
      "Epoch 1356: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3909 - val_loss: 1.1047\n",
      "Epoch 1357/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.3877\n",
      "Epoch 1357: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3877 - val_loss: 1.1157\n",
      "Epoch 1358/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3897\n",
      "Epoch 1358: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3897 - val_loss: 1.1050\n",
      "Epoch 1359/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3872\n",
      "Epoch 1359: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3872 - val_loss: 1.1149\n",
      "Epoch 1360/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3887\n",
      "Epoch 1360: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3887 - val_loss: 1.1062\n",
      "Epoch 1361/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3863\n",
      "Epoch 1361: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3863 - val_loss: 1.1166\n",
      "Epoch 1362/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3893\n",
      "Epoch 1362: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3893 - val_loss: 1.1067\n",
      "Epoch 1363/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3873\n",
      "Epoch 1363: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3873 - val_loss: 1.1150\n",
      "Epoch 1364/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3904\n",
      "Epoch 1364: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3904 - val_loss: 1.1037\n",
      "Epoch 1365/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3858\n",
      "Epoch 1365: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3858 - val_loss: 1.1131\n",
      "Epoch 1366/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3879\n",
      "Epoch 1366: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3879 - val_loss: 1.1035\n",
      "Epoch 1367/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3869\n",
      "Epoch 1367: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3869 - val_loss: 1.1182\n",
      "Epoch 1368/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3922\n",
      "Epoch 1368: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3922 - val_loss: 1.1031\n",
      "Epoch 1369/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3864\n",
      "Epoch 1369: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3864 - val_loss: 1.1140\n",
      "Epoch 1370/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3886\n",
      "Epoch 1370: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3886 - val_loss: 1.1067\n",
      "Epoch 1371/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3853\n",
      "Epoch 1371: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3853 - val_loss: 1.1117\n",
      "Epoch 1372/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3843\n",
      "Epoch 1372: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3843 - val_loss: 1.1044\n",
      "Epoch 1373/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3861\n",
      "Epoch 1373: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.3861 - val_loss: 1.1180\n",
      "Epoch 1374/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3902\n",
      "Epoch 1374: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3902 - val_loss: 1.1047\n",
      "Epoch 1375/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3859\n",
      "Epoch 1375: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3859 - val_loss: 1.1172\n",
      "Epoch 1376/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3896\n",
      "Epoch 1376: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3896 - val_loss: 1.1049\n",
      "Epoch 1377/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3844\n",
      "Epoch 1377: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3844 - val_loss: 1.1132\n",
      "Epoch 1378/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3854\n",
      "Epoch 1378: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3854 - val_loss: 1.1069\n",
      "Epoch 1379/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3838\n",
      "Epoch 1379: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3838 - val_loss: 1.1189\n",
      "Epoch 1380/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3890\n",
      "Epoch 1380: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3890 - val_loss: 1.1062\n",
      "Epoch 1381/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3862\n",
      "Epoch 1381: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3862 - val_loss: 1.1201\n",
      "Epoch 1382/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3910\n",
      "Epoch 1382: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3910 - val_loss: 1.1059\n",
      "Epoch 1383/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3845\n",
      "Epoch 1383: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.3845 - val_loss: 1.1156\n",
      "Epoch 1384/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.3859\n",
      "Epoch 1384: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3859 - val_loss: 1.1084\n",
      "Epoch 1385/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3827\n",
      "Epoch 1385: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3827 - val_loss: 1.1169\n",
      "Epoch 1386/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3861\n",
      "Epoch 1386: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3861 - val_loss: 1.1082\n",
      "Epoch 1387/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3844\n",
      "Epoch 1387: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3844 - val_loss: 1.1172\n",
      "Epoch 1388/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3880\n",
      "Epoch 1388: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3880 - val_loss: 1.1061\n",
      "Epoch 1389/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3830\n",
      "Epoch 1389: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3830 - val_loss: 1.1130\n",
      "Epoch 1390/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3822\n",
      "Epoch 1390: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3822 - val_loss: 1.1084\n",
      "Epoch 1391/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3846\n",
      "Epoch 1391: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3846 - val_loss: 1.1127\n",
      "Epoch 1392/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3835\n",
      "Epoch 1392: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3835 - val_loss: 1.1092\n",
      "Epoch 1393/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3818\n",
      "Epoch 1393: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3818 - val_loss: 1.1176\n",
      "Epoch 1394/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3852\n",
      "Epoch 1394: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3852 - val_loss: 1.1052\n",
      "Epoch 1395/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3895\n",
      "Epoch 1395: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3895 - val_loss: 1.1189\n",
      "Epoch 1396/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3876\n",
      "Epoch 1396: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.3876 - val_loss: 1.1048\n",
      "Epoch 1397/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3842\n",
      "Epoch 1397: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3842 - val_loss: 1.1181\n",
      "Epoch 1398/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3872\n",
      "Epoch 1398: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3872 - val_loss: 1.1061\n",
      "Epoch 1399/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3828\n",
      "Epoch 1399: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3828 - val_loss: 1.1185\n",
      "Epoch 1400/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3861\n",
      "Epoch 1400: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3861 - val_loss: 1.1080\n",
      "Epoch 1401/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3831\n",
      "Epoch 1401: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3831 - val_loss: 1.1201\n",
      "Epoch 1402/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3867\n",
      "Epoch 1402: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3867 - val_loss: 1.1070\n",
      "Epoch 1403/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3821\n",
      "Epoch 1403: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3821 - val_loss: 1.1172\n",
      "Epoch 1404/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3841\n",
      "Epoch 1404: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3841 - val_loss: 1.1095\n",
      "Epoch 1405/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3816\n",
      "Epoch 1405: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.3816 - val_loss: 1.1160\n",
      "Epoch 1406/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3841\n",
      "Epoch 1406: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3841 - val_loss: 1.1055\n",
      "Epoch 1407/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3828\n",
      "Epoch 1407: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3828 - val_loss: 1.1138\n",
      "Epoch 1408/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3819\n",
      "Epoch 1408: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3819 - val_loss: 1.1038\n",
      "Epoch 1409/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3833\n",
      "Epoch 1409: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3833 - val_loss: 1.1162\n",
      "Epoch 1410/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3850\n",
      "Epoch 1410: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3850 - val_loss: 1.1047\n",
      "Epoch 1411/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3833\n",
      "Epoch 1411: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3833 - val_loss: 1.1177\n",
      "Epoch 1412/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3853\n",
      "Epoch 1412: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3853 - val_loss: 1.1069\n",
      "Epoch 1413/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3819\n",
      "Epoch 1413: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3819 - val_loss: 1.1172\n",
      "Epoch 1414/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3844\n",
      "Epoch 1414: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3844 - val_loss: 1.1066\n",
      "Epoch 1415/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3815\n",
      "Epoch 1415: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3815 - val_loss: 1.1220\n",
      "Epoch 1416/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3888\n",
      "Epoch 1416: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3888 - val_loss: 1.1064\n",
      "Epoch 1417/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3800\n",
      "Epoch 1417: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3800 - val_loss: 1.1151\n",
      "Epoch 1418/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3814\n",
      "Epoch 1418: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3814 - val_loss: 1.1073\n",
      "Epoch 1419/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3796\n",
      "Epoch 1419: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3796 - val_loss: 1.1184\n",
      "Epoch 1420/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3840\n",
      "Epoch 1420: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3840 - val_loss: 1.1088\n",
      "Epoch 1421/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3795\n",
      "Epoch 1421: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.3795 - val_loss: 1.1196\n",
      "Epoch 1422/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3838\n",
      "Epoch 1422: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3838 - val_loss: 1.1103\n",
      "Epoch 1423/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3807\n",
      "Epoch 1423: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3807 - val_loss: 1.1242\n",
      "Epoch 1424/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3888\n",
      "Epoch 1424: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.3888 - val_loss: 1.1096\n",
      "Epoch 1425/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3790\n",
      "Epoch 1425: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3790 - val_loss: 1.1194\n",
      "Epoch 1426/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3824\n",
      "Epoch 1426: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3824 - val_loss: 1.1104\n",
      "Epoch 1427/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3788\n",
      "Epoch 1427: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3788 - val_loss: 1.1204\n",
      "Epoch 1428/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3824\n",
      "Epoch 1428: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3824 - val_loss: 1.1114\n",
      "Epoch 1429/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3792\n",
      "Epoch 1429: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3792 - val_loss: 1.1220\n",
      "Epoch 1430/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3879\n",
      "Epoch 1430: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3879 - val_loss: 1.1107\n",
      "Epoch 1431/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3780\n",
      "Epoch 1431: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3780 - val_loss: 1.1172\n",
      "Epoch 1432/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3817\n",
      "Epoch 1432: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3817 - val_loss: 1.1075\n",
      "Epoch 1433/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.3806\n",
      "Epoch 1433: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3806 - val_loss: 1.1210\n",
      "Epoch 1434/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3860\n",
      "Epoch 1434: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3860 - val_loss: 1.1066\n",
      "Epoch 1435/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3784\n",
      "Epoch 1435: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3784 - val_loss: 1.1134\n",
      "Epoch 1436/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3780\n",
      "Epoch 1436: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3780 - val_loss: 1.1087\n",
      "Epoch 1437/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3782\n",
      "Epoch 1437: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3782 - val_loss: 1.1130\n",
      "Epoch 1438/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3779\n",
      "Epoch 1438: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3779 - val_loss: 1.1154\n",
      "Epoch 1439/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3794\n",
      "Epoch 1439: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3794 - val_loss: 1.1079\n",
      "Epoch 1440/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3791\n",
      "Epoch 1440: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3791 - val_loss: 1.1232\n",
      "Epoch 1441/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3856\n",
      "Epoch 1441: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3856 - val_loss: 1.1095\n",
      "Epoch 1442/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3777\n",
      "Epoch 1442: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3777 - val_loss: 1.1197\n",
      "Epoch 1443/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3816\n",
      "Epoch 1443: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3816 - val_loss: 1.1095\n",
      "Epoch 1444/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3788\n",
      "Epoch 1444: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3788 - val_loss: 1.1240\n",
      "Epoch 1445/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3849\n",
      "Epoch 1445: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3849 - val_loss: 1.1089\n",
      "Epoch 1446/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3778\n",
      "Epoch 1446: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3778 - val_loss: 1.1220\n",
      "Epoch 1447/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3831\n",
      "Epoch 1447: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3831 - val_loss: 1.1108\n",
      "Epoch 1448/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3767\n",
      "Epoch 1448: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.3767 - val_loss: 1.1185\n",
      "Epoch 1449/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3796\n",
      "Epoch 1449: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3796 - val_loss: 1.1101\n",
      "Epoch 1450/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3769\n",
      "Epoch 1450: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3769 - val_loss: 1.1137\n",
      "Epoch 1451/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3792\n",
      "Epoch 1451: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3792 - val_loss: 1.1100\n",
      "Epoch 1452/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3782\n",
      "Epoch 1452: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3782 - val_loss: 1.1271\n",
      "Epoch 1453/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3883\n",
      "Epoch 1453: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3883 - val_loss: 1.1098\n",
      "Epoch 1454/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3759\n",
      "Epoch 1454: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3759 - val_loss: 1.1163\n",
      "Epoch 1455/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3778\n",
      "Epoch 1455: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3778 - val_loss: 1.1112\n",
      "Epoch 1456/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3763\n",
      "Epoch 1456: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3763 - val_loss: 1.1092\n",
      "Epoch 1457/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3783\n",
      "Epoch 1457: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3783 - val_loss: 1.1236\n",
      "Epoch 1458/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3825\n",
      "Epoch 1458: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3825 - val_loss: 1.1118\n",
      "Epoch 1459/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3766\n",
      "Epoch 1459: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3766 - val_loss: 1.1212\n",
      "Epoch 1460/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.3839\n",
      "Epoch 1460: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.3839 - val_loss: 1.1097\n",
      "Epoch 1461/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3769\n",
      "Epoch 1461: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3769 - val_loss: 1.1206\n",
      "Epoch 1462/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3806\n",
      "Epoch 1462: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3806 - val_loss: 1.1103\n",
      "Epoch 1463/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3758\n",
      "Epoch 1463: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3758 - val_loss: 1.1157\n",
      "Epoch 1464/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3791\n",
      "Epoch 1464: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3791 - val_loss: 1.1095\n",
      "Epoch 1465/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3770\n",
      "Epoch 1465: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3770 - val_loss: 1.1214\n",
      "Epoch 1466/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3806\n",
      "Epoch 1466: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3806 - val_loss: 1.1105\n",
      "Epoch 1467/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3785\n",
      "Epoch 1467: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3785 - val_loss: 1.1246\n",
      "Epoch 1468/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3827\n",
      "Epoch 1468: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3827 - val_loss: 1.1120\n",
      "Epoch 1469/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3753\n",
      "Epoch 1469: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3753 - val_loss: 1.1126\n",
      "Epoch 1470/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3764\n",
      "Epoch 1470: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3764 - val_loss: 1.1098\n",
      "Epoch 1471/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.3762\n",
      "Epoch 1471: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3762 - val_loss: 1.1257\n",
      "Epoch 1472/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3843\n",
      "Epoch 1472: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3843 - val_loss: 1.1112\n",
      "Epoch 1473/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3755\n",
      "Epoch 1473: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3755 - val_loss: 1.1191\n",
      "Epoch 1474/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3780\n",
      "Epoch 1474: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3780 - val_loss: 1.1097\n",
      "Epoch 1475/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3773\n",
      "Epoch 1475: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3773 - val_loss: 1.1225\n",
      "Epoch 1476/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3810\n",
      "Epoch 1476: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3810 - val_loss: 1.1104\n",
      "Epoch 1477/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3754\n",
      "Epoch 1477: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3754 - val_loss: 1.1234\n",
      "Epoch 1478/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3818\n",
      "Epoch 1478: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3818 - val_loss: 1.1107\n",
      "Epoch 1479/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3756\n",
      "Epoch 1479: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3756 - val_loss: 1.1238\n",
      "Epoch 1480/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3818\n",
      "Epoch 1480: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3818 - val_loss: 1.1125\n",
      "Epoch 1481/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3750\n",
      "Epoch 1481: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3750 - val_loss: 1.1142\n",
      "Epoch 1482/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3773\n",
      "Epoch 1482: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3773 - val_loss: 1.1165\n",
      "Epoch 1483/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3755\n",
      "Epoch 1483: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3755 - val_loss: 1.1095\n",
      "Epoch 1484/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3751\n",
      "Epoch 1484: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3751 - val_loss: 1.1189\n",
      "Epoch 1485/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3772\n",
      "Epoch 1485: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.3772 - val_loss: 1.1103\n",
      "Epoch 1486/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3746\n",
      "Epoch 1486: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3746 - val_loss: 1.1238\n",
      "Epoch 1487/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3804\n",
      "Epoch 1487: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3804 - val_loss: 1.1113\n",
      "Epoch 1488/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3746\n",
      "Epoch 1488: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3746 - val_loss: 1.1217\n",
      "Epoch 1489/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3784\n",
      "Epoch 1489: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3784 - val_loss: 1.1118\n",
      "Epoch 1490/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3739\n",
      "Epoch 1490: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3739 - val_loss: 1.1143\n",
      "Epoch 1491/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3768\n",
      "Epoch 1491: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3768 - val_loss: 1.1093\n",
      "Epoch 1492/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3753\n",
      "Epoch 1492: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3753 - val_loss: 1.1238\n",
      "Epoch 1493/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3822\n",
      "Epoch 1493: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3822 - val_loss: 1.1100\n",
      "Epoch 1494/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3736\n",
      "Epoch 1494: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3736 - val_loss: 1.1183\n",
      "Epoch 1495/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3764\n",
      "Epoch 1495: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3764 - val_loss: 1.1095\n",
      "Epoch 1496/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3734\n",
      "Epoch 1496: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3734 - val_loss: 1.1134\n",
      "Epoch 1497/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3737\n",
      "Epoch 1497: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3737 - val_loss: 1.1132\n",
      "Epoch 1498/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3742\n",
      "Epoch 1498: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3742 - val_loss: 1.1107\n",
      "Epoch 1499/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.3734\n",
      "Epoch 1499: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.3734 - val_loss: 1.1233\n",
      "Epoch 1500/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3793\n",
      "Epoch 1500: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3793 - val_loss: 1.1086\n",
      "Epoch 1501/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3779\n",
      "Epoch 1501: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3779 - val_loss: 1.1241\n",
      "Epoch 1502/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3823\n",
      "Epoch 1502: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3823 - val_loss: 1.1099\n",
      "Epoch 1503/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3727\n",
      "Epoch 1503: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3727 - val_loss: 1.1138\n",
      "Epoch 1504/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3729\n",
      "Epoch 1504: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3729 - val_loss: 1.1080\n",
      "Epoch 1505/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3742\n",
      "Epoch 1505: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3742 - val_loss: 1.1229\n",
      "Epoch 1506/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3814\n",
      "Epoch 1506: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3814 - val_loss: 1.1101\n",
      "Epoch 1507/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3732\n",
      "Epoch 1507: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.3732 - val_loss: 1.1183\n",
      "Epoch 1508/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3752\n",
      "Epoch 1508: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3752 - val_loss: 1.1081\n",
      "Epoch 1509/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3754\n",
      "Epoch 1509: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3754 - val_loss: 1.1221\n",
      "Epoch 1510/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3791\n",
      "Epoch 1510: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3791 - val_loss: 1.1104\n",
      "Epoch 1511/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3729\n",
      "Epoch 1511: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3729 - val_loss: 1.1179\n",
      "Epoch 1512/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3754\n",
      "Epoch 1512: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3754 - val_loss: 1.1083\n",
      "Epoch 1513/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3742\n",
      "Epoch 1513: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3742 - val_loss: 1.1182\n",
      "Epoch 1514/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3754\n",
      "Epoch 1514: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3754 - val_loss: 1.1098\n",
      "Epoch 1515/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3724\n",
      "Epoch 1515: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3724 - val_loss: 1.1146\n",
      "Epoch 1516/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3726\n",
      "Epoch 1516: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3726 - val_loss: 1.1098\n",
      "Epoch 1517/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3718\n",
      "Epoch 1517: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3718 - val_loss: 1.1102\n",
      "Epoch 1518/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3728\n",
      "Epoch 1518: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3728 - val_loss: 1.1194\n",
      "Epoch 1519/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3754\n",
      "Epoch 1519: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3754 - val_loss: 1.1100\n",
      "Epoch 1520/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3736\n",
      "Epoch 1520: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3736 - val_loss: 1.1247\n",
      "Epoch 1521/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3803\n",
      "Epoch 1521: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3803 - val_loss: 1.1078\n",
      "Epoch 1522/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3746\n",
      "Epoch 1522: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.3746 - val_loss: 1.1221\n",
      "Epoch 1523/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3793\n",
      "Epoch 1523: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.3793 - val_loss: 1.1085\n",
      "Epoch 1524/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3720\n",
      "Epoch 1524: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.3720 - val_loss: 1.1159\n",
      "Epoch 1525/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3731\n",
      "Epoch 1525: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3731 - val_loss: 1.1077\n",
      "Epoch 1526/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3740\n",
      "Epoch 1526: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3740 - val_loss: 1.1193\n",
      "Epoch 1527/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3761\n",
      "Epoch 1527: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3761 - val_loss: 1.1087\n",
      "Epoch 1528/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3715\n",
      "Epoch 1528: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3715 - val_loss: 1.1139\n",
      "Epoch 1529/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3711\n",
      "Epoch 1529: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3711 - val_loss: 1.1072\n",
      "Epoch 1530/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3711\n",
      "Epoch 1530: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3711 - val_loss: 1.1149\n",
      "Epoch 1531/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3719\n",
      "Epoch 1531: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3719 - val_loss: 1.1094\n",
      "Epoch 1532/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3706\n",
      "Epoch 1532: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3706 - val_loss: 1.1167\n",
      "Epoch 1533/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3731\n",
      "Epoch 1533: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3731 - val_loss: 1.1066\n",
      "Epoch 1534/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3722\n",
      "Epoch 1534: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.3722 - val_loss: 1.1151\n",
      "Epoch 1535/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.3737\n",
      "Epoch 1535: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3737 - val_loss: 1.1059\n",
      "Epoch 1536/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3718\n",
      "Epoch 1536: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3718 - val_loss: 1.1155\n",
      "Epoch 1537/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3741\n",
      "Epoch 1537: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3741 - val_loss: 1.1085\n",
      "Epoch 1538/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3746\n",
      "Epoch 1538: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3746 - val_loss: 1.1201\n",
      "Epoch 1539/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3778\n",
      "Epoch 1539: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3778 - val_loss: 1.1020\n",
      "Epoch 1540/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3739\n",
      "Epoch 1540: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3739 - val_loss: 1.1164\n",
      "Epoch 1541/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3758\n",
      "Epoch 1541: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.3758 - val_loss: 1.1087\n",
      "Epoch 1542/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3713\n",
      "Epoch 1542: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3713 - val_loss: 1.1138\n",
      "Epoch 1543/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3706\n",
      "Epoch 1543: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3706 - val_loss: 1.1080\n",
      "Epoch 1544/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3694\n",
      "Epoch 1544: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3694 - val_loss: 1.1096\n",
      "Epoch 1545/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3702\n",
      "Epoch 1545: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3702 - val_loss: 1.1136\n",
      "Epoch 1546/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3716\n",
      "Epoch 1546: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3716 - val_loss: 1.1093\n",
      "Epoch 1547/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3718\n",
      "Epoch 1547: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3718 - val_loss: 1.1242\n",
      "Epoch 1548/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3794\n",
      "Epoch 1548: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3794 - val_loss: 1.1061\n",
      "Epoch 1549/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3717\n",
      "Epoch 1549: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3717 - val_loss: 1.1166\n",
      "Epoch 1550/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3724\n",
      "Epoch 1550: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3724 - val_loss: 1.1050\n",
      "Epoch 1551/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3713\n",
      "Epoch 1551: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3713 - val_loss: 1.1152\n",
      "Epoch 1552/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3718\n",
      "Epoch 1552: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3718 - val_loss: 1.1044\n",
      "Epoch 1553/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3703\n",
      "Epoch 1553: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3703 - val_loss: 1.1145\n",
      "Epoch 1554/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3712\n",
      "Epoch 1554: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3712 - val_loss: 1.1041\n",
      "Epoch 1555/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3709\n",
      "Epoch 1555: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.3709 - val_loss: 1.1138\n",
      "Epoch 1556/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3715\n",
      "Epoch 1556: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.3715 - val_loss: 1.1099\n",
      "Epoch 1557/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3705\n",
      "Epoch 1557: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3705 - val_loss: 1.1161\n",
      "Epoch 1558/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3755\n",
      "Epoch 1558: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.3755 - val_loss: 1.1082\n",
      "Epoch 1559/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3692\n",
      "Epoch 1559: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3692 - val_loss: 1.1167\n",
      "Epoch 1560/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3713\n",
      "Epoch 1560: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3713 - val_loss: 1.1048\n",
      "Epoch 1561/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3706\n",
      "Epoch 1561: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3706 - val_loss: 1.1160\n",
      "Epoch 1562/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3719\n",
      "Epoch 1562: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3719 - val_loss: 1.1028\n",
      "Epoch 1563/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3714\n",
      "Epoch 1563: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3714 - val_loss: 1.1153\n",
      "Epoch 1564/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3734\n",
      "Epoch 1564: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3734 - val_loss: 1.1077\n",
      "Epoch 1565/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3688\n",
      "Epoch 1565: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3688 - val_loss: 1.1171\n",
      "Epoch 1566/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3729\n",
      "Epoch 1566: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3729 - val_loss: 1.1054\n",
      "Epoch 1567/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3711\n",
      "Epoch 1567: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3711 - val_loss: 1.1209\n",
      "Epoch 1568/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3770\n",
      "Epoch 1568: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.3770 - val_loss: 1.1061\n",
      "Epoch 1569/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3702\n",
      "Epoch 1569: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3702 - val_loss: 1.1147\n",
      "Epoch 1570/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3696\n",
      "Epoch 1570: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3696 - val_loss: 1.1056\n",
      "Epoch 1571/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3697\n",
      "Epoch 1571: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3697 - val_loss: 1.1171\n",
      "Epoch 1572/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3723\n",
      "Epoch 1572: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3723 - val_loss: 1.1044\n",
      "Epoch 1573/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3722\n",
      "Epoch 1573: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3722 - val_loss: 1.1149\n",
      "Epoch 1574/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3710\n",
      "Epoch 1574: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3710 - val_loss: 1.1095\n",
      "Epoch 1575/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3684\n",
      "Epoch 1575: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3684 - val_loss: 1.1142\n",
      "Epoch 1576/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3697\n",
      "Epoch 1576: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3697 - val_loss: 1.1046\n",
      "Epoch 1577/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3682\n",
      "Epoch 1577: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3682 - val_loss: 1.1156\n",
      "Epoch 1578/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3709\n",
      "Epoch 1578: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3709 - val_loss: 1.1032\n",
      "Epoch 1579/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3687\n",
      "Epoch 1579: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3687 - val_loss: 1.1142\n",
      "Epoch 1580/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3705\n",
      "Epoch 1580: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3705 - val_loss: 1.1010\n",
      "Epoch 1581/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3721\n",
      "Epoch 1581: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3721 - val_loss: 1.1157\n",
      "Epoch 1582/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3750\n",
      "Epoch 1582: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3750 - val_loss: 1.1044\n",
      "Epoch 1583/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3682\n",
      "Epoch 1583: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.3682 - val_loss: 1.1105\n",
      "Epoch 1584/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3671\n",
      "Epoch 1584: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3671 - val_loss: 1.1058\n",
      "Epoch 1585/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3674\n",
      "Epoch 1585: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3674 - val_loss: 1.1135\n",
      "Epoch 1586/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3692\n",
      "Epoch 1586: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3692 - val_loss: 1.1021\n",
      "Epoch 1587/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3708\n",
      "Epoch 1587: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3708 - val_loss: 1.1160\n",
      "Epoch 1588/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3735\n",
      "Epoch 1588: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3735 - val_loss: 1.1077\n",
      "Epoch 1589/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3682\n",
      "Epoch 1589: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3682 - val_loss: 1.1135\n",
      "Epoch 1590/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3676\n",
      "Epoch 1590: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3676 - val_loss: 1.1061\n",
      "Epoch 1591/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3665\n",
      "Epoch 1591: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3665 - val_loss: 1.1123\n",
      "Epoch 1592/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3675\n",
      "Epoch 1592: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3675 - val_loss: 1.1056\n",
      "Epoch 1593/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3665\n",
      "Epoch 1593: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3665 - val_loss: 1.1123\n",
      "Epoch 1594/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3673\n",
      "Epoch 1594: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3673 - val_loss: 1.1028\n",
      "Epoch 1595/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3702\n",
      "Epoch 1595: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3702 - val_loss: 1.1126\n",
      "Epoch 1596/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3697\n",
      "Epoch 1596: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3697 - val_loss: 1.1005\n",
      "Epoch 1597/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.3685\n",
      "Epoch 1597: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.3685 - val_loss: 1.1167\n",
      "Epoch 1598/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3738\n",
      "Epoch 1598: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3738 - val_loss: 1.1037\n",
      "Epoch 1599/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3707\n",
      "Epoch 1599: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3707 - val_loss: 1.1182\n",
      "Epoch 1600/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3731\n",
      "Epoch 1600: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3731 - val_loss: 1.1019\n",
      "Epoch 1601/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3693\n",
      "Epoch 1601: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3693 - val_loss: 1.1121\n",
      "Epoch 1602/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3683\n",
      "Epoch 1602: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3683 - val_loss: 1.1066\n",
      "Epoch 1603/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3674\n",
      "Epoch 1603: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3674 - val_loss: 1.1176\n",
      "Epoch 1604/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3718\n",
      "Epoch 1604: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3718 - val_loss: 1.1030\n",
      "Epoch 1605/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3698\n",
      "Epoch 1605: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.3698 - val_loss: 1.1188\n",
      "Epoch 1606/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.3751\n",
      "Epoch 1606: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3751 - val_loss: 1.1028\n",
      "Epoch 1607/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3673\n",
      "Epoch 1607: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3673 - val_loss: 1.1092\n",
      "Epoch 1608/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3662\n",
      "Epoch 1608: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3662 - val_loss: 1.1066\n",
      "Epoch 1609/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3657\n",
      "Epoch 1609: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3657 - val_loss: 1.1089\n",
      "Epoch 1610/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3663\n",
      "Epoch 1610: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3663 - val_loss: 1.1063\n",
      "Epoch 1611/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3653\n",
      "Epoch 1611: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3653 - val_loss: 1.1114\n",
      "Epoch 1612/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3658\n",
      "Epoch 1612: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3658 - val_loss: 1.1019\n",
      "Epoch 1613/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3669\n",
      "Epoch 1613: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3669 - val_loss: 1.1128\n",
      "Epoch 1614/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3683\n",
      "Epoch 1614: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3683 - val_loss: 1.0998\n",
      "Epoch 1615/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3700\n",
      "Epoch 1615: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3700 - val_loss: 1.1166\n",
      "Epoch 1616/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3740\n",
      "Epoch 1616: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3740 - val_loss: 1.0992\n",
      "Epoch 1617/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3684\n",
      "Epoch 1617: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3684 - val_loss: 1.1088\n",
      "Epoch 1618/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3673\n",
      "Epoch 1618: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3673 - val_loss: 1.1044\n",
      "Epoch 1619/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3664\n",
      "Epoch 1619: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3664 - val_loss: 1.1146\n",
      "Epoch 1620/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3695\n",
      "Epoch 1620: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.3695 - val_loss: 1.1022\n",
      "Epoch 1621/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3713\n",
      "Epoch 1621: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3713 - val_loss: 1.1188\n",
      "Epoch 1622/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3746\n",
      "Epoch 1622: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3746 - val_loss: 1.1031\n",
      "Epoch 1623/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3656\n",
      "Epoch 1623: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3656 - val_loss: 1.1094\n",
      "Epoch 1624/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3649\n",
      "Epoch 1624: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3649 - val_loss: 1.1039\n",
      "Epoch 1625/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3659\n",
      "Epoch 1625: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3659 - val_loss: 1.1110\n",
      "Epoch 1626/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3655\n",
      "Epoch 1626: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.3655 - val_loss: 1.1006\n",
      "Epoch 1627/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.3661\n",
      "Epoch 1627: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3661 - val_loss: 1.1088\n",
      "Epoch 1628/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3652\n",
      "Epoch 1628: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3652 - val_loss: 1.1059\n",
      "Epoch 1629/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3662\n",
      "Epoch 1629: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3662 - val_loss: 1.1108\n",
      "Epoch 1630/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3704\n",
      "Epoch 1630: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3704 - val_loss: 1.1040\n",
      "Epoch 1631/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3653\n",
      "Epoch 1631: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3653 - val_loss: 1.1151\n",
      "Epoch 1632/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3688\n",
      "Epoch 1632: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3688 - val_loss: 1.1018\n",
      "Epoch 1633/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3658\n",
      "Epoch 1633: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3658 - val_loss: 1.1115\n",
      "Epoch 1634/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3659\n",
      "Epoch 1634: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3659 - val_loss: 1.0984\n",
      "Epoch 1635/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3708\n",
      "Epoch 1635: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3708 - val_loss: 1.1174\n",
      "Epoch 1636/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3750\n",
      "Epoch 1636: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3750 - val_loss: 1.1039\n",
      "Epoch 1637/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3644\n",
      "Epoch 1637: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3644 - val_loss: 1.1123\n",
      "Epoch 1638/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3653\n",
      "Epoch 1638: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3653 - val_loss: 1.1006\n",
      "Epoch 1639/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3658\n",
      "Epoch 1639: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3658 - val_loss: 1.1110\n",
      "Epoch 1640/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3656\n",
      "Epoch 1640: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3656 - val_loss: 1.1027\n",
      "Epoch 1641/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3659\n",
      "Epoch 1641: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.3659 - val_loss: 1.1136\n",
      "Epoch 1642/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3672\n",
      "Epoch 1642: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3672 - val_loss: 1.1008\n",
      "Epoch 1643/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3668\n",
      "Epoch 1643: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3668 - val_loss: 1.1171\n",
      "Epoch 1644/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3729\n",
      "Epoch 1644: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3729 - val_loss: 1.1048\n",
      "Epoch 1645/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3644\n",
      "Epoch 1645: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3644 - val_loss: 1.1122\n",
      "Epoch 1646/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3646\n",
      "Epoch 1646: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3646 - val_loss: 1.1025\n",
      "Epoch 1647/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3648\n",
      "Epoch 1647: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3648 - val_loss: 1.1127\n",
      "Epoch 1648/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3667\n",
      "Epoch 1648: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3667 - val_loss: 1.0995\n",
      "Epoch 1649/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3655\n",
      "Epoch 1649: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3655 - val_loss: 1.1092\n",
      "Epoch 1650/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3644\n",
      "Epoch 1650: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3644 - val_loss: 1.1031\n",
      "Epoch 1651/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3680\n",
      "Epoch 1651: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3680 - val_loss: 1.1184\n",
      "Epoch 1652/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3726\n",
      "Epoch 1652: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3726 - val_loss: 1.1013\n",
      "Epoch 1653/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3656\n",
      "Epoch 1653: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3656 - val_loss: 1.1143\n",
      "Epoch 1654/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3691\n",
      "Epoch 1654: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.3691 - val_loss: 1.1051\n",
      "Epoch 1655/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3654\n",
      "Epoch 1655: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3654 - val_loss: 1.1152\n",
      "Epoch 1656/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3670\n",
      "Epoch 1656: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3670 - val_loss: 1.1026\n",
      "Epoch 1657/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3654\n",
      "Epoch 1657: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3654 - val_loss: 1.1148\n",
      "Epoch 1658/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3681\n",
      "Epoch 1658: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.3681 - val_loss: 1.1024\n",
      "Epoch 1659/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3667\n",
      "Epoch 1659: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3667 - val_loss: 1.1115\n",
      "Epoch 1660/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3639\n",
      "Epoch 1660: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3639 - val_loss: 1.1081\n",
      "Epoch 1661/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3633\n",
      "Epoch 1661: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3633 - val_loss: 1.1070\n",
      "Epoch 1662/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3638\n",
      "Epoch 1662: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3638 - val_loss: 1.1071\n",
      "Epoch 1663/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3623\n",
      "Epoch 1663: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3623 - val_loss: 1.1033\n",
      "Epoch 1664/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3638\n",
      "Epoch 1664: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3638 - val_loss: 1.1085\n",
      "Epoch 1665/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3633\n",
      "Epoch 1665: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3633 - val_loss: 1.1004\n",
      "Epoch 1666/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3671\n",
      "Epoch 1666: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3671 - val_loss: 1.1187\n",
      "Epoch 1667/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3727\n",
      "Epoch 1667: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.3727 - val_loss: 1.1017\n",
      "Epoch 1668/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3650\n",
      "Epoch 1668: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3650 - val_loss: 1.1154\n",
      "Epoch 1669/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3680\n",
      "Epoch 1669: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3680 - val_loss: 1.1000\n",
      "Epoch 1670/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3673\n",
      "Epoch 1670: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3673 - val_loss: 1.1144\n",
      "Epoch 1671/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3676\n",
      "Epoch 1671: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3676 - val_loss: 1.1000\n",
      "Epoch 1672/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3663\n",
      "Epoch 1672: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3663 - val_loss: 1.1137\n",
      "Epoch 1673/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3680\n",
      "Epoch 1673: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3680 - val_loss: 1.1031\n",
      "Epoch 1674/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3644\n",
      "Epoch 1674: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3644 - val_loss: 1.1126\n",
      "Epoch 1675/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3636\n",
      "Epoch 1675: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3636 - val_loss: 1.1016\n",
      "Epoch 1676/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3634\n",
      "Epoch 1676: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3634 - val_loss: 1.1078\n",
      "Epoch 1677/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3620\n",
      "Epoch 1677: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3620 - val_loss: 1.1075\n",
      "Epoch 1678/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3618\n",
      "Epoch 1678: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3618 - val_loss: 1.1070\n",
      "Epoch 1679/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3620\n",
      "Epoch 1679: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3620 - val_loss: 1.1031\n",
      "Epoch 1680/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3626\n",
      "Epoch 1680: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.3626 - val_loss: 1.1049\n",
      "Epoch 1681/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3614\n",
      "Epoch 1681: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3614 - val_loss: 1.1102\n",
      "Epoch 1682/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3624\n",
      "Epoch 1682: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3624 - val_loss: 1.1001\n",
      "Epoch 1683/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3627\n",
      "Epoch 1683: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3627 - val_loss: 1.1139\n",
      "Epoch 1684/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3660\n",
      "Epoch 1684: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3660 - val_loss: 1.0996\n",
      "Epoch 1685/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3732\n",
      "Epoch 1685: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3732 - val_loss: 1.1199\n",
      "Epoch 1686/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3728\n",
      "Epoch 1686: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3728 - val_loss: 1.1026\n",
      "Epoch 1687/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3629\n",
      "Epoch 1687: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3629 - val_loss: 1.1080\n",
      "Epoch 1688/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3614\n",
      "Epoch 1688: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3614 - val_loss: 1.1067\n",
      "Epoch 1689/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3612\n",
      "Epoch 1689: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3612 - val_loss: 1.1063\n",
      "Epoch 1690/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3617\n",
      "Epoch 1690: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.3617 - val_loss: 1.1081\n",
      "Epoch 1691/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3657\n",
      "Epoch 1691: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.3657 - val_loss: 1.1038\n",
      "Epoch 1692/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3636\n",
      "Epoch 1692: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3636 - val_loss: 1.1182\n",
      "Epoch 1693/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3680\n",
      "Epoch 1693: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3680 - val_loss: 1.1033\n",
      "Epoch 1694/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3676\n",
      "Epoch 1694: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3676 - val_loss: 1.1198\n",
      "Epoch 1695/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3703\n",
      "Epoch 1695: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3703 - val_loss: 1.1031\n",
      "Epoch 1696/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3631\n",
      "Epoch 1696: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3631 - val_loss: 1.1121\n",
      "Epoch 1697/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3624\n",
      "Epoch 1697: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3624 - val_loss: 1.1051\n",
      "Epoch 1698/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3620\n",
      "Epoch 1698: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3620 - val_loss: 1.1124\n",
      "Epoch 1699/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3625\n",
      "Epoch 1699: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3625 - val_loss: 1.1008\n",
      "Epoch 1700/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3650\n",
      "Epoch 1700: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3650 - val_loss: 1.1162\n",
      "Epoch 1701/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3659\n",
      "Epoch 1701: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.3659 - val_loss: 1.1024\n",
      "Epoch 1702/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3643\n",
      "Epoch 1702: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3643 - val_loss: 1.1161\n",
      "Epoch 1703/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3684\n",
      "Epoch 1703: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3684 - val_loss: 1.1008\n",
      "Epoch 1704/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3632\n",
      "Epoch 1704: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3632 - val_loss: 1.1070\n",
      "Epoch 1705/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3605\n",
      "Epoch 1705: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3605 - val_loss: 1.1045\n",
      "Epoch 1706/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3604\n",
      "Epoch 1706: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3604 - val_loss: 1.1115\n",
      "Epoch 1707/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3614\n",
      "Epoch 1707: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3614 - val_loss: 1.1004\n",
      "Epoch 1708/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3632\n",
      "Epoch 1708: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3632 - val_loss: 1.1104\n",
      "Epoch 1709/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3626\n",
      "Epoch 1709: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3626 - val_loss: 1.0975\n",
      "Epoch 1710/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3651\n",
      "Epoch 1710: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3651 - val_loss: 1.1144\n",
      "Epoch 1711/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3683\n",
      "Epoch 1711: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3683 - val_loss: 1.1031\n",
      "Epoch 1712/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3631\n",
      "Epoch 1712: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3631 - val_loss: 1.1198\n",
      "Epoch 1713/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3686\n",
      "Epoch 1713: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3686 - val_loss: 1.1045\n",
      "Epoch 1714/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.3631\n",
      "Epoch 1714: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.3631 - val_loss: 1.1127\n",
      "Epoch 1715/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3624\n",
      "Epoch 1715: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3624 - val_loss: 1.1008\n",
      "Epoch 1716/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3626\n",
      "Epoch 1716: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3626 - val_loss: 1.1113\n",
      "Epoch 1717/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3623\n",
      "Epoch 1717: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3623 - val_loss: 1.1055\n",
      "Epoch 1718/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3623\n",
      "Epoch 1718: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3623 - val_loss: 1.1200\n",
      "Epoch 1719/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3667\n",
      "Epoch 1719: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.3667 - val_loss: 1.1050\n",
      "Epoch 1720/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3638\n",
      "Epoch 1720: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3638 - val_loss: 1.1174\n",
      "Epoch 1721/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3653\n",
      "Epoch 1721: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3653 - val_loss: 1.1034\n",
      "Epoch 1722/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3614\n",
      "Epoch 1722: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.3614 - val_loss: 1.1113\n",
      "Epoch 1723/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3609\n",
      "Epoch 1723: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3609 - val_loss: 1.1010\n",
      "Epoch 1724/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3617\n",
      "Epoch 1724: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3617 - val_loss: 1.1133\n",
      "Epoch 1725/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3621\n",
      "Epoch 1725: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3621 - val_loss: 1.1000\n",
      "Epoch 1726/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3630\n",
      "Epoch 1726: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3630 - val_loss: 1.1129\n",
      "Epoch 1727/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3650\n",
      "Epoch 1727: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3650 - val_loss: 1.1029\n",
      "Epoch 1728/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3651\n",
      "Epoch 1728: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3651 - val_loss: 1.1169\n",
      "Epoch 1729/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3636\n",
      "Epoch 1729: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3636 - val_loss: 1.1036\n",
      "Epoch 1730/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3611\n",
      "Epoch 1730: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3611 - val_loss: 1.1101\n",
      "Epoch 1731/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3601\n",
      "Epoch 1731: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3601 - val_loss: 1.1018\n",
      "Epoch 1732/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3604\n",
      "Epoch 1732: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.3604 - val_loss: 1.1098\n",
      "Epoch 1733/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3605\n",
      "Epoch 1733: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3605 - val_loss: 1.1065\n",
      "Epoch 1734/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3595\n",
      "Epoch 1734: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3595 - val_loss: 1.1081\n",
      "Epoch 1735/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3590\n",
      "Epoch 1735: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3590 - val_loss: 1.1039\n",
      "Epoch 1736/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3602\n",
      "Epoch 1736: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3602 - val_loss: 1.1173\n",
      "Epoch 1737/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3645\n",
      "Epoch 1737: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3645 - val_loss: 1.1012\n",
      "Epoch 1738/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3646\n",
      "Epoch 1738: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3646 - val_loss: 1.1220\n",
      "Epoch 1739/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3720\n",
      "Epoch 1739: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3720 - val_loss: 1.1057\n",
      "Epoch 1740/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3607\n",
      "Epoch 1740: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3607 - val_loss: 1.1134\n",
      "Epoch 1741/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3613\n",
      "Epoch 1741: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.3613 - val_loss: 1.1004\n",
      "Epoch 1742/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.3620\n",
      "Epoch 1742: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.3620 - val_loss: 1.1132\n",
      "Epoch 1743/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.3626\n",
      "Epoch 1743: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.3626 - val_loss: 1.0992\n",
      "Epoch 1744/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3614\n",
      "Epoch 1744: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.3614 - val_loss: 1.1098\n",
      "Epoch 1745/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3600\n",
      "Epoch 1745: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3600 - val_loss: 1.1025\n",
      "Epoch 1746/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3607\n",
      "Epoch 1746: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3607 - val_loss: 1.1177\n",
      "Epoch 1747/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3655\n",
      "Epoch 1747: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3655 - val_loss: 1.1040\n",
      "Epoch 1748/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3651\n",
      "Epoch 1748: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3651 - val_loss: 1.1195\n",
      "Epoch 1749/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3680\n",
      "Epoch 1749: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3680 - val_loss: 1.1035\n",
      "Epoch 1750/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3605\n",
      "Epoch 1750: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3605 - val_loss: 1.1142\n",
      "Epoch 1751/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3614\n",
      "Epoch 1751: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3614 - val_loss: 1.1076\n",
      "Epoch 1752/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3596\n",
      "Epoch 1752: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3596 - val_loss: 1.1133\n",
      "Epoch 1753/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3598\n",
      "Epoch 1753: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3598 - val_loss: 1.1049\n",
      "Epoch 1754/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3586\n",
      "Epoch 1754: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3586 - val_loss: 1.1120\n",
      "Epoch 1755/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3598\n",
      "Epoch 1755: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3598 - val_loss: 1.1007\n",
      "Epoch 1756/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3609\n",
      "Epoch 1756: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.3609 - val_loss: 1.1155\n",
      "Epoch 1757/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3634\n",
      "Epoch 1757: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3634 - val_loss: 1.1045\n",
      "Epoch 1758/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3645\n",
      "Epoch 1758: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3645 - val_loss: 1.1205\n",
      "Epoch 1759/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3658\n",
      "Epoch 1759: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3658 - val_loss: 1.1045\n",
      "Epoch 1760/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3613\n",
      "Epoch 1760: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3613 - val_loss: 1.1165\n",
      "Epoch 1761/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3610\n",
      "Epoch 1761: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3610 - val_loss: 1.1042\n",
      "Epoch 1762/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3602\n",
      "Epoch 1762: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3602 - val_loss: 1.1124\n",
      "Epoch 1763/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3591\n",
      "Epoch 1763: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3591 - val_loss: 1.1040\n",
      "Epoch 1764/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3585\n",
      "Epoch 1764: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3585 - val_loss: 1.1126\n",
      "Epoch 1765/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3602\n",
      "Epoch 1765: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3602 - val_loss: 1.0991\n",
      "Epoch 1766/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3635\n",
      "Epoch 1766: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3635 - val_loss: 1.1165\n",
      "Epoch 1767/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3650\n",
      "Epoch 1767: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.3650 - val_loss: 1.1020\n",
      "Epoch 1768/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3623\n",
      "Epoch 1768: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3623 - val_loss: 1.1114\n",
      "Epoch 1769/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3600\n",
      "Epoch 1769: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3600 - val_loss: 1.1048\n",
      "Epoch 1770/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3604\n",
      "Epoch 1770: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3604 - val_loss: 1.1185\n",
      "Epoch 1771/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3635\n",
      "Epoch 1771: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3635 - val_loss: 1.1036\n",
      "Epoch 1772/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3617\n",
      "Epoch 1772: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3617 - val_loss: 1.1149\n",
      "Epoch 1773/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3610\n",
      "Epoch 1773: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3610 - val_loss: 1.1009\n",
      "Epoch 1774/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3609\n",
      "Epoch 1774: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3609 - val_loss: 1.1128\n",
      "Epoch 1775/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3595\n",
      "Epoch 1775: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3595 - val_loss: 1.1056\n",
      "Epoch 1776/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3583\n",
      "Epoch 1776: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3583 - val_loss: 1.1151\n",
      "Epoch 1777/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3598\n",
      "Epoch 1777: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3598 - val_loss: 1.1063\n",
      "Epoch 1778/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3576\n",
      "Epoch 1778: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.3576 - val_loss: 1.1075\n",
      "Epoch 1779/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3575\n",
      "Epoch 1779: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3575 - val_loss: 1.1114\n",
      "Epoch 1780/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3587\n",
      "Epoch 1780: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3587 - val_loss: 1.1030\n",
      "Epoch 1781/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3596\n",
      "Epoch 1781: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3596 - val_loss: 1.1154\n",
      "Epoch 1782/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3610\n",
      "Epoch 1782: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3610 - val_loss: 1.1002\n",
      "Epoch 1783/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3625\n",
      "Epoch 1783: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3625 - val_loss: 1.1211\n",
      "Epoch 1784/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3686\n",
      "Epoch 1784: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3686 - val_loss: 1.1039\n",
      "Epoch 1785/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3594\n",
      "Epoch 1785: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3594 - val_loss: 1.1122\n",
      "Epoch 1786/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3585\n",
      "Epoch 1786: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3585 - val_loss: 1.1023\n",
      "Epoch 1787/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3581\n",
      "Epoch 1787: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3581 - val_loss: 1.1123\n",
      "Epoch 1788/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3594\n",
      "Epoch 1788: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3594 - val_loss: 1.1045\n",
      "Epoch 1789/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3605\n",
      "Epoch 1789: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3605 - val_loss: 1.1241\n",
      "Epoch 1790/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3688\n",
      "Epoch 1790: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3688 - val_loss: 1.1065\n",
      "Epoch 1791/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.3592\n",
      "Epoch 1791: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.3592 - val_loss: 1.1158\n",
      "Epoch 1792/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3595\n",
      "Epoch 1792: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3595 - val_loss: 1.1025\n",
      "Epoch 1793/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3606\n",
      "Epoch 1793: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3606 - val_loss: 1.1167\n",
      "Epoch 1794/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3618\n",
      "Epoch 1794: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3618 - val_loss: 1.1020\n",
      "Epoch 1795/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3590\n",
      "Epoch 1795: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3590 - val_loss: 1.1138\n",
      "Epoch 1796/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3597\n",
      "Epoch 1796: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3597 - val_loss: 1.1026\n",
      "Epoch 1797/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3585\n",
      "Epoch 1797: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3585 - val_loss: 1.1122\n",
      "Epoch 1798/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3595\n",
      "Epoch 1798: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3595 - val_loss: 1.1030\n",
      "Epoch 1799/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3609\n",
      "Epoch 1799: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3609 - val_loss: 1.1184\n",
      "Epoch 1800/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3621\n",
      "Epoch 1800: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3621 - val_loss: 1.1035\n",
      "Epoch 1801/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3601\n",
      "Epoch 1801: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3601 - val_loss: 1.1121\n",
      "Epoch 1802/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3576\n",
      "Epoch 1802: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.3576 - val_loss: 1.1050\n",
      "Epoch 1803/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.3566\n",
      "Epoch 1803: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.3566 - val_loss: 1.1087\n",
      "Epoch 1804/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3563\n",
      "Epoch 1804: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3563 - val_loss: 1.1059\n",
      "Epoch 1805/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3567\n",
      "Epoch 1805: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3567 - val_loss: 1.1152\n",
      "Epoch 1806/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3595\n",
      "Epoch 1806: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3595 - val_loss: 1.1002\n",
      "Epoch 1807/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3622\n",
      "Epoch 1807: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3622 - val_loss: 1.1209\n",
      "Epoch 1808/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3669\n",
      "Epoch 1808: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3669 - val_loss: 1.1037\n",
      "Epoch 1809/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3584\n",
      "Epoch 1809: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3584 - val_loss: 1.1152\n",
      "Epoch 1810/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3590\n",
      "Epoch 1810: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3590 - val_loss: 1.1036\n",
      "Epoch 1811/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3576\n",
      "Epoch 1811: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3576 - val_loss: 1.1130\n",
      "Epoch 1812/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3574\n",
      "Epoch 1812: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3574 - val_loss: 1.1033\n",
      "Epoch 1813/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3570\n",
      "Epoch 1813: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3570 - val_loss: 1.1132\n",
      "Epoch 1814/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3588\n",
      "Epoch 1814: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3588 - val_loss: 1.0993\n",
      "Epoch 1815/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.3615\n",
      "Epoch 1815: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.3615 - val_loss: 1.1175\n",
      "Epoch 1816/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3642\n",
      "Epoch 1816: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3642 - val_loss: 1.1053\n",
      "Epoch 1817/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3588\n",
      "Epoch 1817: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3588 - val_loss: 1.1193\n",
      "Epoch 1818/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3612\n",
      "Epoch 1818: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3612 - val_loss: 1.1042\n",
      "Epoch 1819/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3594\n",
      "Epoch 1819: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.3594 - val_loss: 1.1176\n",
      "Epoch 1820/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3596\n",
      "Epoch 1820: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3596 - val_loss: 1.1032\n",
      "Epoch 1821/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3602\n",
      "Epoch 1821: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3602 - val_loss: 1.1181\n",
      "Epoch 1822/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3614\n",
      "Epoch 1822: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3614 - val_loss: 1.1042\n",
      "Epoch 1823/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3596\n",
      "Epoch 1823: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3596 - val_loss: 1.1163\n",
      "Epoch 1824/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3586\n",
      "Epoch 1824: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3586 - val_loss: 1.1111\n",
      "Epoch 1825/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3561\n",
      "Epoch 1825: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3561 - val_loss: 1.1064\n",
      "Epoch 1826/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3565\n",
      "Epoch 1826: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3565 - val_loss: 1.1101\n",
      "Epoch 1827/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3567\n",
      "Epoch 1827: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3567 - val_loss: 1.1098\n",
      "Epoch 1828/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3555\n",
      "Epoch 1828: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3555 - val_loss: 1.1112\n",
      "Epoch 1829/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3556\n",
      "Epoch 1829: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3556 - val_loss: 1.1060\n",
      "Epoch 1830/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3565\n",
      "Epoch 1830: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3565 - val_loss: 1.1115\n",
      "Epoch 1831/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3566\n",
      "Epoch 1831: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.3566 - val_loss: 1.0999\n",
      "Epoch 1832/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3607\n",
      "Epoch 1832: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3607 - val_loss: 1.1196\n",
      "Epoch 1833/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3647\n",
      "Epoch 1833: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3647 - val_loss: 1.1021\n",
      "Epoch 1834/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3593\n",
      "Epoch 1834: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3593 - val_loss: 1.1186\n",
      "Epoch 1835/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3607\n",
      "Epoch 1835: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3607 - val_loss: 1.1079\n",
      "Epoch 1836/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3584\n",
      "Epoch 1836: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3584 - val_loss: 1.1201\n",
      "Epoch 1837/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3601\n",
      "Epoch 1837: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.3601 - val_loss: 1.1059\n",
      "Epoch 1838/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3567\n",
      "Epoch 1838: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3567 - val_loss: 1.1141\n",
      "Epoch 1839/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3568\n",
      "Epoch 1839: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3568 - val_loss: 1.1067\n",
      "Epoch 1840/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3553\n",
      "Epoch 1840: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3553 - val_loss: 1.1122\n",
      "Epoch 1841/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3558\n",
      "Epoch 1841: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3558 - val_loss: 1.1003\n",
      "Epoch 1842/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3576\n",
      "Epoch 1842: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3576 - val_loss: 1.1153\n",
      "Epoch 1843/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3579\n",
      "Epoch 1843: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3579 - val_loss: 1.0995\n",
      "Epoch 1844/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3603\n",
      "Epoch 1844: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3603 - val_loss: 1.1162\n",
      "Epoch 1845/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3611\n",
      "Epoch 1845: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3611 - val_loss: 1.1046\n",
      "Epoch 1846/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3589\n",
      "Epoch 1846: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3589 - val_loss: 1.1211\n",
      "Epoch 1847/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3616\n",
      "Epoch 1847: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3616 - val_loss: 1.1046\n",
      "Epoch 1848/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3581\n",
      "Epoch 1848: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.3581 - val_loss: 1.1183\n",
      "Epoch 1849/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3580\n",
      "Epoch 1849: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.3580 - val_loss: 1.1044\n",
      "Epoch 1850/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3574\n",
      "Epoch 1850: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3574 - val_loss: 1.1134\n",
      "Epoch 1851/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3560\n",
      "Epoch 1851: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.3560 - val_loss: 1.1063\n",
      "Epoch 1852/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3548\n",
      "Epoch 1852: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3548 - val_loss: 1.1115\n",
      "Epoch 1853/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3552\n",
      "Epoch 1853: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3552 - val_loss: 1.1044\n",
      "Epoch 1854/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3567\n",
      "Epoch 1854: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3567 - val_loss: 1.1206\n",
      "Epoch 1855/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3610\n",
      "Epoch 1855: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3610 - val_loss: 1.1044\n",
      "Epoch 1856/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3593\n",
      "Epoch 1856: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3593 - val_loss: 1.1197\n",
      "Epoch 1857/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3601\n",
      "Epoch 1857: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3601 - val_loss: 1.1047\n",
      "Epoch 1858/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3568\n",
      "Epoch 1858: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.3568 - val_loss: 1.1149\n",
      "Epoch 1859/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3559\n",
      "Epoch 1859: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3559 - val_loss: 1.1055\n",
      "Epoch 1860/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3547\n",
      "Epoch 1860: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.3547 - val_loss: 1.1127\n",
      "Epoch 1861/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3559\n",
      "Epoch 1861: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3559 - val_loss: 1.1043\n",
      "Epoch 1862/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3559\n",
      "Epoch 1862: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3559 - val_loss: 1.1103\n",
      "Epoch 1863/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3550\n",
      "Epoch 1863: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3550 - val_loss: 1.1054\n",
      "Epoch 1864/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3544\n",
      "Epoch 1864: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3544 - val_loss: 1.1090\n",
      "Epoch 1865/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3553\n",
      "Epoch 1865: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3553 - val_loss: 1.1044\n",
      "Epoch 1866/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3543\n",
      "Epoch 1866: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3543 - val_loss: 1.1066\n",
      "Epoch 1867/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3544\n",
      "Epoch 1867: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3544 - val_loss: 1.1088\n",
      "Epoch 1868/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3533\n",
      "Epoch 1868: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3533 - val_loss: 1.1101\n",
      "Epoch 1869/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3549\n",
      "Epoch 1869: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3549 - val_loss: 1.0995\n",
      "Epoch 1870/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3577\n",
      "Epoch 1870: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3577 - val_loss: 1.1178\n",
      "Epoch 1871/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3612\n",
      "Epoch 1871: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3612 - val_loss: 1.0997\n",
      "Epoch 1872/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3616\n",
      "Epoch 1872: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.3616 - val_loss: 1.1203\n",
      "Epoch 1873/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3631\n",
      "Epoch 1873: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3631 - val_loss: 1.1021\n",
      "Epoch 1874/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3574\n",
      "Epoch 1874: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3574 - val_loss: 1.1134\n",
      "Epoch 1875/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3559\n",
      "Epoch 1875: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3559 - val_loss: 1.1013\n",
      "Epoch 1876/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3548\n",
      "Epoch 1876: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3548 - val_loss: 1.1077\n",
      "Epoch 1877/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3540\n",
      "Epoch 1877: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3540 - val_loss: 1.1053\n",
      "Epoch 1878/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3537\n",
      "Epoch 1878: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3537 - val_loss: 1.1098\n",
      "Epoch 1879/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3532\n",
      "Epoch 1879: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3532 - val_loss: 1.1047\n",
      "Epoch 1880/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3546\n",
      "Epoch 1880: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3546 - val_loss: 1.1160\n",
      "Epoch 1881/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3562\n",
      "Epoch 1881: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3562 - val_loss: 1.1011\n",
      "Epoch 1882/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3588\n",
      "Epoch 1882: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3588 - val_loss: 1.1236\n",
      "Epoch 1883/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3657\n",
      "Epoch 1883: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3657 - val_loss: 1.1047\n",
      "Epoch 1884/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3551\n",
      "Epoch 1884: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.3551 - val_loss: 1.1176\n",
      "Epoch 1885/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3563\n",
      "Epoch 1885: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3563 - val_loss: 1.1053\n",
      "Epoch 1886/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3537\n",
      "Epoch 1886: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3537 - val_loss: 1.1131\n",
      "Epoch 1887/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3545\n",
      "Epoch 1887: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3545 - val_loss: 1.1003\n",
      "Epoch 1888/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3561\n",
      "Epoch 1888: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3561 - val_loss: 1.1191\n",
      "Epoch 1889/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3619\n",
      "Epoch 1889: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3619 - val_loss: 1.1011\n",
      "Epoch 1890/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3566\n",
      "Epoch 1890: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3566 - val_loss: 1.1175\n",
      "Epoch 1891/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3588\n",
      "Epoch 1891: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3588 - val_loss: 1.1017\n",
      "Epoch 1892/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3574\n",
      "Epoch 1892: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3574 - val_loss: 1.1169\n",
      "Epoch 1893/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3564\n",
      "Epoch 1893: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3564 - val_loss: 1.1028\n",
      "Epoch 1894/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3553\n",
      "Epoch 1894: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3553 - val_loss: 1.1119\n",
      "Epoch 1895/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3537\n",
      "Epoch 1895: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.3537 - val_loss: 1.1016\n",
      "Epoch 1896/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3536\n",
      "Epoch 1896: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3536 - val_loss: 1.1112\n",
      "Epoch 1897/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3538\n",
      "Epoch 1897: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3538 - val_loss: 1.1042\n",
      "Epoch 1898/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3541\n",
      "Epoch 1898: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3541 - val_loss: 1.1115\n",
      "Epoch 1899/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3540\n",
      "Epoch 1899: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3540 - val_loss: 1.1096\n",
      "Epoch 1900/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3539\n",
      "Epoch 1900: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3539 - val_loss: 1.1125\n",
      "Epoch 1901/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3551\n",
      "Epoch 1901: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3551 - val_loss: 1.1060\n",
      "Epoch 1902/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3563\n",
      "Epoch 1902: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.3563 - val_loss: 1.1173\n",
      "Epoch 1903/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3552\n",
      "Epoch 1903: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3552 - val_loss: 1.1027\n",
      "Epoch 1904/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3562\n",
      "Epoch 1904: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3562 - val_loss: 1.1186\n",
      "Epoch 1905/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3568\n",
      "Epoch 1905: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3568 - val_loss: 1.1019\n",
      "Epoch 1906/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3568\n",
      "Epoch 1906: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3568 - val_loss: 1.1184\n",
      "Epoch 1907/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3567\n",
      "Epoch 1907: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3567 - val_loss: 1.1023\n",
      "Epoch 1908/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3556\n",
      "Epoch 1908: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3556 - val_loss: 1.1168\n",
      "Epoch 1909/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3551\n",
      "Epoch 1909: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.3551 - val_loss: 1.1029\n",
      "Epoch 1910/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3541\n",
      "Epoch 1910: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3541 - val_loss: 1.1112\n",
      "Epoch 1911/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3531\n",
      "Epoch 1911: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3531 - val_loss: 1.1039\n",
      "Epoch 1912/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3524\n",
      "Epoch 1912: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3524 - val_loss: 1.1094\n",
      "Epoch 1913/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3524\n",
      "Epoch 1913: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3524 - val_loss: 1.1058\n",
      "Epoch 1914/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3525\n",
      "Epoch 1914: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3525 - val_loss: 1.1140\n",
      "Epoch 1915/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3535\n",
      "Epoch 1915: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3535 - val_loss: 1.1030\n",
      "Epoch 1916/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3539\n",
      "Epoch 1916: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.3539 - val_loss: 1.1153\n",
      "Epoch 1917/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3538\n",
      "Epoch 1917: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3538 - val_loss: 1.1031\n",
      "Epoch 1918/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3527\n",
      "Epoch 1918: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3527 - val_loss: 1.1145\n",
      "Epoch 1919/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3536\n",
      "Epoch 1919: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3536 - val_loss: 1.1001\n",
      "Epoch 1920/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3566\n",
      "Epoch 1920: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3566 - val_loss: 1.1229\n",
      "Epoch 1921/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3636\n",
      "Epoch 1921: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3636 - val_loss: 1.1038\n",
      "Epoch 1922/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3533\n",
      "Epoch 1922: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3533 - val_loss: 1.1125\n",
      "Epoch 1923/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3525\n",
      "Epoch 1923: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3525 - val_loss: 1.1076\n",
      "Epoch 1924/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3511\n",
      "Epoch 1924: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3511 - val_loss: 1.1067\n",
      "Epoch 1925/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3521\n",
      "Epoch 1925: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3521 - val_loss: 1.1055\n",
      "Epoch 1926/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3514\n",
      "Epoch 1926: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3514 - val_loss: 1.1105\n",
      "Epoch 1927/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3509\n",
      "Epoch 1927: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.3509 - val_loss: 1.1048\n",
      "Epoch 1928/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3519\n",
      "Epoch 1928: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3519 - val_loss: 1.1170\n",
      "Epoch 1929/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3548\n",
      "Epoch 1929: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3548 - val_loss: 1.1000\n",
      "Epoch 1930/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3583\n",
      "Epoch 1930: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.3583 - val_loss: 1.1233\n",
      "Epoch 1931/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3625\n",
      "Epoch 1931: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.3625 - val_loss: 1.1037\n",
      "Epoch 1932/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3533\n",
      "Epoch 1932: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3533 - val_loss: 1.1181\n",
      "Epoch 1933/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3548\n",
      "Epoch 1933: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3548 - val_loss: 1.1042\n",
      "Epoch 1934/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3525\n",
      "Epoch 1934: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3525 - val_loss: 1.1149\n",
      "Epoch 1935/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3528\n",
      "Epoch 1935: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3528 - val_loss: 1.1025\n",
      "Epoch 1936/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3521\n",
      "Epoch 1936: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3521 - val_loss: 1.1129\n",
      "Epoch 1937/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3516\n",
      "Epoch 1937: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3516 - val_loss: 1.1000\n",
      "Epoch 1938/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3546\n",
      "Epoch 1938: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3546 - val_loss: 1.1170\n",
      "Epoch 1939/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3567\n",
      "Epoch 1939: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3567 - val_loss: 1.0998\n",
      "Epoch 1940/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3574\n",
      "Epoch 1940: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3574 - val_loss: 1.1190\n",
      "Epoch 1941/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3569\n",
      "Epoch 1941: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3569 - val_loss: 1.1035\n",
      "Epoch 1942/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3522\n",
      "Epoch 1942: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3522 - val_loss: 1.1132\n",
      "Epoch 1943/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3517\n",
      "Epoch 1943: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3517 - val_loss: 1.1072\n",
      "Epoch 1944/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3512\n",
      "Epoch 1944: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3512 - val_loss: 1.1150\n",
      "Epoch 1945/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3518\n",
      "Epoch 1945: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3518 - val_loss: 1.1076\n",
      "Epoch 1946/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3503\n",
      "Epoch 1946: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3503 - val_loss: 1.1142\n",
      "Epoch 1947/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3517\n",
      "Epoch 1947: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3517 - val_loss: 1.1048\n",
      "Epoch 1948/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3514\n",
      "Epoch 1948: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3514 - val_loss: 1.1142\n",
      "Epoch 1949/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3523\n",
      "Epoch 1949: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3523 - val_loss: 1.1021\n",
      "Epoch 1950/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3507\n",
      "Epoch 1950: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.3507 - val_loss: 1.1134\n",
      "Epoch 1951/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3521\n",
      "Epoch 1951: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.3521 - val_loss: 1.0985\n",
      "Epoch 1952/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3548\n",
      "Epoch 1952: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3548 - val_loss: 1.1202\n",
      "Epoch 1953/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3605\n",
      "Epoch 1953: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.3605 - val_loss: 1.1009\n",
      "Epoch 1954/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3529\n",
      "Epoch 1954: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3529 - val_loss: 1.1168\n",
      "Epoch 1955/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.3551\n",
      "Epoch 1955: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3551 - val_loss: 1.1003\n",
      "Epoch 1956/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3555\n",
      "Epoch 1956: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3555 - val_loss: 1.1175\n",
      "Epoch 1957/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3540\n",
      "Epoch 1957: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3540 - val_loss: 1.1024\n",
      "Epoch 1958/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3526\n",
      "Epoch 1958: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3526 - val_loss: 1.1129\n",
      "Epoch 1959/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3509\n",
      "Epoch 1959: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3509 - val_loss: 1.1017\n",
      "Epoch 1960/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3509\n",
      "Epoch 1960: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3509 - val_loss: 1.1113\n",
      "Epoch 1961/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.3500\n",
      "Epoch 1961: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3500 - val_loss: 1.1007\n",
      "Epoch 1962/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3510\n",
      "Epoch 1962: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3510 - val_loss: 1.1131\n",
      "Epoch 1963/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3508\n",
      "Epoch 1963: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.3508 - val_loss: 1.1058\n",
      "Epoch 1964/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3502\n",
      "Epoch 1964: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3502 - val_loss: 1.1174\n",
      "Epoch 1965/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3522\n",
      "Epoch 1965: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3522 - val_loss: 1.1059\n",
      "Epoch 1966/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3491\n",
      "Epoch 1966: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3491 - val_loss: 1.1145\n",
      "Epoch 1967/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3504\n",
      "Epoch 1967: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.3504 - val_loss: 1.1024\n",
      "Epoch 1968/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3508\n",
      "Epoch 1968: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3508 - val_loss: 1.1169\n",
      "Epoch 1969/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3543\n",
      "Epoch 1969: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3543 - val_loss: 1.1001\n",
      "Epoch 1970/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3519\n",
      "Epoch 1970: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3519 - val_loss: 1.1179\n",
      "Epoch 1971/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3570\n",
      "Epoch 1971: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3570 - val_loss: 1.1005\n",
      "Epoch 1972/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3528\n",
      "Epoch 1972: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.3528 - val_loss: 1.1168\n",
      "Epoch 1973/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3530\n",
      "Epoch 1973: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.3530 - val_loss: 1.1017\n",
      "Epoch 1974/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3531\n",
      "Epoch 1974: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3531 - val_loss: 1.1188\n",
      "Epoch 1975/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3537\n",
      "Epoch 1975: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3537 - val_loss: 1.1030\n",
      "Epoch 1976/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3521\n",
      "Epoch 1976: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3521 - val_loss: 1.1155\n",
      "Epoch 1977/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3513\n",
      "Epoch 1977: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3513 - val_loss: 1.1018\n",
      "Epoch 1978/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3507\n",
      "Epoch 1978: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3507 - val_loss: 1.1124\n",
      "Epoch 1979/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3496\n",
      "Epoch 1979: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3496 - val_loss: 1.1017\n",
      "Epoch 1980/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3496\n",
      "Epoch 1980: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3496 - val_loss: 1.1118\n",
      "Epoch 1981/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3493\n",
      "Epoch 1981: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3493 - val_loss: 1.1007\n",
      "Epoch 1982/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3496\n",
      "Epoch 1982: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3496 - val_loss: 1.1113\n",
      "Epoch 1983/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3492\n",
      "Epoch 1983: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3492 - val_loss: 1.1040\n",
      "Epoch 1984/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3505\n",
      "Epoch 1984: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.3505 - val_loss: 1.1196\n",
      "Epoch 1985/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3537\n",
      "Epoch 1985: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3537 - val_loss: 1.1045\n",
      "Epoch 1986/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3502\n",
      "Epoch 1986: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3502 - val_loss: 1.1171\n",
      "Epoch 1987/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3518\n",
      "Epoch 1987: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3518 - val_loss: 1.1016\n",
      "Epoch 1988/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3507\n",
      "Epoch 1988: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3507 - val_loss: 1.1177\n",
      "Epoch 1989/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3518\n",
      "Epoch 1989: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3518 - val_loss: 1.1023\n",
      "Epoch 1990/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3507\n",
      "Epoch 1990: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3507 - val_loss: 1.1170\n",
      "Epoch 1991/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3516\n",
      "Epoch 1991: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3516 - val_loss: 1.1018\n",
      "Epoch 1992/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3500\n",
      "Epoch 1992: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3500 - val_loss: 1.1172\n",
      "Epoch 1993/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3528\n",
      "Epoch 1993: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3528 - val_loss: 1.1008\n",
      "Epoch 1994/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3527\n",
      "Epoch 1994: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3527 - val_loss: 1.1176\n",
      "Epoch 1995/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3516\n",
      "Epoch 1995: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.3516 - val_loss: 1.1030\n",
      "Epoch 1996/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3503\n",
      "Epoch 1996: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3503 - val_loss: 1.1142\n",
      "Epoch 1997/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3493\n",
      "Epoch 1997: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3493 - val_loss: 1.1026\n",
      "Epoch 1998/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3484\n",
      "Epoch 1998: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3484 - val_loss: 1.1126\n",
      "Epoch 1999/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3484\n",
      "Epoch 1999: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3484 - val_loss: 1.1016\n",
      "Epoch 2000/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3485\n",
      "Epoch 2000: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3485 - val_loss: 1.1145\n",
      "Epoch 2001/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3494\n",
      "Epoch 2001: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3494 - val_loss: 1.1015\n",
      "Epoch 2002/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3491\n",
      "Epoch 2002: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3491 - val_loss: 1.1133\n",
      "Epoch 2003/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3490\n",
      "Epoch 2003: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3490 - val_loss: 1.1017\n",
      "Epoch 2004/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3478\n",
      "Epoch 2004: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3478 - val_loss: 1.1127\n",
      "Epoch 2005/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3489\n",
      "Epoch 2005: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3489 - val_loss: 1.1045\n",
      "Epoch 2006/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3482\n",
      "Epoch 2006: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.3482 - val_loss: 1.1159\n",
      "Epoch 2007/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3529\n",
      "Epoch 2007: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3529 - val_loss: 1.1026\n",
      "Epoch 2008/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3518\n",
      "Epoch 2008: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3518 - val_loss: 1.1217\n",
      "Epoch 2009/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3531\n",
      "Epoch 2009: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3531 - val_loss: 1.1036\n",
      "Epoch 2010/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3522\n",
      "Epoch 2010: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3522 - val_loss: 1.1202\n",
      "Epoch 2011/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3507\n",
      "Epoch 2011: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3507 - val_loss: 1.1067\n",
      "Epoch 2012/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3474\n",
      "Epoch 2012: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3474 - val_loss: 1.1143\n",
      "Epoch 2013/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3480\n",
      "Epoch 2013: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3480 - val_loss: 1.1034\n",
      "Epoch 2014/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3474\n",
      "Epoch 2014: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3474 - val_loss: 1.1138\n",
      "Epoch 2015/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3478\n",
      "Epoch 2015: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3478 - val_loss: 1.1024\n",
      "Epoch 2016/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3476\n",
      "Epoch 2016: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3476 - val_loss: 1.1159\n",
      "Epoch 2017/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3487\n",
      "Epoch 2017: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3487 - val_loss: 1.1022\n",
      "Epoch 2018/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3482\n",
      "Epoch 2018: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3482 - val_loss: 1.1118\n",
      "Epoch 2019/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3480\n",
      "Epoch 2019: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3480 - val_loss: 1.1025\n",
      "Epoch 2020/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3467\n",
      "Epoch 2020: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3467 - val_loss: 1.1141\n",
      "Epoch 2021/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3481\n",
      "Epoch 2021: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3481 - val_loss: 1.0996\n",
      "Epoch 2022/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3489\n",
      "Epoch 2022: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3489 - val_loss: 1.1168\n",
      "Epoch 2023/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3522\n",
      "Epoch 2023: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3522 - val_loss: 1.0987\n",
      "Epoch 2024/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3532\n",
      "Epoch 2024: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.3532 - val_loss: 1.1219\n",
      "Epoch 2025/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3551\n",
      "Epoch 2025: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3551 - val_loss: 1.1031\n",
      "Epoch 2026/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3499\n",
      "Epoch 2026: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3499 - val_loss: 1.1142\n",
      "Epoch 2027/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3469\n",
      "Epoch 2027: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3469 - val_loss: 1.1050\n",
      "Epoch 2028/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3464\n",
      "Epoch 2028: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3464 - val_loss: 1.1102\n",
      "Epoch 2029/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3463\n",
      "Epoch 2029: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3463 - val_loss: 1.1030\n",
      "Epoch 2030/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3457\n",
      "Epoch 2030: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3457 - val_loss: 1.1084\n",
      "Epoch 2031/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3463\n",
      "Epoch 2031: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3463 - val_loss: 1.0989\n",
      "Epoch 2032/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3473\n",
      "Epoch 2032: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3473 - val_loss: 1.1137\n",
      "Epoch 2033/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3487\n",
      "Epoch 2033: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3487 - val_loss: 1.0986\n",
      "Epoch 2034/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3491\n",
      "Epoch 2034: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3491 - val_loss: 1.1163\n",
      "Epoch 2035/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3511\n",
      "Epoch 2035: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3511 - val_loss: 1.1023\n",
      "Epoch 2036/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3507\n",
      "Epoch 2036: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.3507 - val_loss: 1.1233\n",
      "Epoch 2037/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3527\n",
      "Epoch 2037: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3527 - val_loss: 1.1054\n",
      "Epoch 2038/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3481\n",
      "Epoch 2038: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3481 - val_loss: 1.1135\n",
      "Epoch 2039/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3469\n",
      "Epoch 2039: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3469 - val_loss: 1.1035\n",
      "Epoch 2040/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3458\n",
      "Epoch 2040: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3458 - val_loss: 1.1087\n",
      "Epoch 2041/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3451\n",
      "Epoch 2041: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3451 - val_loss: 1.1016\n",
      "Epoch 2042/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3459\n",
      "Epoch 2042: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3459 - val_loss: 1.1094\n",
      "Epoch 2043/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3456\n",
      "Epoch 2043: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3456 - val_loss: 1.1013\n",
      "Epoch 2044/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3469\n",
      "Epoch 2044: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3469 - val_loss: 1.1171\n",
      "Epoch 2045/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3488\n",
      "Epoch 2045: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3488 - val_loss: 1.1029\n",
      "Epoch 2046/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3456\n",
      "Epoch 2046: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.3456 - val_loss: 1.1198\n",
      "Epoch 2047/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3514\n",
      "Epoch 2047: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.3514 - val_loss: 1.1007\n",
      "Epoch 2048/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3515\n",
      "Epoch 2048: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3515 - val_loss: 1.1205\n",
      "Epoch 2049/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3509\n",
      "Epoch 2049: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3509 - val_loss: 1.1042\n",
      "Epoch 2050/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3483\n",
      "Epoch 2050: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3483 - val_loss: 1.1197\n",
      "Epoch 2051/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3488\n",
      "Epoch 2051: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3488 - val_loss: 1.1060\n",
      "Epoch 2052/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3456\n",
      "Epoch 2052: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3456 - val_loss: 1.1083\n",
      "Epoch 2053/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3443\n",
      "Epoch 2053: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3443 - val_loss: 1.1015\n",
      "Epoch 2054/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3456\n",
      "Epoch 2054: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3456 - val_loss: 1.1085\n",
      "Epoch 2055/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3443\n",
      "Epoch 2055: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.3443 - val_loss: 1.1040\n",
      "Epoch 2056/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3449\n",
      "Epoch 2056: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.3449 - val_loss: 1.1079\n",
      "Epoch 2057/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3441\n",
      "Epoch 2057: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.3441 - val_loss: 1.1032\n",
      "Epoch 2058/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3447\n",
      "Epoch 2058: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3447 - val_loss: 1.1087\n",
      "Epoch 2059/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3448\n",
      "Epoch 2059: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3448 - val_loss: 1.0960\n",
      "Epoch 2060/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3497\n",
      "Epoch 2060: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3497 - val_loss: 1.1182\n",
      "Epoch 2061/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3529\n",
      "Epoch 2061: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3529 - val_loss: 1.0990\n",
      "Epoch 2062/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3492\n",
      "Epoch 2062: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3492 - val_loss: 1.1201\n",
      "Epoch 2063/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3522\n",
      "Epoch 2063: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3522 - val_loss: 1.1016\n",
      "Epoch 2064/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3478\n",
      "Epoch 2064: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3478 - val_loss: 1.1169\n",
      "Epoch 2065/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3480\n",
      "Epoch 2065: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3480 - val_loss: 1.1026\n",
      "Epoch 2066/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3451\n",
      "Epoch 2066: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3451 - val_loss: 1.1144\n",
      "Epoch 2067/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3457\n",
      "Epoch 2067: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.3457 - val_loss: 1.1045\n",
      "Epoch 2068/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3435\n",
      "Epoch 2068: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.3435 - val_loss: 1.1095\n",
      "Epoch 2069/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3438\n",
      "Epoch 2069: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3438 - val_loss: 1.1026\n",
      "Epoch 2070/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3443\n",
      "Epoch 2070: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3443 - val_loss: 1.1099\n",
      "Epoch 2071/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3448\n",
      "Epoch 2071: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3448 - val_loss: 1.0974\n",
      "Epoch 2072/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3486\n",
      "Epoch 2072: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3486 - val_loss: 1.1193\n",
      "Epoch 2073/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3530\n",
      "Epoch 2073: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3530 - val_loss: 1.1003\n",
      "Epoch 2074/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3472\n",
      "Epoch 2074: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3472 - val_loss: 1.1165\n",
      "Epoch 2075/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3472\n",
      "Epoch 2075: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3472 - val_loss: 1.1021\n",
      "Epoch 2076/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3470\n",
      "Epoch 2076: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3470 - val_loss: 1.1178\n",
      "Epoch 2077/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3467\n",
      "Epoch 2077: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3467 - val_loss: 1.1048\n",
      "Epoch 2078/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3443\n",
      "Epoch 2078: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.3443 - val_loss: 1.1145\n",
      "Epoch 2079/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3452\n",
      "Epoch 2079: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.3452 - val_loss: 1.1034\n",
      "Epoch 2080/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3435\n",
      "Epoch 2080: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3435 - val_loss: 1.1160\n",
      "Epoch 2081/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3456\n",
      "Epoch 2081: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3456 - val_loss: 1.1012\n",
      "Epoch 2082/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3455\n",
      "Epoch 2082: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3455 - val_loss: 1.1184\n",
      "Epoch 2083/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3494\n",
      "Epoch 2083: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3494 - val_loss: 1.1024\n",
      "Epoch 2084/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3477\n",
      "Epoch 2084: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3477 - val_loss: 1.1196\n",
      "Epoch 2085/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3474\n",
      "Epoch 2085: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3474 - val_loss: 1.1045\n",
      "Epoch 2086/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3459\n",
      "Epoch 2086: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3459 - val_loss: 1.1159\n",
      "Epoch 2087/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3466\n",
      "Epoch 2087: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3466 - val_loss: 1.1017\n",
      "Epoch 2088/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3446\n",
      "Epoch 2088: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.3446 - val_loss: 1.1133\n",
      "Epoch 2089/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3444\n",
      "Epoch 2089: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3444 - val_loss: 1.1036\n",
      "Epoch 2090/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3426\n",
      "Epoch 2090: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3426 - val_loss: 1.1124\n",
      "Epoch 2091/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3443\n",
      "Epoch 2091: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3443 - val_loss: 1.1046\n",
      "Epoch 2092/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3426\n",
      "Epoch 2092: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3426 - val_loss: 1.1094\n",
      "Epoch 2093/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3430\n",
      "Epoch 2093: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3430 - val_loss: 1.1037\n",
      "Epoch 2094/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3424\n",
      "Epoch 2094: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3424 - val_loss: 1.1087\n",
      "Epoch 2095/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3432\n",
      "Epoch 2095: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3432 - val_loss: 1.0977\n",
      "Epoch 2096/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3462\n",
      "Epoch 2096: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3462 - val_loss: 1.1172\n",
      "Epoch 2097/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3486\n",
      "Epoch 2097: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3486 - val_loss: 1.0981\n",
      "Epoch 2098/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3498\n",
      "Epoch 2098: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3498 - val_loss: 1.1168\n",
      "Epoch 2099/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3471\n",
      "Epoch 2099: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.3471 - val_loss: 1.1021\n",
      "Epoch 2100/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3441\n",
      "Epoch 2100: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.3441 - val_loss: 1.1176\n",
      "Epoch 2101/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3477\n",
      "Epoch 2101: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3477 - val_loss: 1.1010\n",
      "Epoch 2102/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3479\n",
      "Epoch 2102: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3479 - val_loss: 1.1143\n",
      "Epoch 2103/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3448\n",
      "Epoch 2103: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3448 - val_loss: 1.0991\n",
      "Epoch 2104/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3470\n",
      "Epoch 2104: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3470 - val_loss: 1.1167\n",
      "Epoch 2105/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3468\n",
      "Epoch 2105: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3468 - val_loss: 1.1003\n",
      "Epoch 2106/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3456\n",
      "Epoch 2106: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3456 - val_loss: 1.1152\n",
      "Epoch 2107/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3448\n",
      "Epoch 2107: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3448 - val_loss: 1.1036\n",
      "Epoch 2108/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3423\n",
      "Epoch 2108: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.3423 - val_loss: 1.1119\n",
      "Epoch 2109/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3429\n",
      "Epoch 2109: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3429 - val_loss: 1.1033\n",
      "Epoch 2110/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3413\n",
      "Epoch 2110: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.3413 - val_loss: 1.1124\n",
      "Epoch 2111/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3431\n",
      "Epoch 2111: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3431 - val_loss: 1.1018\n",
      "Epoch 2112/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3420\n",
      "Epoch 2112: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.3420 - val_loss: 1.1146\n",
      "Epoch 2113/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3442\n",
      "Epoch 2113: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3442 - val_loss: 1.1010\n",
      "Epoch 2114/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3438\n",
      "Epoch 2114: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.3438 - val_loss: 1.1139\n",
      "Epoch 2115/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3435\n",
      "Epoch 2115: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3435 - val_loss: 1.1029\n",
      "Epoch 2116/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3415\n",
      "Epoch 2116: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3415 - val_loss: 1.1110\n",
      "Epoch 2117/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3451\n",
      "Epoch 2117: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3451 - val_loss: 1.0982\n",
      "Epoch 2118/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3493\n",
      "Epoch 2118: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3493 - val_loss: 1.1194\n",
      "Epoch 2119/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3485\n",
      "Epoch 2119: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3485 - val_loss: 1.1006\n",
      "Epoch 2120/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3475\n",
      "Epoch 2120: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3475 - val_loss: 1.1157\n",
      "Epoch 2121/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3456\n",
      "Epoch 2121: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3456 - val_loss: 1.1011\n",
      "Epoch 2122/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3433\n",
      "Epoch 2122: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3433 - val_loss: 1.1098\n",
      "Epoch 2123/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3421\n",
      "Epoch 2123: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3421 - val_loss: 1.1032\n",
      "Epoch 2124/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3411\n",
      "Epoch 2124: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3411 - val_loss: 1.1111\n",
      "Epoch 2125/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3427\n",
      "Epoch 2125: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3427 - val_loss: 1.0991\n",
      "Epoch 2126/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3430\n",
      "Epoch 2126: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3430 - val_loss: 1.1153\n",
      "Epoch 2127/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3463\n",
      "Epoch 2127: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3463 - val_loss: 1.0974\n",
      "Epoch 2128/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3461\n",
      "Epoch 2128: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3461 - val_loss: 1.1164\n",
      "Epoch 2129/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3472\n",
      "Epoch 2129: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.3472 - val_loss: 1.0996\n",
      "Epoch 2130/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3458\n",
      "Epoch 2130: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3458 - val_loss: 1.1177\n",
      "Epoch 2131/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3459\n",
      "Epoch 2131: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.3459 - val_loss: 1.1022\n",
      "Epoch 2132/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3433\n",
      "Epoch 2132: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.3433 - val_loss: 1.1115\n",
      "Epoch 2133/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3424\n",
      "Epoch 2133: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3424 - val_loss: 1.1009\n",
      "Epoch 2134/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3420\n",
      "Epoch 2134: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.3420 - val_loss: 1.1096\n",
      "Epoch 2135/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3423\n",
      "Epoch 2135: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3423 - val_loss: 1.0966\n",
      "Epoch 2136/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3440\n",
      "Epoch 2136: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.3440 - val_loss: 1.1135\n",
      "Epoch 2137/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3451\n",
      "Epoch 2137: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3451 - val_loss: 1.0965\n",
      "Epoch 2138/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3469\n",
      "Epoch 2138: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3469 - val_loss: 1.1154\n",
      "Epoch 2139/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3462\n",
      "Epoch 2139: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3462 - val_loss: 1.1000\n",
      "Epoch 2140/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3423\n",
      "Epoch 2140: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3423 - val_loss: 1.1094\n",
      "Epoch 2141/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3413\n",
      "Epoch 2141: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3413 - val_loss: 1.0999\n",
      "Epoch 2142/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3410\n",
      "Epoch 2142: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3410 - val_loss: 1.1122\n",
      "Epoch 2143/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3423\n",
      "Epoch 2143: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3423 - val_loss: 1.1007\n",
      "Epoch 2144/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3413\n",
      "Epoch 2144: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3413 - val_loss: 1.1145\n",
      "Epoch 2145/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.3448\n",
      "Epoch 2145: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.3448 - val_loss: 1.0992\n",
      "Epoch 2146/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3457\n",
      "Epoch 2146: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3457 - val_loss: 1.1187\n",
      "Epoch 2147/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3476\n",
      "Epoch 2147: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3476 - val_loss: 1.1029\n",
      "Epoch 2148/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3439\n",
      "Epoch 2148: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3439 - val_loss: 1.1121\n",
      "Epoch 2149/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3422\n",
      "Epoch 2149: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3422 - val_loss: 1.1015\n",
      "Epoch 2150/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3412\n",
      "Epoch 2150: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3412 - val_loss: 1.1091\n",
      "Epoch 2151/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3413\n",
      "Epoch 2151: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3413 - val_loss: 1.0962\n",
      "Epoch 2152/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3443\n",
      "Epoch 2152: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3443 - val_loss: 1.1131\n",
      "Epoch 2153/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3436\n",
      "Epoch 2153: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3436 - val_loss: 1.0966\n",
      "Epoch 2154/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3454\n",
      "Epoch 2154: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3454 - val_loss: 1.1161\n",
      "Epoch 2155/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3470\n",
      "Epoch 2155: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3470 - val_loss: 1.0996\n",
      "Epoch 2156/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3425\n",
      "Epoch 2156: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.3425 - val_loss: 1.1135\n",
      "Epoch 2157/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3428\n",
      "Epoch 2157: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3428 - val_loss: 1.1004\n",
      "Epoch 2158/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3427\n",
      "Epoch 2158: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3427 - val_loss: 1.1159\n",
      "Epoch 2159/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3436\n",
      "Epoch 2159: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3436 - val_loss: 1.1002\n",
      "Epoch 2160/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3433\n",
      "Epoch 2160: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3433 - val_loss: 1.1128\n",
      "Epoch 2161/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3418\n",
      "Epoch 2161: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3418 - val_loss: 1.1012\n",
      "Epoch 2162/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3409\n",
      "Epoch 2162: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3409 - val_loss: 1.1147\n",
      "Epoch 2163/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3428\n",
      "Epoch 2163: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3428 - val_loss: 1.1005\n",
      "Epoch 2164/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3411\n",
      "Epoch 2164: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3411 - val_loss: 1.1143\n",
      "Epoch 2165/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3425\n",
      "Epoch 2165: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3425 - val_loss: 1.0999\n",
      "Epoch 2166/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3413\n",
      "Epoch 2166: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3413 - val_loss: 1.1138\n",
      "Epoch 2167/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3426\n",
      "Epoch 2167: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3426 - val_loss: 1.1001\n",
      "Epoch 2168/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3422\n",
      "Epoch 2168: val_loss did not improve from 1.09534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3422 - val_loss: 1.1079\n",
      "Epoch 2169/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3398\n",
      "Epoch 2169: val_loss improved from 1.09534 to 1.09488, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.3398 - val_loss: 1.0949\n",
      "Epoch 2170/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3441\n",
      "Epoch 2170: val_loss did not improve from 1.09488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3441 - val_loss: 1.1156\n",
      "Epoch 2171/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3490\n",
      "Epoch 2171: val_loss did not improve from 1.09488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3490 - val_loss: 1.0977\n",
      "Epoch 2172/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3432\n",
      "Epoch 2172: val_loss did not improve from 1.09488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3432 - val_loss: 1.1147\n",
      "Epoch 2173/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3451\n",
      "Epoch 2173: val_loss did not improve from 1.09488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3451 - val_loss: 1.0991\n",
      "Epoch 2174/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3423\n",
      "Epoch 2174: val_loss did not improve from 1.09488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3423 - val_loss: 1.1141\n",
      "Epoch 2175/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3428\n",
      "Epoch 2175: val_loss did not improve from 1.09488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3428 - val_loss: 1.1018\n",
      "Epoch 2176/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3401\n",
      "Epoch 2176: val_loss did not improve from 1.09488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3401 - val_loss: 1.1101\n",
      "Epoch 2177/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3402\n",
      "Epoch 2177: val_loss did not improve from 1.09488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3402 - val_loss: 1.1023\n",
      "Epoch 2178/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3392\n",
      "Epoch 2178: val_loss did not improve from 1.09488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3392 - val_loss: 1.1052\n",
      "Epoch 2179/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3391\n",
      "Epoch 2179: val_loss did not improve from 1.09488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.3391 - val_loss: 1.0972\n",
      "Epoch 2180/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3414\n",
      "Epoch 2180: val_loss did not improve from 1.09488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3414 - val_loss: 1.1104\n",
      "Epoch 2181/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3424\n",
      "Epoch 2181: val_loss did not improve from 1.09488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3424 - val_loss: 1.0964\n",
      "Epoch 2182/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3421\n",
      "Epoch 2182: val_loss did not improve from 1.09488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3421 - val_loss: 1.1127\n",
      "Epoch 2183/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3427\n",
      "Epoch 2183: val_loss did not improve from 1.09488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.3427 - val_loss: 1.0956\n",
      "Epoch 2184/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3471\n",
      "Epoch 2184: val_loss did not improve from 1.09488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3471 - val_loss: 1.1161\n",
      "Epoch 2185/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3463\n",
      "Epoch 2185: val_loss did not improve from 1.09488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3463 - val_loss: 1.0992\n",
      "Epoch 2186/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3437\n",
      "Epoch 2186: val_loss did not improve from 1.09488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3437 - val_loss: 1.1109\n",
      "Epoch 2187/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3417\n",
      "Epoch 2187: val_loss did not improve from 1.09488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3417 - val_loss: 1.0968\n",
      "Epoch 2188/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3436\n",
      "Epoch 2188: val_loss did not improve from 1.09488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3436 - val_loss: 1.1096\n",
      "Epoch 2189/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3401\n",
      "Epoch 2189: val_loss did not improve from 1.09488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3401 - val_loss: 1.0989\n",
      "Epoch 2190/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3397\n",
      "Epoch 2190: val_loss did not improve from 1.09488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3397 - val_loss: 1.1065\n",
      "Epoch 2191/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3389\n",
      "Epoch 2191: val_loss did not improve from 1.09488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3389 - val_loss: 1.1008\n",
      "Epoch 2192/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3391\n",
      "Epoch 2192: val_loss did not improve from 1.09488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3391 - val_loss: 1.1090\n",
      "Epoch 2193/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3407\n",
      "Epoch 2193: val_loss did not improve from 1.09488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3407 - val_loss: 1.0970\n",
      "Epoch 2194/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3420\n",
      "Epoch 2194: val_loss did not improve from 1.09488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3420 - val_loss: 1.1141\n",
      "Epoch 2195/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3432\n",
      "Epoch 2195: val_loss did not improve from 1.09488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3432 - val_loss: 1.0973\n",
      "Epoch 2196/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3452\n",
      "Epoch 2196: val_loss did not improve from 1.09488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3452 - val_loss: 1.1116\n",
      "Epoch 2197/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3432\n",
      "Epoch 2197: val_loss improved from 1.09488 to 1.09474, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.3432 - val_loss: 1.0947\n",
      "Epoch 2198/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.3458\n",
      "Epoch 2198: val_loss did not improve from 1.09474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3458 - val_loss: 1.1105\n",
      "Epoch 2199/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3412\n",
      "Epoch 2199: val_loss did not improve from 1.09474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3412 - val_loss: 1.0992\n",
      "Epoch 2200/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3399\n",
      "Epoch 2200: val_loss did not improve from 1.09474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3399 - val_loss: 1.1104\n",
      "Epoch 2201/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3401\n",
      "Epoch 2201: val_loss did not improve from 1.09474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3401 - val_loss: 1.0965\n",
      "Epoch 2202/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3409\n",
      "Epoch 2202: val_loss did not improve from 1.09474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3409 - val_loss: 1.1128\n",
      "Epoch 2203/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3432\n",
      "Epoch 2203: val_loss did not improve from 1.09474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3432 - val_loss: 1.0967\n",
      "Epoch 2204/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3424\n",
      "Epoch 2204: val_loss did not improve from 1.09474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3424 - val_loss: 1.1135\n",
      "Epoch 2205/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3429\n",
      "Epoch 2205: val_loss did not improve from 1.09474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3429 - val_loss: 1.0973\n",
      "Epoch 2206/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3441\n",
      "Epoch 2206: val_loss did not improve from 1.09474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3441 - val_loss: 1.1142\n",
      "Epoch 2207/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3420\n",
      "Epoch 2207: val_loss did not improve from 1.09474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3420 - val_loss: 1.0997\n",
      "Epoch 2208/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3415\n",
      "Epoch 2208: val_loss did not improve from 1.09474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3415 - val_loss: 1.1077\n",
      "Epoch 2209/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3388\n",
      "Epoch 2209: val_loss did not improve from 1.09474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3388 - val_loss: 1.0970\n",
      "Epoch 2210/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3410\n",
      "Epoch 2210: val_loss did not improve from 1.09474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3410 - val_loss: 1.1096\n",
      "Epoch 2211/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3406\n",
      "Epoch 2211: val_loss did not improve from 1.09474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3406 - val_loss: 1.1014\n",
      "Epoch 2212/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3375\n",
      "Epoch 2212: val_loss did not improve from 1.09474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3375 - val_loss: 1.1033\n",
      "Epoch 2213/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3373\n",
      "Epoch 2213: val_loss did not improve from 1.09474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3373 - val_loss: 1.1026\n",
      "Epoch 2214/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3376\n",
      "Epoch 2214: val_loss did not improve from 1.09474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3376 - val_loss: 1.1014\n",
      "Epoch 2215/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3375\n",
      "Epoch 2215: val_loss did not improve from 1.09474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3375 - val_loss: 1.1046\n",
      "Epoch 2216/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3377\n",
      "Epoch 2216: val_loss did not improve from 1.09474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3377 - val_loss: 1.0981\n",
      "Epoch 2217/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3382\n",
      "Epoch 2217: val_loss did not improve from 1.09474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3382 - val_loss: 1.1072\n",
      "Epoch 2218/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3384\n",
      "Epoch 2218: val_loss improved from 1.09474 to 1.09261, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.3384 - val_loss: 1.0926\n",
      "Epoch 2219/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3455\n",
      "Epoch 2219: val_loss did not improve from 1.09261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3455 - val_loss: 1.1151\n",
      "Epoch 2220/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3480\n",
      "Epoch 2220: val_loss did not improve from 1.09261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3480 - val_loss: 1.0947\n",
      "Epoch 2221/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3431\n",
      "Epoch 2221: val_loss did not improve from 1.09261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3431 - val_loss: 1.1151\n",
      "Epoch 2222/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3460\n",
      "Epoch 2222: val_loss did not improve from 1.09261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3460 - val_loss: 1.0968\n",
      "Epoch 2223/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3419\n",
      "Epoch 2223: val_loss did not improve from 1.09261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3419 - val_loss: 1.1101\n",
      "Epoch 2224/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3420\n",
      "Epoch 2224: val_loss did not improve from 1.09261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3420 - val_loss: 1.0968\n",
      "Epoch 2225/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3399\n",
      "Epoch 2225: val_loss did not improve from 1.09261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3399 - val_loss: 1.1089\n",
      "Epoch 2226/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3396\n",
      "Epoch 2226: val_loss did not improve from 1.09261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3396 - val_loss: 1.0971\n",
      "Epoch 2227/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3386\n",
      "Epoch 2227: val_loss did not improve from 1.09261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3386 - val_loss: 1.1098\n",
      "Epoch 2228/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3399\n",
      "Epoch 2228: val_loss did not improve from 1.09261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3399 - val_loss: 1.0954\n",
      "Epoch 2229/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3399\n",
      "Epoch 2229: val_loss did not improve from 1.09261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3399 - val_loss: 1.1124\n",
      "Epoch 2230/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3434\n",
      "Epoch 2230: val_loss did not improve from 1.09261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3434 - val_loss: 1.0946\n",
      "Epoch 2231/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3441\n",
      "Epoch 2231: val_loss did not improve from 1.09261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3441 - val_loss: 1.1128\n",
      "Epoch 2232/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3422\n",
      "Epoch 2232: val_loss did not improve from 1.09261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3422 - val_loss: 1.0964\n",
      "Epoch 2233/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3432\n",
      "Epoch 2233: val_loss did not improve from 1.09261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3432 - val_loss: 1.1113\n",
      "Epoch 2234/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3420\n",
      "Epoch 2234: val_loss did not improve from 1.09261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3420 - val_loss: 1.0967\n",
      "Epoch 2235/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3410\n",
      "Epoch 2235: val_loss did not improve from 1.09261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3410 - val_loss: 1.1092\n",
      "Epoch 2236/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3389\n",
      "Epoch 2236: val_loss did not improve from 1.09261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3389 - val_loss: 1.0998\n",
      "Epoch 2237/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3380\n",
      "Epoch 2237: val_loss did not improve from 1.09261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3380 - val_loss: 1.1056\n",
      "Epoch 2238/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3378\n",
      "Epoch 2238: val_loss did not improve from 1.09261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.3378 - val_loss: 1.0936\n",
      "Epoch 2239/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3403\n",
      "Epoch 2239: val_loss did not improve from 1.09261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3403 - val_loss: 1.1080\n",
      "Epoch 2240/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3393\n",
      "Epoch 2240: val_loss did not improve from 1.09261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3393 - val_loss: 1.0979\n",
      "Epoch 2241/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3373\n",
      "Epoch 2241: val_loss did not improve from 1.09261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3373 - val_loss: 1.1046\n",
      "Epoch 2242/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3372\n",
      "Epoch 2242: val_loss did not improve from 1.09261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3372 - val_loss: 1.0976\n",
      "Epoch 2243/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3369\n",
      "Epoch 2243: val_loss did not improve from 1.09261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3369 - val_loss: 1.1093\n",
      "Epoch 2244/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3392\n",
      "Epoch 2244: val_loss did not improve from 1.09261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3392 - val_loss: 1.0938\n",
      "Epoch 2245/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3406\n",
      "Epoch 2245: val_loss did not improve from 1.09261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3406 - val_loss: 1.1114\n",
      "Epoch 2246/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3422\n",
      "Epoch 2246: val_loss did not improve from 1.09261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3422 - val_loss: 1.0937\n",
      "Epoch 2247/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3445\n",
      "Epoch 2247: val_loss did not improve from 1.09261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3445 - val_loss: 1.1090\n",
      "Epoch 2248/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3422\n",
      "Epoch 2248: val_loss did not improve from 1.09261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3422 - val_loss: 1.0928\n",
      "Epoch 2249/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3431\n",
      "Epoch 2249: val_loss did not improve from 1.09261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3431 - val_loss: 1.1113\n",
      "Epoch 2250/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3421\n",
      "Epoch 2250: val_loss did not improve from 1.09261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3421 - val_loss: 1.0947\n",
      "Epoch 2251/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3425\n",
      "Epoch 2251: val_loss did not improve from 1.09261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3425 - val_loss: 1.1104\n",
      "Epoch 2252/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3402\n",
      "Epoch 2252: val_loss did not improve from 1.09261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3402 - val_loss: 1.1001\n",
      "Epoch 2253/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3367\n",
      "Epoch 2253: val_loss did not improve from 1.09261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3367 - val_loss: 1.1018\n",
      "Epoch 2254/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3363\n",
      "Epoch 2254: val_loss did not improve from 1.09261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3363 - val_loss: 1.0976\n",
      "Epoch 2255/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3358\n",
      "Epoch 2255: val_loss did not improve from 1.09261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3358 - val_loss: 1.1049\n",
      "Epoch 2256/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3375\n",
      "Epoch 2256: val_loss improved from 1.09261 to 1.09161, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3375 - val_loss: 1.0916\n",
      "Epoch 2257/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3399\n",
      "Epoch 2257: val_loss did not improve from 1.09161\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3399 - val_loss: 1.1100\n",
      "Epoch 2258/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3440\n",
      "Epoch 2258: val_loss improved from 1.09161 to 1.09089, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.3440 - val_loss: 1.0909\n",
      "Epoch 2259/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3427\n",
      "Epoch 2259: val_loss did not improve from 1.09089\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3427 - val_loss: 1.1106\n",
      "Epoch 2260/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3423\n",
      "Epoch 2260: val_loss did not improve from 1.09089\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.3423 - val_loss: 1.0939\n",
      "Epoch 2261/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3419\n",
      "Epoch 2261: val_loss did not improve from 1.09089\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3419 - val_loss: 1.1112\n",
      "Epoch 2262/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3414\n",
      "Epoch 2262: val_loss did not improve from 1.09089\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3414 - val_loss: 1.0960\n",
      "Epoch 2263/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3387\n",
      "Epoch 2263: val_loss did not improve from 1.09089\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3387 - val_loss: 1.1068\n",
      "Epoch 2264/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3380\n",
      "Epoch 2264: val_loss did not improve from 1.09089\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3380 - val_loss: 1.0972\n",
      "Epoch 2265/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3373\n",
      "Epoch 2265: val_loss did not improve from 1.09089\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3373 - val_loss: 1.1030\n",
      "Epoch 2266/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3369\n",
      "Epoch 2266: val_loss did not improve from 1.09089\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3369 - val_loss: 1.0922\n",
      "Epoch 2267/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3388\n",
      "Epoch 2267: val_loss did not improve from 1.09089\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3388 - val_loss: 1.1077\n",
      "Epoch 2268/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3409\n",
      "Epoch 2268: val_loss did not improve from 1.09089\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3409 - val_loss: 1.0913\n",
      "Epoch 2269/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3406\n",
      "Epoch 2269: val_loss did not improve from 1.09089\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.3406 - val_loss: 1.1090\n",
      "Epoch 2270/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.3418\n",
      "Epoch 2270: val_loss did not improve from 1.09089\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3418 - val_loss: 1.0927\n",
      "Epoch 2271/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3397\n",
      "Epoch 2271: val_loss did not improve from 1.09089\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3397 - val_loss: 1.1098\n",
      "Epoch 2272/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3414\n",
      "Epoch 2272: val_loss did not improve from 1.09089\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3414 - val_loss: 1.0941\n",
      "Epoch 2273/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3392\n",
      "Epoch 2273: val_loss did not improve from 1.09089\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.3392 - val_loss: 1.1075\n",
      "Epoch 2274/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3384\n",
      "Epoch 2274: val_loss did not improve from 1.09089\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3384 - val_loss: 1.0956\n",
      "Epoch 2275/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3386\n",
      "Epoch 2275: val_loss did not improve from 1.09089\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3386 - val_loss: 1.1058\n",
      "Epoch 2276/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3390\n",
      "Epoch 2276: val_loss did not improve from 1.09089\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3390 - val_loss: 1.0944\n",
      "Epoch 2277/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3367\n",
      "Epoch 2277: val_loss did not improve from 1.09089\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3367 - val_loss: 1.1061\n",
      "Epoch 2278/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3376\n",
      "Epoch 2278: val_loss did not improve from 1.09089\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3376 - val_loss: 1.0938\n",
      "Epoch 2279/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3384\n",
      "Epoch 2279: val_loss did not improve from 1.09089\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3384 - val_loss: 1.1051\n",
      "Epoch 2280/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3394\n",
      "Epoch 2280: val_loss improved from 1.09089 to 1.09075, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.3394 - val_loss: 1.0907\n",
      "Epoch 2281/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3396\n",
      "Epoch 2281: val_loss did not improve from 1.09075\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3396 - val_loss: 1.1082\n",
      "Epoch 2282/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3413\n",
      "Epoch 2282: val_loss improved from 1.09075 to 1.09056, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3413 - val_loss: 1.0906\n",
      "Epoch 2283/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3427\n",
      "Epoch 2283: val_loss did not improve from 1.09056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3427 - val_loss: 1.1104\n",
      "Epoch 2284/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3420\n",
      "Epoch 2284: val_loss did not improve from 1.09056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3420 - val_loss: 1.0938\n",
      "Epoch 2285/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3396\n",
      "Epoch 2285: val_loss did not improve from 1.09056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.3396 - val_loss: 1.1082\n",
      "Epoch 2286/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3390\n",
      "Epoch 2286: val_loss did not improve from 1.09056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3390 - val_loss: 1.0958\n",
      "Epoch 2287/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3369\n",
      "Epoch 2287: val_loss did not improve from 1.09056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3369 - val_loss: 1.1059\n",
      "Epoch 2288/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3372\n",
      "Epoch 2288: val_loss did not improve from 1.09056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3372 - val_loss: 1.0977\n",
      "Epoch 2289/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.3353\n",
      "Epoch 2289: val_loss did not improve from 1.09056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.3353 - val_loss: 1.0979\n",
      "Epoch 2290/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3360\n",
      "Epoch 2290: val_loss did not improve from 1.09056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3360 - val_loss: 1.1011\n",
      "Epoch 2291/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3354\n",
      "Epoch 2291: val_loss did not improve from 1.09056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3354 - val_loss: 1.0936\n",
      "Epoch 2292/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3376\n",
      "Epoch 2292: val_loss did not improve from 1.09056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3376 - val_loss: 1.1070\n",
      "Epoch 2293/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3396\n",
      "Epoch 2293: val_loss improved from 1.09056 to 1.08941, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3396 - val_loss: 1.0894\n",
      "Epoch 2294/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3425\n",
      "Epoch 2294: val_loss did not improve from 1.08941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3425 - val_loss: 1.1097\n",
      "Epoch 2295/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3424\n",
      "Epoch 2295: val_loss did not improve from 1.08941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3424 - val_loss: 1.0915\n",
      "Epoch 2296/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3411\n",
      "Epoch 2296: val_loss did not improve from 1.08941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3411 - val_loss: 1.1080\n",
      "Epoch 2297/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3419\n",
      "Epoch 2297: val_loss did not improve from 1.08941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3419 - val_loss: 1.0921\n",
      "Epoch 2298/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3386\n",
      "Epoch 2298: val_loss did not improve from 1.08941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3386 - val_loss: 1.1049\n",
      "Epoch 2299/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3369\n",
      "Epoch 2299: val_loss did not improve from 1.08941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3369 - val_loss: 1.0933\n",
      "Epoch 2300/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3370\n",
      "Epoch 2300: val_loss did not improve from 1.08941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.3370 - val_loss: 1.1036\n",
      "Epoch 2301/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3361\n",
      "Epoch 2301: val_loss did not improve from 1.08941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3361 - val_loss: 1.0947\n",
      "Epoch 2302/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3355\n",
      "Epoch 2302: val_loss did not improve from 1.08941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3355 - val_loss: 1.1019\n",
      "Epoch 2303/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3364\n",
      "Epoch 2303: val_loss improved from 1.08941 to 1.08941, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3364 - val_loss: 1.0894\n",
      "Epoch 2304/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3385\n",
      "Epoch 2304: val_loss did not improve from 1.08941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3385 - val_loss: 1.1078\n",
      "Epoch 2305/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3422\n",
      "Epoch 2305: val_loss did not improve from 1.08941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3422 - val_loss: 1.0895\n",
      "Epoch 2306/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3415\n",
      "Epoch 2306: val_loss did not improve from 1.08941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3415 - val_loss: 1.1082\n",
      "Epoch 2307/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3408\n",
      "Epoch 2307: val_loss did not improve from 1.08941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3408 - val_loss: 1.0914\n",
      "Epoch 2308/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3404\n",
      "Epoch 2308: val_loss did not improve from 1.08941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3404 - val_loss: 1.1088\n",
      "Epoch 2309/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3399\n",
      "Epoch 2309: val_loss did not improve from 1.08941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.3399 - val_loss: 1.0936\n",
      "Epoch 2310/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3384\n",
      "Epoch 2310: val_loss did not improve from 1.08941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.3384 - val_loss: 1.1002\n",
      "Epoch 2311/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3349\n",
      "Epoch 2311: val_loss did not improve from 1.08941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3349 - val_loss: 1.0925\n",
      "Epoch 2312/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3355\n",
      "Epoch 2312: val_loss did not improve from 1.08941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3355 - val_loss: 1.1010\n",
      "Epoch 2313/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3353\n",
      "Epoch 2313: val_loss did not improve from 1.08941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3353 - val_loss: 1.0908\n",
      "Epoch 2314/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3374\n",
      "Epoch 2314: val_loss did not improve from 1.08941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3374 - val_loss: 1.1065\n",
      "Epoch 2315/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3395\n",
      "Epoch 2315: val_loss did not improve from 1.08941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3395 - val_loss: 1.0914\n",
      "Epoch 2316/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3368\n",
      "Epoch 2316: val_loss did not improve from 1.08941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3368 - val_loss: 1.1052\n",
      "Epoch 2317/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3372\n",
      "Epoch 2317: val_loss did not improve from 1.08941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3372 - val_loss: 1.0921\n",
      "Epoch 2318/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3381\n",
      "Epoch 2318: val_loss did not improve from 1.08941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.3381 - val_loss: 1.1067\n",
      "Epoch 2319/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3422\n",
      "Epoch 2319: val_loss did not improve from 1.08941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3422 - val_loss: 1.0902\n",
      "Epoch 2320/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3390\n",
      "Epoch 2320: val_loss did not improve from 1.08941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3390 - val_loss: 1.1074\n",
      "Epoch 2321/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3410\n",
      "Epoch 2321: val_loss did not improve from 1.08941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3410 - val_loss: 1.0903\n",
      "Epoch 2322/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3394\n",
      "Epoch 2322: val_loss did not improve from 1.08941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3394 - val_loss: 1.1082\n",
      "Epoch 2323/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3396\n",
      "Epoch 2323: val_loss did not improve from 1.08941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3396 - val_loss: 1.0939\n",
      "Epoch 2324/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3362\n",
      "Epoch 2324: val_loss did not improve from 1.08941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3362 - val_loss: 1.0959\n",
      "Epoch 2325/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3342\n",
      "Epoch 2325: val_loss did not improve from 1.08941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3342 - val_loss: 1.0998\n",
      "Epoch 2326/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3344\n",
      "Epoch 2326: val_loss did not improve from 1.08941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3344 - val_loss: 1.0916\n",
      "Epoch 2327/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3350\n",
      "Epoch 2327: val_loss did not improve from 1.08941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3350 - val_loss: 1.1037\n",
      "Epoch 2328/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3365\n",
      "Epoch 2328: val_loss improved from 1.08941 to 1.08740, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.3365 - val_loss: 1.0874\n",
      "Epoch 2329/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3426\n",
      "Epoch 2329: val_loss did not improve from 1.08740\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3426 - val_loss: 1.1081\n",
      "Epoch 2330/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3419\n",
      "Epoch 2330: val_loss did not improve from 1.08740\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3419 - val_loss: 1.0905\n",
      "Epoch 2331/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3386\n",
      "Epoch 2331: val_loss did not improve from 1.08740\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3386 - val_loss: 1.1073\n",
      "Epoch 2332/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3395\n",
      "Epoch 2332: val_loss did not improve from 1.08740\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3395 - val_loss: 1.0932\n",
      "Epoch 2333/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3365\n",
      "Epoch 2333: val_loss did not improve from 1.08740\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3365 - val_loss: 1.1004\n",
      "Epoch 2334/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3346\n",
      "Epoch 2334: val_loss did not improve from 1.08740\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3346 - val_loss: 1.0930\n",
      "Epoch 2335/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3344\n",
      "Epoch 2335: val_loss did not improve from 1.08740\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3344 - val_loss: 1.0995\n",
      "Epoch 2336/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3348\n",
      "Epoch 2336: val_loss did not improve from 1.08740\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3348 - val_loss: 1.0883\n",
      "Epoch 2337/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3375\n",
      "Epoch 2337: val_loss did not improve from 1.08740\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.3375 - val_loss: 1.1049\n",
      "Epoch 2338/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3390\n",
      "Epoch 2338: val_loss did not improve from 1.08740\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.3390 - val_loss: 1.0906\n",
      "Epoch 2339/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3374\n",
      "Epoch 2339: val_loss did not improve from 1.08740\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3374 - val_loss: 1.1038\n",
      "Epoch 2340/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3394\n",
      "Epoch 2340: val_loss improved from 1.08740 to 1.08724, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3394 - val_loss: 1.0872\n",
      "Epoch 2341/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3404\n",
      "Epoch 2341: val_loss did not improve from 1.08724\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3404 - val_loss: 1.1078\n",
      "Epoch 2342/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3415\n",
      "Epoch 2342: val_loss did not improve from 1.08724\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3415 - val_loss: 1.0903\n",
      "Epoch 2343/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3370\n",
      "Epoch 2343: val_loss did not improve from 1.08724\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3370 - val_loss: 1.1027\n",
      "Epoch 2344/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3357\n",
      "Epoch 2344: val_loss did not improve from 1.08724\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.3357 - val_loss: 1.0923\n",
      "Epoch 2345/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3354\n",
      "Epoch 2345: val_loss did not improve from 1.08724\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3354 - val_loss: 1.0980\n",
      "Epoch 2346/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3340\n",
      "Epoch 2346: val_loss did not improve from 1.08724\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3340 - val_loss: 1.0891\n",
      "Epoch 2347/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3348\n",
      "Epoch 2347: val_loss did not improve from 1.08724\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.3348 - val_loss: 1.1002\n",
      "Epoch 2348/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3344\n",
      "Epoch 2348: val_loss did not improve from 1.08724\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3344 - val_loss: 1.0886\n",
      "Epoch 2349/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3358\n",
      "Epoch 2349: val_loss did not improve from 1.08724\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3358 - val_loss: 1.1031\n",
      "Epoch 2350/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3370\n",
      "Epoch 2350: val_loss improved from 1.08724 to 1.08645, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3370 - val_loss: 1.0865\n",
      "Epoch 2351/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3412\n",
      "Epoch 2351: val_loss did not improve from 1.08645\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3412 - val_loss: 1.1077\n",
      "Epoch 2352/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3425\n",
      "Epoch 2352: val_loss did not improve from 1.08645\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.3425 - val_loss: 1.0890\n",
      "Epoch 2353/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3392\n",
      "Epoch 2353: val_loss did not improve from 1.08645\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.3392 - val_loss: 1.1026\n",
      "Epoch 2354/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3380\n",
      "Epoch 2354: val_loss did not improve from 1.08645\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3380 - val_loss: 1.0871\n",
      "Epoch 2355/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3383\n",
      "Epoch 2355: val_loss did not improve from 1.08645\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3383 - val_loss: 1.1022\n",
      "Epoch 2356/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3365\n",
      "Epoch 2356: val_loss did not improve from 1.08645\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.3365 - val_loss: 1.0909\n",
      "Epoch 2357/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3344\n",
      "Epoch 2357: val_loss did not improve from 1.08645\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.3344 - val_loss: 1.1000\n",
      "Epoch 2358/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3344\n",
      "Epoch 2358: val_loss did not improve from 1.08645\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3344 - val_loss: 1.0912\n",
      "Epoch 2359/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3337\n",
      "Epoch 2359: val_loss did not improve from 1.08645\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3337 - val_loss: 1.0982\n",
      "Epoch 2360/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3346\n",
      "Epoch 2360: val_loss improved from 1.08645 to 1.08601, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3346 - val_loss: 1.0860\n",
      "Epoch 2361/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3365\n",
      "Epoch 2361: val_loss did not improve from 1.08601\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3365 - val_loss: 1.1002\n",
      "Epoch 2362/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3352\n",
      "Epoch 2362: val_loss did not improve from 1.08601\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3352 - val_loss: 1.0878\n",
      "Epoch 2363/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3367\n",
      "Epoch 2363: val_loss did not improve from 1.08601\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3367 - val_loss: 1.1035\n",
      "Epoch 2364/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3388\n",
      "Epoch 2364: val_loss did not improve from 1.08601\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3388 - val_loss: 1.0866\n",
      "Epoch 2365/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3382\n",
      "Epoch 2365: val_loss did not improve from 1.08601\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.3382 - val_loss: 1.0998\n",
      "Epoch 2366/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3373\n",
      "Epoch 2366: val_loss improved from 1.08601 to 1.08556, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3373 - val_loss: 1.0856\n",
      "Epoch 2367/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3368\n",
      "Epoch 2367: val_loss did not improve from 1.08556\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3368 - val_loss: 1.0990\n",
      "Epoch 2368/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3354\n",
      "Epoch 2368: val_loss did not improve from 1.08556\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3354 - val_loss: 1.0886\n",
      "Epoch 2369/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3337\n",
      "Epoch 2369: val_loss did not improve from 1.08556\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3337 - val_loss: 1.1010\n",
      "Epoch 2370/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3352\n",
      "Epoch 2370: val_loss did not improve from 1.08556\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3352 - val_loss: 1.0863\n",
      "Epoch 2371/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3369\n",
      "Epoch 2371: val_loss did not improve from 1.08556\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3369 - val_loss: 1.1048\n",
      "Epoch 2372/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3402\n",
      "Epoch 2372: val_loss did not improve from 1.08556\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3402 - val_loss: 1.0873\n",
      "Epoch 2373/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3410\n",
      "Epoch 2373: val_loss did not improve from 1.08556\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3410 - val_loss: 1.1031\n",
      "Epoch 2374/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3384\n",
      "Epoch 2374: val_loss did not improve from 1.08556\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.3384 - val_loss: 1.0859\n",
      "Epoch 2375/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3389\n",
      "Epoch 2375: val_loss did not improve from 1.08556\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3389 - val_loss: 1.1037\n",
      "Epoch 2376/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3375\n",
      "Epoch 2376: val_loss did not improve from 1.08556\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3375 - val_loss: 1.0883\n",
      "Epoch 2377/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3366\n",
      "Epoch 2377: val_loss did not improve from 1.08556\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3366 - val_loss: 1.0985\n",
      "Epoch 2378/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3336\n",
      "Epoch 2378: val_loss did not improve from 1.08556\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3336 - val_loss: 1.0918\n",
      "Epoch 2379/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3322\n",
      "Epoch 2379: val_loss did not improve from 1.08556\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3322 - val_loss: 1.0935\n",
      "Epoch 2380/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.3331\n",
      "Epoch 2380: val_loss did not improve from 1.08556\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.3331 - val_loss: 1.0870\n",
      "Epoch 2381/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3339\n",
      "Epoch 2381: val_loss did not improve from 1.08556\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3339 - val_loss: 1.0991\n",
      "Epoch 2382/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3340\n",
      "Epoch 2382: val_loss improved from 1.08556 to 1.08547, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.3340 - val_loss: 1.0855\n",
      "Epoch 2383/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3347\n",
      "Epoch 2383: val_loss did not improve from 1.08547\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3347 - val_loss: 1.1016\n",
      "Epoch 2384/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3379\n",
      "Epoch 2384: val_loss improved from 1.08547 to 1.08480, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.3379 - val_loss: 1.0848\n",
      "Epoch 2385/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3413\n",
      "Epoch 2385: val_loss did not improve from 1.08480\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3413 - val_loss: 1.1055\n",
      "Epoch 2386/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3396\n",
      "Epoch 2386: val_loss did not improve from 1.08480\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3396 - val_loss: 1.0889\n",
      "Epoch 2387/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3355\n",
      "Epoch 2387: val_loss did not improve from 1.08480\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3355 - val_loss: 1.0989\n",
      "Epoch 2388/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3341\n",
      "Epoch 2388: val_loss did not improve from 1.08480\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3341 - val_loss: 1.0860\n",
      "Epoch 2389/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3379\n",
      "Epoch 2389: val_loss did not improve from 1.08480\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.3379 - val_loss: 1.1028\n",
      "Epoch 2390/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.3375\n",
      "Epoch 2390: val_loss did not improve from 1.08480\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3375 - val_loss: 1.0883\n",
      "Epoch 2391/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3355\n",
      "Epoch 2391: val_loss did not improve from 1.08480\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3355 - val_loss: 1.0981\n",
      "Epoch 2392/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3342\n",
      "Epoch 2392: val_loss did not improve from 1.08480\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3342 - val_loss: 1.0882\n",
      "Epoch 2393/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3330\n",
      "Epoch 2393: val_loss did not improve from 1.08480\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3330 - val_loss: 1.0987\n",
      "Epoch 2394/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3354\n",
      "Epoch 2394: val_loss did not improve from 1.08480\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3354 - val_loss: 1.0868\n",
      "Epoch 2395/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3339\n",
      "Epoch 2395: val_loss did not improve from 1.08480\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3339 - val_loss: 1.0985\n",
      "Epoch 2396/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3376\n",
      "Epoch 2396: val_loss improved from 1.08480 to 1.08130, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3376 - val_loss: 1.0813\n",
      "Epoch 2397/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3388\n",
      "Epoch 2397: val_loss did not improve from 1.08130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3388 - val_loss: 1.1008\n",
      "Epoch 2398/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3377\n",
      "Epoch 2398: val_loss did not improve from 1.08130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3377 - val_loss: 1.0847\n",
      "Epoch 2399/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3372\n",
      "Epoch 2399: val_loss did not improve from 1.08130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.3372 - val_loss: 1.0993\n",
      "Epoch 2400/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3368\n",
      "Epoch 2400: val_loss did not improve from 1.08130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.3368 - val_loss: 1.0831\n",
      "Epoch 2401/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3361\n",
      "Epoch 2401: val_loss did not improve from 1.08130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3361 - val_loss: 1.0962\n",
      "Epoch 2402/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3342\n",
      "Epoch 2402: val_loss did not improve from 1.08130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3342 - val_loss: 1.0867\n",
      "Epoch 2403/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3326\n",
      "Epoch 2403: val_loss did not improve from 1.08130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3326 - val_loss: 1.0950\n",
      "Epoch 2404/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3325\n",
      "Epoch 2404: val_loss did not improve from 1.08130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3325 - val_loss: 1.0863\n",
      "Epoch 2405/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3322\n",
      "Epoch 2405: val_loss did not improve from 1.08130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3322 - val_loss: 1.0983\n",
      "Epoch 2406/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3347\n",
      "Epoch 2406: val_loss did not improve from 1.08130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3347 - val_loss: 1.0820\n",
      "Epoch 2407/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3368\n",
      "Epoch 2407: val_loss did not improve from 1.08130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3368 - val_loss: 1.1024\n",
      "Epoch 2408/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3410\n",
      "Epoch 2408: val_loss did not improve from 1.08130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.3410 - val_loss: 1.0834\n",
      "Epoch 2409/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3375\n",
      "Epoch 2409: val_loss did not improve from 1.08130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.3375 - val_loss: 1.1005\n",
      "Epoch 2410/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3365\n",
      "Epoch 2410: val_loss did not improve from 1.08130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3365 - val_loss: 1.0853\n",
      "Epoch 2411/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3361\n",
      "Epoch 2411: val_loss did not improve from 1.08130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3361 - val_loss: 1.0977\n",
      "Epoch 2412/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3353\n",
      "Epoch 2412: val_loss did not improve from 1.08130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3353 - val_loss: 1.0820\n",
      "Epoch 2413/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3362\n",
      "Epoch 2413: val_loss did not improve from 1.08130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3362 - val_loss: 1.0972\n",
      "Epoch 2414/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3343\n",
      "Epoch 2414: val_loss did not improve from 1.08130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3343 - val_loss: 1.0869\n",
      "Epoch 2415/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3322\n",
      "Epoch 2415: val_loss did not improve from 1.08130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3322 - val_loss: 1.0959\n",
      "Epoch 2416/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3326\n",
      "Epoch 2416: val_loss did not improve from 1.08130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3326 - val_loss: 1.0854\n",
      "Epoch 2417/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3331\n",
      "Epoch 2417: val_loss did not improve from 1.08130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3331 - val_loss: 1.0999\n",
      "Epoch 2418/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3356\n",
      "Epoch 2418: val_loss did not improve from 1.08130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3356 - val_loss: 1.0829\n",
      "Epoch 2419/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.3404\n",
      "Epoch 2419: val_loss did not improve from 1.08130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3404 - val_loss: 1.1021\n",
      "Epoch 2420/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3366\n",
      "Epoch 2420: val_loss did not improve from 1.08130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.3366 - val_loss: 1.0855\n",
      "Epoch 2421/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3366\n",
      "Epoch 2421: val_loss did not improve from 1.08130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3366 - val_loss: 1.0988\n",
      "Epoch 2422/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3354\n",
      "Epoch 2422: val_loss did not improve from 1.08130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3354 - val_loss: 1.0840\n",
      "Epoch 2423/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3360\n",
      "Epoch 2423: val_loss did not improve from 1.08130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3360 - val_loss: 1.0980\n",
      "Epoch 2424/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3339\n",
      "Epoch 2424: val_loss did not improve from 1.08130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3339 - val_loss: 1.0889\n",
      "Epoch 2425/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3315\n",
      "Epoch 2425: val_loss did not improve from 1.08130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3315 - val_loss: 1.0890\n",
      "Epoch 2426/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3313\n",
      "Epoch 2426: val_loss did not improve from 1.08130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3313 - val_loss: 1.0885\n",
      "Epoch 2427/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3314\n",
      "Epoch 2427: val_loss did not improve from 1.08130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3314 - val_loss: 1.0889\n",
      "Epoch 2428/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.3312\n",
      "Epoch 2428: val_loss did not improve from 1.08130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.3312 - val_loss: 1.0855\n",
      "Epoch 2429/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3317\n",
      "Epoch 2429: val_loss did not improve from 1.08130\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3317 - val_loss: 1.0964\n",
      "Epoch 2430/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3351\n",
      "Epoch 2430: val_loss improved from 1.08130 to 1.07916, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3351 - val_loss: 1.0792\n",
      "Epoch 2431/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3423\n",
      "Epoch 2431: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3423 - val_loss: 1.1002\n",
      "Epoch 2432/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3368\n",
      "Epoch 2432: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3368 - val_loss: 1.0819\n",
      "Epoch 2433/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3373\n",
      "Epoch 2433: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3373 - val_loss: 1.1020\n",
      "Epoch 2434/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3384\n",
      "Epoch 2434: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3384 - val_loss: 1.0844\n",
      "Epoch 2435/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3360\n",
      "Epoch 2435: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3360 - val_loss: 1.0949\n",
      "Epoch 2436/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3325\n",
      "Epoch 2436: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3325 - val_loss: 1.0841\n",
      "Epoch 2437/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3345\n",
      "Epoch 2437: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.3345 - val_loss: 1.0957\n",
      "Epoch 2438/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3325\n",
      "Epoch 2438: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.3325 - val_loss: 1.0870\n",
      "Epoch 2439/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3312\n",
      "Epoch 2439: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3312 - val_loss: 1.0983\n",
      "Epoch 2440/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3331\n",
      "Epoch 2440: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3331 - val_loss: 1.0866\n",
      "Epoch 2441/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3326\n",
      "Epoch 2441: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3326 - val_loss: 1.0956\n",
      "Epoch 2442/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3324\n",
      "Epoch 2442: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3324 - val_loss: 1.0817\n",
      "Epoch 2443/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3358\n",
      "Epoch 2443: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3358 - val_loss: 1.0968\n",
      "Epoch 2444/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3340\n",
      "Epoch 2444: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3340 - val_loss: 1.0849\n",
      "Epoch 2445/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3323\n",
      "Epoch 2445: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3323 - val_loss: 1.0967\n",
      "Epoch 2446/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3366\n",
      "Epoch 2446: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.3366 - val_loss: 1.0795\n",
      "Epoch 2447/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3373\n",
      "Epoch 2447: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.3373 - val_loss: 1.0990\n",
      "Epoch 2448/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3366\n",
      "Epoch 2448: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3366 - val_loss: 1.0820\n",
      "Epoch 2449/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3374\n",
      "Epoch 2449: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3374 - val_loss: 1.0991\n",
      "Epoch 2450/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3340\n",
      "Epoch 2450: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3340 - val_loss: 1.0851\n",
      "Epoch 2451/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3341\n",
      "Epoch 2451: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3341 - val_loss: 1.0961\n",
      "Epoch 2452/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3329\n",
      "Epoch 2452: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3329 - val_loss: 1.0827\n",
      "Epoch 2453/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3333\n",
      "Epoch 2453: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3333 - val_loss: 1.0937\n",
      "Epoch 2454/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3313\n",
      "Epoch 2454: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3313 - val_loss: 1.0831\n",
      "Epoch 2455/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3321\n",
      "Epoch 2455: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3321 - val_loss: 1.0955\n",
      "Epoch 2456/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3319\n",
      "Epoch 2456: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.3319 - val_loss: 1.0837\n",
      "Epoch 2457/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3328\n",
      "Epoch 2457: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3328 - val_loss: 1.0991\n",
      "Epoch 2458/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3346\n",
      "Epoch 2458: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3346 - val_loss: 1.0819\n",
      "Epoch 2459/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3391\n",
      "Epoch 2459: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3391 - val_loss: 1.0972\n",
      "Epoch 2460/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3347\n",
      "Epoch 2460: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3347 - val_loss: 1.0840\n",
      "Epoch 2461/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3328\n",
      "Epoch 2461: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3328 - val_loss: 1.0943\n",
      "Epoch 2462/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3312\n",
      "Epoch 2462: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3312 - val_loss: 1.0874\n",
      "Epoch 2463/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3295\n",
      "Epoch 2463: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3295 - val_loss: 1.0863\n",
      "Epoch 2464/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3294\n",
      "Epoch 2464: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3294 - val_loss: 1.0846\n",
      "Epoch 2465/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3303\n",
      "Epoch 2465: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.3303 - val_loss: 1.0924\n",
      "Epoch 2466/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3305\n",
      "Epoch 2466: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3305 - val_loss: 1.0822\n",
      "Epoch 2467/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3324\n",
      "Epoch 2467: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3324 - val_loss: 1.1027\n",
      "Epoch 2468/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3414\n",
      "Epoch 2468: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3414 - val_loss: 1.0811\n",
      "Epoch 2469/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3376\n",
      "Epoch 2469: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3376 - val_loss: 1.0969\n",
      "Epoch 2470/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3356\n",
      "Epoch 2470: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3356 - val_loss: 1.0796\n",
      "Epoch 2471/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3384\n",
      "Epoch 2471: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3384 - val_loss: 1.0992\n",
      "Epoch 2472/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3358\n",
      "Epoch 2472: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3358 - val_loss: 1.0853\n",
      "Epoch 2473/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3309\n",
      "Epoch 2473: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3309 - val_loss: 1.0870\n",
      "Epoch 2474/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3296\n",
      "Epoch 2474: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3296 - val_loss: 1.0887\n",
      "Epoch 2475/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3292\n",
      "Epoch 2475: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3292 - val_loss: 1.0845\n",
      "Epoch 2476/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3304\n",
      "Epoch 2476: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3304 - val_loss: 1.0873\n",
      "Epoch 2477/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3297\n",
      "Epoch 2477: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3297 - val_loss: 1.0867\n",
      "Epoch 2478/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3294\n",
      "Epoch 2478: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3294 - val_loss: 1.0875\n",
      "Epoch 2479/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3301\n",
      "Epoch 2479: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.3301 - val_loss: 1.0840\n",
      "Epoch 2480/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3305\n",
      "Epoch 2480: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3305 - val_loss: 1.0955\n",
      "Epoch 2481/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3318\n",
      "Epoch 2481: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3318 - val_loss: 1.0830\n",
      "Epoch 2482/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3333\n",
      "Epoch 2482: val_loss did not improve from 1.07916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3333 - val_loss: 1.0998\n",
      "Epoch 2483/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3403\n",
      "Epoch 2483: val_loss improved from 1.07916 to 1.07609, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.3403 - val_loss: 1.0761\n",
      "Epoch 2484/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3421\n",
      "Epoch 2484: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.3421 - val_loss: 1.0973\n",
      "Epoch 2485/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3353\n",
      "Epoch 2485: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3353 - val_loss: 1.0804\n",
      "Epoch 2486/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3356\n",
      "Epoch 2486: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3356 - val_loss: 1.1008\n",
      "Epoch 2487/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3379\n",
      "Epoch 2487: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3379 - val_loss: 1.0801\n",
      "Epoch 2488/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3375\n",
      "Epoch 2488: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3375 - val_loss: 1.0963\n",
      "Epoch 2489/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3317\n",
      "Epoch 2489: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3317 - val_loss: 1.0853\n",
      "Epoch 2490/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3314\n",
      "Epoch 2490: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3314 - val_loss: 1.0906\n",
      "Epoch 2491/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3292\n",
      "Epoch 2491: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3292 - val_loss: 1.0845\n",
      "Epoch 2492/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3285\n",
      "Epoch 2492: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.3285 - val_loss: 1.0927\n",
      "Epoch 2493/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3313\n",
      "Epoch 2493: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3313 - val_loss: 1.0784\n",
      "Epoch 2494/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3357\n",
      "Epoch 2494: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3357 - val_loss: 1.0968\n",
      "Epoch 2495/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3347\n",
      "Epoch 2495: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.3347 - val_loss: 1.0801\n",
      "Epoch 2496/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3366\n",
      "Epoch 2496: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3366 - val_loss: 1.0991\n",
      "Epoch 2497/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3350\n",
      "Epoch 2497: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3350 - val_loss: 1.0839\n",
      "Epoch 2498/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3320\n",
      "Epoch 2498: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3320 - val_loss: 1.0925\n",
      "Epoch 2499/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3302\n",
      "Epoch 2499: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3302 - val_loss: 1.0796\n",
      "Epoch 2500/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3337\n",
      "Epoch 2500: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3337 - val_loss: 1.0934\n",
      "Epoch 2501/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3300\n",
      "Epoch 2501: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3300 - val_loss: 1.0839\n",
      "Epoch 2502/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3306\n",
      "Epoch 2502: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.3306 - val_loss: 1.0960\n",
      "Epoch 2503/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3324\n",
      "Epoch 2503: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3324 - val_loss: 1.0819\n",
      "Epoch 2504/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3337\n",
      "Epoch 2504: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3337 - val_loss: 1.0970\n",
      "Epoch 2505/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3358\n",
      "Epoch 2505: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3358 - val_loss: 1.0784\n",
      "Epoch 2506/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3357\n",
      "Epoch 2506: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3357 - val_loss: 1.0976\n",
      "Epoch 2507/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3347\n",
      "Epoch 2507: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3347 - val_loss: 1.0816\n",
      "Epoch 2508/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3329\n",
      "Epoch 2508: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.3329 - val_loss: 1.0941\n",
      "Epoch 2509/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3321\n",
      "Epoch 2509: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.3321 - val_loss: 1.0797\n",
      "Epoch 2510/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3342\n",
      "Epoch 2510: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3342 - val_loss: 1.0923\n",
      "Epoch 2511/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3302\n",
      "Epoch 2511: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.3302 - val_loss: 1.0841\n",
      "Epoch 2512/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3287\n",
      "Epoch 2512: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.3287 - val_loss: 1.0929\n",
      "Epoch 2513/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3305\n",
      "Epoch 2513: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3305 - val_loss: 1.0828\n",
      "Epoch 2514/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3301\n",
      "Epoch 2514: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3301 - val_loss: 1.0857\n",
      "Epoch 2515/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3282\n",
      "Epoch 2515: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3282 - val_loss: 1.0859\n",
      "Epoch 2516/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3278\n",
      "Epoch 2516: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3278 - val_loss: 1.0834\n",
      "Epoch 2517/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3289\n",
      "Epoch 2517: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3289 - val_loss: 1.0868\n",
      "Epoch 2518/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3279\n",
      "Epoch 2518: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3279 - val_loss: 1.0861\n",
      "Epoch 2519/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3290\n",
      "Epoch 2519: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3290 - val_loss: 1.0878\n",
      "Epoch 2520/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3297\n",
      "Epoch 2520: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3297 - val_loss: 1.0897\n",
      "Epoch 2521/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3295\n",
      "Epoch 2521: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.3295 - val_loss: 1.0858\n",
      "Epoch 2522/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3309\n",
      "Epoch 2522: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3309 - val_loss: 1.0924\n",
      "Epoch 2523/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3306\n",
      "Epoch 2523: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3306 - val_loss: 1.0770\n",
      "Epoch 2524/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3391\n",
      "Epoch 2524: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3391 - val_loss: 1.1014\n",
      "Epoch 2525/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3410\n",
      "Epoch 2525: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3410 - val_loss: 1.0771\n",
      "Epoch 2526/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3412\n",
      "Epoch 2526: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.3412 - val_loss: 1.0971\n",
      "Epoch 2527/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3334\n",
      "Epoch 2527: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3334 - val_loss: 1.0821\n",
      "Epoch 2528/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3321\n",
      "Epoch 2528: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3321 - val_loss: 1.0937\n",
      "Epoch 2529/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3306\n",
      "Epoch 2529: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3306 - val_loss: 1.0793\n",
      "Epoch 2530/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3323\n",
      "Epoch 2530: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3323 - val_loss: 1.0935\n",
      "Epoch 2531/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3311\n",
      "Epoch 2531: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.3311 - val_loss: 1.0824\n",
      "Epoch 2532/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3293\n",
      "Epoch 2532: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3293 - val_loss: 1.0911\n",
      "Epoch 2533/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3290\n",
      "Epoch 2533: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3290 - val_loss: 1.0784\n",
      "Epoch 2534/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3327\n",
      "Epoch 2534: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.3327 - val_loss: 1.0950\n",
      "Epoch 2535/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3341\n",
      "Epoch 2535: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3341 - val_loss: 1.0792\n",
      "Epoch 2536/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3336\n",
      "Epoch 2536: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3336 - val_loss: 1.0938\n",
      "Epoch 2537/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3329\n",
      "Epoch 2537: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3329 - val_loss: 1.0776\n",
      "Epoch 2538/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3350\n",
      "Epoch 2538: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3350 - val_loss: 1.0939\n",
      "Epoch 2539/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3307\n",
      "Epoch 2539: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.3307 - val_loss: 1.0821\n",
      "Epoch 2540/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3295\n",
      "Epoch 2540: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3295 - val_loss: 1.0875\n",
      "Epoch 2541/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3276\n",
      "Epoch 2541: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.3276 - val_loss: 1.0800\n",
      "Epoch 2542/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3283\n",
      "Epoch 2542: val_loss did not improve from 1.07609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3283 - val_loss: 1.0897\n",
      "Epoch 2543/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3295\n",
      "Epoch 2543: val_loss improved from 1.07609 to 1.07536, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3295 - val_loss: 1.0754\n",
      "Epoch 2544/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3359\n",
      "Epoch 2544: val_loss did not improve from 1.07536\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3359 - val_loss: 1.0962\n",
      "Epoch 2545/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3363\n",
      "Epoch 2545: val_loss improved from 1.07536 to 1.07535, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.3363 - val_loss: 1.0754\n",
      "Epoch 2546/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3375\n",
      "Epoch 2546: val_loss did not improve from 1.07535\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3375 - val_loss: 1.0930\n",
      "Epoch 2547/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3312\n",
      "Epoch 2547: val_loss did not improve from 1.07535\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3312 - val_loss: 1.0797\n",
      "Epoch 2548/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3314\n",
      "Epoch 2548: val_loss did not improve from 1.07535\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.3314 - val_loss: 1.0926\n",
      "Epoch 2549/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3319\n",
      "Epoch 2549: val_loss did not improve from 1.07535\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.3319 - val_loss: 1.0774\n",
      "Epoch 2550/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3342\n",
      "Epoch 2550: val_loss did not improve from 1.07535\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3342 - val_loss: 1.0936\n",
      "Epoch 2551/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3306\n",
      "Epoch 2551: val_loss did not improve from 1.07535\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3306 - val_loss: 1.0820\n",
      "Epoch 2552/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3301\n",
      "Epoch 2552: val_loss did not improve from 1.07535\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3301 - val_loss: 1.0837\n",
      "Epoch 2553/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3270\n",
      "Epoch 2553: val_loss did not improve from 1.07535\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3270 - val_loss: 1.0856\n",
      "Epoch 2554/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3268\n",
      "Epoch 2554: val_loss did not improve from 1.07535\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3268 - val_loss: 1.0792\n",
      "Epoch 2555/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3277\n",
      "Epoch 2555: val_loss did not improve from 1.07535\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.3277 - val_loss: 1.0905\n",
      "Epoch 2556/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3312\n",
      "Epoch 2556: val_loss did not improve from 1.07535\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3312 - val_loss: 1.0764\n",
      "Epoch 2557/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3319\n",
      "Epoch 2557: val_loss did not improve from 1.07535\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.3319 - val_loss: 1.0927\n",
      "Epoch 2558/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3322\n",
      "Epoch 2558: val_loss improved from 1.07535 to 1.07507, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3322 - val_loss: 1.0751\n",
      "Epoch 2559/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3349\n",
      "Epoch 2559: val_loss did not improve from 1.07507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3349 - val_loss: 1.0947\n",
      "Epoch 2560/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3351\n",
      "Epoch 2560: val_loss did not improve from 1.07507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.3351 - val_loss: 1.0770\n",
      "Epoch 2561/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3322\n",
      "Epoch 2561: val_loss did not improve from 1.07507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3322 - val_loss: 1.0941\n",
      "Epoch 2562/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3323\n",
      "Epoch 2562: val_loss did not improve from 1.07507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3323 - val_loss: 1.0777\n",
      "Epoch 2563/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3347\n",
      "Epoch 2563: val_loss did not improve from 1.07507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3347 - val_loss: 1.0916\n",
      "Epoch 2564/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3308\n",
      "Epoch 2564: val_loss did not improve from 1.07507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3308 - val_loss: 1.0786\n",
      "Epoch 2565/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3308\n",
      "Epoch 2565: val_loss did not improve from 1.07507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3308 - val_loss: 1.0898\n",
      "Epoch 2566/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3280\n",
      "Epoch 2566: val_loss did not improve from 1.07507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.3280 - val_loss: 1.0819\n",
      "Epoch 2567/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3272\n",
      "Epoch 2567: val_loss did not improve from 1.07507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3272 - val_loss: 1.0819\n",
      "Epoch 2568/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3275\n",
      "Epoch 2568: val_loss did not improve from 1.07507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3275 - val_loss: 1.0810\n",
      "Epoch 2569/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3283\n",
      "Epoch 2569: val_loss did not improve from 1.07507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3283 - val_loss: 1.0863\n",
      "Epoch 2570/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3293\n",
      "Epoch 2570: val_loss improved from 1.07507 to 1.07470, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.3293 - val_loss: 1.0747\n",
      "Epoch 2571/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3369\n",
      "Epoch 2571: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3369 - val_loss: 1.0943\n",
      "Epoch 2572/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3332\n",
      "Epoch 2572: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.3332 - val_loss: 1.0755\n",
      "Epoch 2573/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3349\n",
      "Epoch 2573: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.3349 - val_loss: 1.0943\n",
      "Epoch 2574/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3324\n",
      "Epoch 2574: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3324 - val_loss: 1.0770\n",
      "Epoch 2575/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3341\n",
      "Epoch 2575: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3341 - val_loss: 1.0943\n",
      "Epoch 2576/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3316\n",
      "Epoch 2576: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.3316 - val_loss: 1.0786\n",
      "Epoch 2577/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3299\n",
      "Epoch 2577: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3299 - val_loss: 1.0898\n",
      "Epoch 2578/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3280\n",
      "Epoch 2578: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3280 - val_loss: 1.0812\n",
      "Epoch 2579/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3278\n",
      "Epoch 2579: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3278 - val_loss: 1.0901\n",
      "Epoch 2580/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3276\n",
      "Epoch 2580: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3276 - val_loss: 1.0805\n",
      "Epoch 2581/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3299\n",
      "Epoch 2581: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3299 - val_loss: 1.0860\n",
      "Epoch 2582/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3266\n",
      "Epoch 2582: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3266 - val_loss: 1.0818\n",
      "Epoch 2583/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3272\n",
      "Epoch 2583: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3272 - val_loss: 1.0870\n",
      "Epoch 2584/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3275\n",
      "Epoch 2584: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.3275 - val_loss: 1.0747\n",
      "Epoch 2585/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3338\n",
      "Epoch 2585: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3338 - val_loss: 1.0945\n",
      "Epoch 2586/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3360\n",
      "Epoch 2586: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.3360 - val_loss: 1.0751\n",
      "Epoch 2587/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3358\n",
      "Epoch 2587: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.3358 - val_loss: 1.0928\n",
      "Epoch 2588/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3318\n",
      "Epoch 2588: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.3318 - val_loss: 1.0775\n",
      "Epoch 2589/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3313\n",
      "Epoch 2589: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3313 - val_loss: 1.0922\n",
      "Epoch 2590/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3295\n",
      "Epoch 2590: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3295 - val_loss: 1.0788\n",
      "Epoch 2591/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3328\n",
      "Epoch 2591: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3328 - val_loss: 1.0904\n",
      "Epoch 2592/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3286\n",
      "Epoch 2592: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3286 - val_loss: 1.0775\n",
      "Epoch 2593/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3306\n",
      "Epoch 2593: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.3306 - val_loss: 1.0920\n",
      "Epoch 2594/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3288\n",
      "Epoch 2594: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.3288 - val_loss: 1.0783\n",
      "Epoch 2595/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3295\n",
      "Epoch 2595: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3295 - val_loss: 1.0912\n",
      "Epoch 2596/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3288\n",
      "Epoch 2596: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3288 - val_loss: 1.0781\n",
      "Epoch 2597/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3327\n",
      "Epoch 2597: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3327 - val_loss: 1.0899\n",
      "Epoch 2598/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3296\n",
      "Epoch 2598: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3296 - val_loss: 1.0772\n",
      "Epoch 2599/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3313\n",
      "Epoch 2599: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3313 - val_loss: 1.0920\n",
      "Epoch 2600/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3291\n",
      "Epoch 2600: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3291 - val_loss: 1.0785\n",
      "Epoch 2601/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3330\n",
      "Epoch 2601: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3330 - val_loss: 1.0901\n",
      "Epoch 2602/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3283\n",
      "Epoch 2602: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.3283 - val_loss: 1.0771\n",
      "Epoch 2603/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3303\n",
      "Epoch 2603: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.3303 - val_loss: 1.0930\n",
      "Epoch 2604/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3308\n",
      "Epoch 2604: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3308 - val_loss: 1.0753\n",
      "Epoch 2605/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3340\n",
      "Epoch 2605: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3340 - val_loss: 1.0910\n",
      "Epoch 2606/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3285\n",
      "Epoch 2606: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3285 - val_loss: 1.0769\n",
      "Epoch 2607/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3288\n",
      "Epoch 2607: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3288 - val_loss: 1.0857\n",
      "Epoch 2608/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3262\n",
      "Epoch 2608: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.3262 - val_loss: 1.0792\n",
      "Epoch 2609/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3262\n",
      "Epoch 2609: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3262 - val_loss: 1.0865\n",
      "Epoch 2610/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3277\n",
      "Epoch 2610: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.3277 - val_loss: 1.0766\n",
      "Epoch 2611/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.3296\n",
      "Epoch 2611: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.3296 - val_loss: 1.0915\n",
      "Epoch 2612/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3319\n",
      "Epoch 2612: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3319 - val_loss: 1.0749\n",
      "Epoch 2613/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3383\n",
      "Epoch 2613: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3383 - val_loss: 1.0927\n",
      "Epoch 2614/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3309\n",
      "Epoch 2614: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3309 - val_loss: 1.0769\n",
      "Epoch 2615/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3310\n",
      "Epoch 2615: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3310 - val_loss: 1.0877\n",
      "Epoch 2616/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3280\n",
      "Epoch 2616: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3280 - val_loss: 1.0768\n",
      "Epoch 2617/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3285\n",
      "Epoch 2617: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3285 - val_loss: 1.0891\n",
      "Epoch 2618/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3275\n",
      "Epoch 2618: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.3275 - val_loss: 1.0774\n",
      "Epoch 2619/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3291\n",
      "Epoch 2619: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.3291 - val_loss: 1.0879\n",
      "Epoch 2620/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3269\n",
      "Epoch 2620: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.3269 - val_loss: 1.0785\n",
      "Epoch 2621/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3273\n",
      "Epoch 2621: val_loss did not improve from 1.07470\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3273 - val_loss: 1.0861\n",
      "Epoch 2622/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3271\n",
      "Epoch 2622: val_loss improved from 1.07470 to 1.07405, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3271 - val_loss: 1.0740\n",
      "Epoch 2623/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3308\n",
      "Epoch 2623: val_loss did not improve from 1.07405\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3308 - val_loss: 1.0902\n",
      "Epoch 2624/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3322\n",
      "Epoch 2624: val_loss improved from 1.07405 to 1.07287, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3322 - val_loss: 1.0729\n",
      "Epoch 2625/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3418\n",
      "Epoch 2625: val_loss did not improve from 1.07287\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3418 - val_loss: 1.0887\n",
      "Epoch 2626/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3281\n",
      "Epoch 2626: val_loss did not improve from 1.07287\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3281 - val_loss: 1.0763\n",
      "Epoch 2627/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3291\n",
      "Epoch 2627: val_loss did not improve from 1.07287\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3291 - val_loss: 1.0911\n",
      "Epoch 2628/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3303\n",
      "Epoch 2628: val_loss did not improve from 1.07287\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.3303 - val_loss: 1.0757\n",
      "Epoch 2629/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3311\n",
      "Epoch 2629: val_loss did not improve from 1.07287\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.3311 - val_loss: 1.0890\n",
      "Epoch 2630/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3307\n",
      "Epoch 2630: val_loss did not improve from 1.07287\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3307 - val_loss: 1.0736\n",
      "Epoch 2631/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3342\n",
      "Epoch 2631: val_loss did not improve from 1.07287\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3342 - val_loss: 1.0885\n",
      "Epoch 2632/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.3279\n",
      "Epoch 2632: val_loss did not improve from 1.07287\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3279 - val_loss: 1.0731\n",
      "Epoch 2633/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3327\n",
      "Epoch 2633: val_loss did not improve from 1.07287\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.3327 - val_loss: 1.0894\n",
      "Epoch 2634/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3296\n",
      "Epoch 2634: val_loss did not improve from 1.07287\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.3296 - val_loss: 1.0744\n",
      "Epoch 2635/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3308\n",
      "Epoch 2635: val_loss did not improve from 1.07287\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3308 - val_loss: 1.0899\n",
      "Epoch 2636/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3290\n",
      "Epoch 2636: val_loss did not improve from 1.07287\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3290 - val_loss: 1.0781\n",
      "Epoch 2637/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.3286\n",
      "Epoch 2637: val_loss did not improve from 1.07287\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.3286 - val_loss: 1.0806\n",
      "Epoch 2638/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3250\n",
      "Epoch 2638: val_loss did not improve from 1.07287\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.3250 - val_loss: 1.0821\n",
      "Epoch 2639/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3248\n",
      "Epoch 2639: val_loss did not improve from 1.07287\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3248 - val_loss: 1.0782\n",
      "Epoch 2640/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3251\n",
      "Epoch 2640: val_loss did not improve from 1.07287\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3251 - val_loss: 1.0821\n",
      "Epoch 2641/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3257\n",
      "Epoch 2641: val_loss did not improve from 1.07287\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3257 - val_loss: 1.0796\n",
      "Epoch 2642/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3258\n",
      "Epoch 2642: val_loss did not improve from 1.07287\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3258 - val_loss: 1.0816\n",
      "Epoch 2643/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3256\n",
      "Epoch 2643: val_loss did not improve from 1.07287\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3256 - val_loss: 1.0853\n",
      "Epoch 2644/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3267\n",
      "Epoch 2644: val_loss improved from 1.07287 to 1.07164, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.3267 - val_loss: 1.0716\n",
      "Epoch 2645/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3342\n",
      "Epoch 2645: val_loss did not improve from 1.07164\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3342 - val_loss: 1.0920\n",
      "Epoch 2646/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.3363\n",
      "Epoch 2646: val_loss improved from 1.07164 to 1.07081, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.3363 - val_loss: 1.0708\n",
      "Epoch 2647/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3400\n",
      "Epoch 2647: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.3400 - val_loss: 1.0865\n",
      "Epoch 2648/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3282\n",
      "Epoch 2648: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3282 - val_loss: 1.0750\n",
      "Epoch 2649/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3277\n",
      "Epoch 2649: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3277 - val_loss: 1.0867\n",
      "Epoch 2650/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3273\n",
      "Epoch 2650: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3273 - val_loss: 1.0754\n",
      "Epoch 2651/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3297\n",
      "Epoch 2651: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3297 - val_loss: 1.0883\n",
      "Epoch 2652/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3272\n",
      "Epoch 2652: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3272 - val_loss: 1.0764\n",
      "Epoch 2653/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3297\n",
      "Epoch 2653: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3297 - val_loss: 1.0879\n",
      "Epoch 2654/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3283\n",
      "Epoch 2654: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.3283 - val_loss: 1.0743\n",
      "Epoch 2655/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3306\n",
      "Epoch 2655: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.3306 - val_loss: 1.0920\n",
      "Epoch 2656/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3315\n",
      "Epoch 2656: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3315 - val_loss: 1.0740\n",
      "Epoch 2657/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3348\n",
      "Epoch 2657: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3348 - val_loss: 1.0897\n",
      "Epoch 2658/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3284\n",
      "Epoch 2658: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3284 - val_loss: 1.0767\n",
      "Epoch 2659/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3274\n",
      "Epoch 2659: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3274 - val_loss: 1.0854\n",
      "Epoch 2660/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3262\n",
      "Epoch 2660: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3262 - val_loss: 1.0751\n",
      "Epoch 2661/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.3282\n",
      "Epoch 2661: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3282 - val_loss: 1.0876\n",
      "Epoch 2662/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3276\n",
      "Epoch 2662: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.3276 - val_loss: 1.0751\n",
      "Epoch 2663/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3297\n",
      "Epoch 2663: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.3297 - val_loss: 1.0858\n",
      "Epoch 2664/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3251\n",
      "Epoch 2664: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3251 - val_loss: 1.0775\n",
      "Epoch 2665/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3258\n",
      "Epoch 2665: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3258 - val_loss: 1.0892\n",
      "Epoch 2666/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3298\n",
      "Epoch 2666: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3298 - val_loss: 1.0737\n",
      "Epoch 2667/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3328\n",
      "Epoch 2667: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3328 - val_loss: 1.0913\n",
      "Epoch 2668/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3324\n",
      "Epoch 2668: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3324 - val_loss: 1.0747\n",
      "Epoch 2669/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3321\n",
      "Epoch 2669: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3321 - val_loss: 1.0863\n",
      "Epoch 2670/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3276\n",
      "Epoch 2670: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.3276 - val_loss: 1.0739\n",
      "Epoch 2671/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3298\n",
      "Epoch 2671: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.3298 - val_loss: 1.0900\n",
      "Epoch 2672/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3302\n",
      "Epoch 2672: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3302 - val_loss: 1.0730\n",
      "Epoch 2673/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3331\n",
      "Epoch 2673: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3331 - val_loss: 1.0888\n",
      "Epoch 2674/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3283\n",
      "Epoch 2674: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3283 - val_loss: 1.0748\n",
      "Epoch 2675/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3292\n",
      "Epoch 2675: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3292 - val_loss: 1.0872\n",
      "Epoch 2676/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3261\n",
      "Epoch 2676: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.3261 - val_loss: 1.0769\n",
      "Epoch 2677/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3260\n",
      "Epoch 2677: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3260 - val_loss: 1.0847\n",
      "Epoch 2678/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.3248\n",
      "Epoch 2678: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3248 - val_loss: 1.0774\n",
      "Epoch 2679/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3264\n",
      "Epoch 2679: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.3264 - val_loss: 1.0803\n",
      "Epoch 2680/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3255\n",
      "Epoch 2680: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3255 - val_loss: 1.0754\n",
      "Epoch 2681/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3275\n",
      "Epoch 2681: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3275 - val_loss: 1.0870\n",
      "Epoch 2682/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3273\n",
      "Epoch 2682: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3273 - val_loss: 1.0724\n",
      "Epoch 2683/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3328\n",
      "Epoch 2683: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3328 - val_loss: 1.0913\n",
      "Epoch 2684/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3339\n",
      "Epoch 2684: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.3339 - val_loss: 1.0723\n",
      "Epoch 2685/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3379\n",
      "Epoch 2685: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3379 - val_loss: 1.0875\n",
      "Epoch 2686/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3268\n",
      "Epoch 2686: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3268 - val_loss: 1.0758\n",
      "Epoch 2687/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3272\n",
      "Epoch 2687: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3272 - val_loss: 1.0863\n",
      "Epoch 2688/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3256\n",
      "Epoch 2688: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3256 - val_loss: 1.0771\n",
      "Epoch 2689/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3266\n",
      "Epoch 2689: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3266 - val_loss: 1.0814\n",
      "Epoch 2690/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3245\n",
      "Epoch 2690: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.3245 - val_loss: 1.0771\n",
      "Epoch 2691/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3261\n",
      "Epoch 2691: val_loss did not improve from 1.07081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3261 - val_loss: 1.0850\n",
      "Epoch 2692/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3278\n",
      "Epoch 2692: val_loss improved from 1.07081 to 1.07053, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.3278 - val_loss: 1.0705\n",
      "Epoch 2693/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3356\n",
      "Epoch 2693: val_loss did not improve from 1.07053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3356 - val_loss: 1.0866\n",
      "Epoch 2694/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3286\n",
      "Epoch 2694: val_loss did not improve from 1.07053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3286 - val_loss: 1.0714\n",
      "Epoch 2695/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3314\n",
      "Epoch 2695: val_loss did not improve from 1.07053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3314 - val_loss: 1.0891\n",
      "Epoch 2696/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3308\n",
      "Epoch 2696: val_loss did not improve from 1.07053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3308 - val_loss: 1.0722\n",
      "Epoch 2697/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3321\n",
      "Epoch 2697: val_loss did not improve from 1.07053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.3321 - val_loss: 1.0880\n",
      "Epoch 2698/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3283\n",
      "Epoch 2698: val_loss did not improve from 1.07053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3283 - val_loss: 1.0736\n",
      "Epoch 2699/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3300\n",
      "Epoch 2699: val_loss did not improve from 1.07053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3300 - val_loss: 1.0898\n",
      "Epoch 2700/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3294\n",
      "Epoch 2700: val_loss did not improve from 1.07053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3294 - val_loss: 1.0736\n",
      "Epoch 2701/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3304\n",
      "Epoch 2701: val_loss did not improve from 1.07053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.3304 - val_loss: 1.0861\n",
      "Epoch 2702/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3249\n",
      "Epoch 2702: val_loss did not improve from 1.07053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.3249 - val_loss: 1.0782\n",
      "Epoch 2703/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3251\n",
      "Epoch 2703: val_loss did not improve from 1.07053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3251 - val_loss: 1.0811\n",
      "Epoch 2704/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3233\n",
      "Epoch 2704: val_loss did not improve from 1.07053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3233 - val_loss: 1.0770\n",
      "Epoch 2705/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3238\n",
      "Epoch 2705: val_loss did not improve from 1.07053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.3238 - val_loss: 1.0844\n",
      "Epoch 2706/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3265\n",
      "Epoch 2706: val_loss did not improve from 1.07053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3265 - val_loss: 1.0734\n",
      "Epoch 2707/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3285\n",
      "Epoch 2707: val_loss did not improve from 1.07053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.3285 - val_loss: 1.0890\n",
      "Epoch 2708/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3299\n",
      "Epoch 2708: val_loss did not improve from 1.07053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3299 - val_loss: 1.0727\n",
      "Epoch 2709/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3388\n",
      "Epoch 2709: val_loss did not improve from 1.07053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3388 - val_loss: 1.0878\n",
      "Epoch 2710/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3263\n",
      "Epoch 2710: val_loss did not improve from 1.07053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3263 - val_loss: 1.0752\n",
      "Epoch 2711/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3278\n",
      "Epoch 2711: val_loss did not improve from 1.07053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3278 - val_loss: 1.0860\n",
      "Epoch 2712/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3270\n",
      "Epoch 2712: val_loss did not improve from 1.07053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3270 - val_loss: 1.0736\n",
      "Epoch 2713/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3289\n",
      "Epoch 2713: val_loss did not improve from 1.07053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3289 - val_loss: 1.0874\n",
      "Epoch 2714/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.3272\n",
      "Epoch 2714: val_loss did not improve from 1.07053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3272 - val_loss: 1.0742\n",
      "Epoch 2715/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3279\n",
      "Epoch 2715: val_loss did not improve from 1.07053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3279 - val_loss: 1.0887\n",
      "Epoch 2716/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3280\n",
      "Epoch 2716: val_loss did not improve from 1.07053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3280 - val_loss: 1.0730\n",
      "Epoch 2717/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3342\n",
      "Epoch 2717: val_loss did not improve from 1.07053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3342 - val_loss: 1.0877\n",
      "Epoch 2718/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3260\n",
      "Epoch 2718: val_loss did not improve from 1.07053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3260 - val_loss: 1.0746\n",
      "Epoch 2719/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3283\n",
      "Epoch 2719: val_loss did not improve from 1.07053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.3283 - val_loss: 1.0883\n",
      "Epoch 2720/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3277\n",
      "Epoch 2720: val_loss did not improve from 1.07053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.3277 - val_loss: 1.0744\n",
      "Epoch 2721/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3285\n",
      "Epoch 2721: val_loss did not improve from 1.07053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3285 - val_loss: 1.0803\n",
      "Epoch 2722/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3236\n",
      "Epoch 2722: val_loss did not improve from 1.07053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3236 - val_loss: 1.0764\n",
      "Epoch 2723/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3241\n",
      "Epoch 2723: val_loss did not improve from 1.07053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3241 - val_loss: 1.0825\n",
      "Epoch 2724/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3248\n",
      "Epoch 2724: val_loss did not improve from 1.07053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.3248 - val_loss: 1.0723\n",
      "Epoch 2725/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3281\n",
      "Epoch 2725: val_loss did not improve from 1.07053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3281 - val_loss: 1.0870\n",
      "Epoch 2726/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3296\n",
      "Epoch 2726: val_loss did not improve from 1.07053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3296 - val_loss: 1.0714\n",
      "Epoch 2727/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3371\n",
      "Epoch 2727: val_loss did not improve from 1.07053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3371 - val_loss: 1.0872\n",
      "Epoch 2728/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3270\n",
      "Epoch 2728: val_loss did not improve from 1.07053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.3270 - val_loss: 1.0740\n",
      "Epoch 2729/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3280\n",
      "Epoch 2729: val_loss did not improve from 1.07053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3280 - val_loss: 1.0875\n",
      "Epoch 2730/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3313\n",
      "Epoch 2730: val_loss improved from 1.07053 to 1.06977, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3313 - val_loss: 1.0698\n",
      "Epoch 2731/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3351\n",
      "Epoch 2731: val_loss did not improve from 1.06977\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3351 - val_loss: 1.0847\n",
      "Epoch 2732/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3259\n",
      "Epoch 2732: val_loss did not improve from 1.06977\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3259 - val_loss: 1.0725\n",
      "Epoch 2733/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3274\n",
      "Epoch 2733: val_loss did not improve from 1.06977\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3274 - val_loss: 1.0853\n",
      "Epoch 2734/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3259\n",
      "Epoch 2734: val_loss did not improve from 1.06977\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3259 - val_loss: 1.0746\n",
      "Epoch 2735/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.3265\n",
      "Epoch 2735: val_loss did not improve from 1.06977\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.3265 - val_loss: 1.0808\n",
      "Epoch 2736/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3239\n",
      "Epoch 2736: val_loss did not improve from 1.06977\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.3239 - val_loss: 1.0738\n",
      "Epoch 2737/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3242\n",
      "Epoch 2737: val_loss did not improve from 1.06977\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3242 - val_loss: 1.0810\n",
      "Epoch 2738/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3240\n",
      "Epoch 2738: val_loss did not improve from 1.06977\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3240 - val_loss: 1.0724\n",
      "Epoch 2739/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3260\n",
      "Epoch 2739: val_loss did not improve from 1.06977\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3260 - val_loss: 1.0880\n",
      "Epoch 2740/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3308\n",
      "Epoch 2740: val_loss improved from 1.06977 to 1.06964, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3308 - val_loss: 1.0696\n",
      "Epoch 2741/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3383\n",
      "Epoch 2741: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3383 - val_loss: 1.0846\n",
      "Epoch 2742/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3248\n",
      "Epoch 2742: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3248 - val_loss: 1.0723\n",
      "Epoch 2743/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3275\n",
      "Epoch 2743: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3275 - val_loss: 1.0863\n",
      "Epoch 2744/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.3271\n",
      "Epoch 2744: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.3271 - val_loss: 1.0720\n",
      "Epoch 2745/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3288\n",
      "Epoch 2745: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3288 - val_loss: 1.0862\n",
      "Epoch 2746/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3269\n",
      "Epoch 2746: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3269 - val_loss: 1.0724\n",
      "Epoch 2747/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3295\n",
      "Epoch 2747: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3295 - val_loss: 1.0865\n",
      "Epoch 2748/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3274\n",
      "Epoch 2748: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.3274 - val_loss: 1.0716\n",
      "Epoch 2749/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3362\n",
      "Epoch 2749: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3362 - val_loss: 1.0850\n",
      "Epoch 2750/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3244\n",
      "Epoch 2750: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.3244 - val_loss: 1.0758\n",
      "Epoch 2751/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3246\n",
      "Epoch 2751: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3246 - val_loss: 1.0830\n",
      "Epoch 2752/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3233\n",
      "Epoch 2752: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3233 - val_loss: 1.0784\n",
      "Epoch 2753/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3229\n",
      "Epoch 2753: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3229 - val_loss: 1.0792\n",
      "Epoch 2754/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3241\n",
      "Epoch 2754: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3241 - val_loss: 1.0760\n",
      "Epoch 2755/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3252\n",
      "Epoch 2755: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3252 - val_loss: 1.0803\n",
      "Epoch 2756/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3243\n",
      "Epoch 2756: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.3243 - val_loss: 1.0717\n",
      "Epoch 2757/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.3300\n",
      "Epoch 2757: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.3300 - val_loss: 1.0911\n",
      "Epoch 2758/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3336\n",
      "Epoch 2758: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3336 - val_loss: 1.0715\n",
      "Epoch 2759/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3352\n",
      "Epoch 2759: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3352 - val_loss: 1.0875\n",
      "Epoch 2760/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3271\n",
      "Epoch 2760: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3271 - val_loss: 1.0734\n",
      "Epoch 2761/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3285\n",
      "Epoch 2761: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3285 - val_loss: 1.0850\n",
      "Epoch 2762/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3265\n",
      "Epoch 2762: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.3265 - val_loss: 1.0709\n",
      "Epoch 2763/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3327\n",
      "Epoch 2763: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3327 - val_loss: 1.0869\n",
      "Epoch 2764/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3275\n",
      "Epoch 2764: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3275 - val_loss: 1.0722\n",
      "Epoch 2765/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3276\n",
      "Epoch 2765: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3276 - val_loss: 1.0865\n",
      "Epoch 2766/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3270\n",
      "Epoch 2766: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3270 - val_loss: 1.0727\n",
      "Epoch 2767/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3268\n",
      "Epoch 2767: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3268 - val_loss: 1.0856\n",
      "Epoch 2768/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3256\n",
      "Epoch 2768: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3256 - val_loss: 1.0755\n",
      "Epoch 2769/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3255\n",
      "Epoch 2769: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3255 - val_loss: 1.0818\n",
      "Epoch 2770/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3242\n",
      "Epoch 2770: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3242 - val_loss: 1.0732\n",
      "Epoch 2771/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3253\n",
      "Epoch 2771: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.3253 - val_loss: 1.0824\n",
      "Epoch 2772/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3239\n",
      "Epoch 2772: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3239 - val_loss: 1.0731\n",
      "Epoch 2773/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3252\n",
      "Epoch 2773: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3252 - val_loss: 1.0852\n",
      "Epoch 2774/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3254\n",
      "Epoch 2774: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3254 - val_loss: 1.0710\n",
      "Epoch 2775/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3316\n",
      "Epoch 2775: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.3316 - val_loss: 1.0877\n",
      "Epoch 2776/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3296\n",
      "Epoch 2776: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.3296 - val_loss: 1.0703\n",
      "Epoch 2777/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3364\n",
      "Epoch 2777: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3364 - val_loss: 1.0846\n",
      "Epoch 2778/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3246\n",
      "Epoch 2778: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3246 - val_loss: 1.0740\n",
      "Epoch 2779/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3246\n",
      "Epoch 2779: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3246 - val_loss: 1.0825\n",
      "Epoch 2780/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3231\n",
      "Epoch 2780: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3231 - val_loss: 1.0769\n",
      "Epoch 2781/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3228\n",
      "Epoch 2781: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3228 - val_loss: 1.0778\n",
      "Epoch 2782/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3224\n",
      "Epoch 2782: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3224 - val_loss: 1.0744\n",
      "Epoch 2783/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3264\n",
      "Epoch 2783: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.3264 - val_loss: 1.0808\n",
      "Epoch 2784/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3251\n",
      "Epoch 2784: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.3251 - val_loss: 1.0714\n",
      "Epoch 2785/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3298\n",
      "Epoch 2785: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3298 - val_loss: 1.0902\n",
      "Epoch 2786/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3330\n",
      "Epoch 2786: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.3330 - val_loss: 1.0711\n",
      "Epoch 2787/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3351\n",
      "Epoch 2787: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3351 - val_loss: 1.0838\n",
      "Epoch 2788/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3250\n",
      "Epoch 2788: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3250 - val_loss: 1.0706\n",
      "Epoch 2789/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3283\n",
      "Epoch 2789: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3283 - val_loss: 1.0856\n",
      "Epoch 2790/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3272\n",
      "Epoch 2790: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.3272 - val_loss: 1.0710\n",
      "Epoch 2791/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3288\n",
      "Epoch 2791: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3288 - val_loss: 1.0857\n",
      "Epoch 2792/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.3262\n",
      "Epoch 2792: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.3262 - val_loss: 1.0701\n",
      "Epoch 2793/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3335\n",
      "Epoch 2793: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3335 - val_loss: 1.0853\n",
      "Epoch 2794/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3251\n",
      "Epoch 2794: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3251 - val_loss: 1.0719\n",
      "Epoch 2795/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3288\n",
      "Epoch 2795: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3288 - val_loss: 1.0853\n",
      "Epoch 2796/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3248\n",
      "Epoch 2796: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3248 - val_loss: 1.0736\n",
      "Epoch 2797/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3251\n",
      "Epoch 2797: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3251 - val_loss: 1.0802\n",
      "Epoch 2798/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3231\n",
      "Epoch 2798: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3231 - val_loss: 1.0719\n",
      "Epoch 2799/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3258\n",
      "Epoch 2799: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3258 - val_loss: 1.0823\n",
      "Epoch 2800/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3257\n",
      "Epoch 2800: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.3257 - val_loss: 1.0700\n",
      "Epoch 2801/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3283\n",
      "Epoch 2801: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.3283 - val_loss: 1.0848\n",
      "Epoch 2802/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3267\n",
      "Epoch 2802: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3267 - val_loss: 1.0709\n",
      "Epoch 2803/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3275\n",
      "Epoch 2803: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3275 - val_loss: 1.0874\n",
      "Epoch 2804/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3305\n",
      "Epoch 2804: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3305 - val_loss: 1.0706\n",
      "Epoch 2805/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3333\n",
      "Epoch 2805: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3333 - val_loss: 1.0834\n",
      "Epoch 2806/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3233\n",
      "Epoch 2806: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3233 - val_loss: 1.0742\n",
      "Epoch 2807/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3237\n",
      "Epoch 2807: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3237 - val_loss: 1.0814\n",
      "Epoch 2808/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3224\n",
      "Epoch 2808: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.3224 - val_loss: 1.0778\n",
      "Epoch 2809/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3224\n",
      "Epoch 2809: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.3224 - val_loss: 1.0770\n",
      "Epoch 2810/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3219\n",
      "Epoch 2810: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3219 - val_loss: 1.0746\n",
      "Epoch 2811/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3250\n",
      "Epoch 2811: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3250 - val_loss: 1.0798\n",
      "Epoch 2812/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3250\n",
      "Epoch 2812: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3250 - val_loss: 1.0702\n",
      "Epoch 2813/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3291\n",
      "Epoch 2813: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3291 - val_loss: 1.0886\n",
      "Epoch 2814/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3324\n",
      "Epoch 2814: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.3324 - val_loss: 1.0697\n",
      "Epoch 2815/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3346\n",
      "Epoch 2815: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3346 - val_loss: 1.0843\n",
      "Epoch 2816/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3238\n",
      "Epoch 2816: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3238 - val_loss: 1.0715\n",
      "Epoch 2817/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3288\n",
      "Epoch 2817: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3288 - val_loss: 1.0860\n",
      "Epoch 2818/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3259\n",
      "Epoch 2818: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3259 - val_loss: 1.0720\n",
      "Epoch 2819/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3277\n",
      "Epoch 2819: val_loss did not improve from 1.06964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3277 - val_loss: 1.0832\n",
      "Epoch 2820/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3249\n",
      "Epoch 2820: val_loss improved from 1.06964 to 1.06904, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3249 - val_loss: 1.0690\n",
      "Epoch 2821/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.3301\n",
      "Epoch 2821: val_loss did not improve from 1.06904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3301 - val_loss: 1.0851\n",
      "Epoch 2822/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3264\n",
      "Epoch 2822: val_loss did not improve from 1.06904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3264 - val_loss: 1.0705\n",
      "Epoch 2823/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3291\n",
      "Epoch 2823: val_loss did not improve from 1.06904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3291 - val_loss: 1.0855\n",
      "Epoch 2824/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3265\n",
      "Epoch 2824: val_loss did not improve from 1.06904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3265 - val_loss: 1.0708\n",
      "Epoch 2825/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3314\n",
      "Epoch 2825: val_loss did not improve from 1.06904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3314 - val_loss: 1.0838\n",
      "Epoch 2826/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3234\n",
      "Epoch 2826: val_loss did not improve from 1.06904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.3234 - val_loss: 1.0744\n",
      "Epoch 2827/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3253\n",
      "Epoch 2827: val_loss did not improve from 1.06904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3253 - val_loss: 1.0802\n",
      "Epoch 2828/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3223\n",
      "Epoch 2828: val_loss did not improve from 1.06904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3223 - val_loss: 1.0728\n",
      "Epoch 2829/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3236\n",
      "Epoch 2829: val_loss did not improve from 1.06904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3236 - val_loss: 1.0813\n",
      "Epoch 2830/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3229\n",
      "Epoch 2830: val_loss did not improve from 1.06904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3229 - val_loss: 1.0706\n",
      "Epoch 2831/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3275\n",
      "Epoch 2831: val_loss did not improve from 1.06904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3275 - val_loss: 1.0834\n",
      "Epoch 2832/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3237\n",
      "Epoch 2832: val_loss did not improve from 1.06904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3237 - val_loss: 1.0708\n",
      "Epoch 2833/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3269\n",
      "Epoch 2833: val_loss did not improve from 1.06904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.3269 - val_loss: 1.0855\n",
      "Epoch 2834/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3274\n",
      "Epoch 2834: val_loss did not improve from 1.06904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.3274 - val_loss: 1.0701\n",
      "Epoch 2835/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3325\n",
      "Epoch 2835: val_loss did not improve from 1.06904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3325 - val_loss: 1.0858\n",
      "Epoch 2836/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3265\n",
      "Epoch 2836: val_loss did not improve from 1.06904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3265 - val_loss: 1.0706\n",
      "Epoch 2837/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3340\n",
      "Epoch 2837: val_loss did not improve from 1.06904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3340 - val_loss: 1.0813\n",
      "Epoch 2838/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3228\n",
      "Epoch 2838: val_loss did not improve from 1.06904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3228 - val_loss: 1.0736\n",
      "Epoch 2839/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3236\n",
      "Epoch 2839: val_loss did not improve from 1.06904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3236 - val_loss: 1.0817\n",
      "Epoch 2840/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3224\n",
      "Epoch 2840: val_loss did not improve from 1.06904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3224 - val_loss: 1.0743\n",
      "Epoch 2841/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3224\n",
      "Epoch 2841: val_loss did not improve from 1.06904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3224 - val_loss: 1.0780\n",
      "Epoch 2842/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.3212\n",
      "Epoch 2842: val_loss did not improve from 1.06904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3212 - val_loss: 1.0722\n",
      "Epoch 2843/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3223\n",
      "Epoch 2843: val_loss did not improve from 1.06904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3223 - val_loss: 1.0817\n",
      "Epoch 2844/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3245\n",
      "Epoch 2844: val_loss improved from 1.06904 to 1.06665, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3245 - val_loss: 1.0666\n",
      "Epoch 2845/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3328\n",
      "Epoch 2845: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3328 - val_loss: 1.0845\n",
      "Epoch 2846/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3301\n",
      "Epoch 2846: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3301 - val_loss: 1.0672\n",
      "Epoch 2847/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3357\n",
      "Epoch 2847: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.3357 - val_loss: 1.0823\n",
      "Epoch 2848/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3240\n",
      "Epoch 2848: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3240 - val_loss: 1.0696\n",
      "Epoch 2849/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3270\n",
      "Epoch 2849: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.3270 - val_loss: 1.0838\n",
      "Epoch 2850/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.3267\n",
      "Epoch 2850: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.3267 - val_loss: 1.0686\n",
      "Epoch 2851/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3335\n",
      "Epoch 2851: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3335 - val_loss: 1.0830\n",
      "Epoch 2852/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3237\n",
      "Epoch 2852: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3237 - val_loss: 1.0715\n",
      "Epoch 2853/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3242\n",
      "Epoch 2853: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3242 - val_loss: 1.0826\n",
      "Epoch 2854/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3231\n",
      "Epoch 2854: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3231 - val_loss: 1.0715\n",
      "Epoch 2855/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3251\n",
      "Epoch 2855: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3251 - val_loss: 1.0811\n",
      "Epoch 2856/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3224\n",
      "Epoch 2856: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3224 - val_loss: 1.0739\n",
      "Epoch 2857/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3239\n",
      "Epoch 2857: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3239 - val_loss: 1.0763\n",
      "Epoch 2858/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3209\n",
      "Epoch 2858: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3209 - val_loss: 1.0753\n",
      "Epoch 2859/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.3216\n",
      "Epoch 2859: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3216 - val_loss: 1.0760\n",
      "Epoch 2860/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3209\n",
      "Epoch 2860: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3209 - val_loss: 1.0736\n",
      "Epoch 2861/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3235\n",
      "Epoch 2861: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.3235 - val_loss: 1.0806\n",
      "Epoch 2862/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3264\n",
      "Epoch 2862: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3264 - val_loss: 1.0673\n",
      "Epoch 2863/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3371\n",
      "Epoch 2863: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.3371 - val_loss: 1.0849\n",
      "Epoch 2864/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3259\n",
      "Epoch 2864: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3259 - val_loss: 1.0692\n",
      "Epoch 2865/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3309\n",
      "Epoch 2865: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3309 - val_loss: 1.0865\n",
      "Epoch 2866/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3287\n",
      "Epoch 2866: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3287 - val_loss: 1.0694\n",
      "Epoch 2867/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3341\n",
      "Epoch 2867: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3341 - val_loss: 1.0811\n",
      "Epoch 2868/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3225\n",
      "Epoch 2868: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3225 - val_loss: 1.0693\n",
      "Epoch 2869/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3259\n",
      "Epoch 2869: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3259 - val_loss: 1.0831\n",
      "Epoch 2870/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3256\n",
      "Epoch 2870: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3256 - val_loss: 1.0684\n",
      "Epoch 2871/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3290\n",
      "Epoch 2871: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3290 - val_loss: 1.0831\n",
      "Epoch 2872/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3248\n",
      "Epoch 2872: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3248 - val_loss: 1.0692\n",
      "Epoch 2873/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3289\n",
      "Epoch 2873: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3289 - val_loss: 1.0838\n",
      "Epoch 2874/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3246\n",
      "Epoch 2874: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3246 - val_loss: 1.0701\n",
      "Epoch 2875/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.3271\n",
      "Epoch 2875: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.3271 - val_loss: 1.0805\n",
      "Epoch 2876/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3239\n",
      "Epoch 2876: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3239 - val_loss: 1.0693\n",
      "Epoch 2877/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3258\n",
      "Epoch 2877: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.3258 - val_loss: 1.0801\n",
      "Epoch 2878/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3213\n",
      "Epoch 2878: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3213 - val_loss: 1.0729\n",
      "Epoch 2879/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3221\n",
      "Epoch 2879: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3221 - val_loss: 1.0803\n",
      "Epoch 2880/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3211\n",
      "Epoch 2880: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3211 - val_loss: 1.0724\n",
      "Epoch 2881/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3235\n",
      "Epoch 2881: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3235 - val_loss: 1.0780\n",
      "Epoch 2882/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3214\n",
      "Epoch 2882: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.3214 - val_loss: 1.0719\n",
      "Epoch 2883/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3228\n",
      "Epoch 2883: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3228 - val_loss: 1.0803\n",
      "Epoch 2884/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3237\n",
      "Epoch 2884: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3237 - val_loss: 1.0668\n",
      "Epoch 2885/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3315\n",
      "Epoch 2885: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3315 - val_loss: 1.0848\n",
      "Epoch 2886/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3305\n",
      "Epoch 2886: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3305 - val_loss: 1.0672\n",
      "Epoch 2887/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3326\n",
      "Epoch 2887: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3326 - val_loss: 1.0817\n",
      "Epoch 2888/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3233\n",
      "Epoch 2888: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3233 - val_loss: 1.0688\n",
      "Epoch 2889/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3269\n",
      "Epoch 2889: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3269 - val_loss: 1.0836\n",
      "Epoch 2890/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3258\n",
      "Epoch 2890: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.3258 - val_loss: 1.0687\n",
      "Epoch 2891/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3310\n",
      "Epoch 2891: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.3310 - val_loss: 1.0839\n",
      "Epoch 2892/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3252\n",
      "Epoch 2892: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3252 - val_loss: 1.0700\n",
      "Epoch 2893/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3281\n",
      "Epoch 2893: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3281 - val_loss: 1.0814\n",
      "Epoch 2894/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3240\n",
      "Epoch 2894: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3240 - val_loss: 1.0699\n",
      "Epoch 2895/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3259\n",
      "Epoch 2895: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3259 - val_loss: 1.0820\n",
      "Epoch 2896/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3229\n",
      "Epoch 2896: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3229 - val_loss: 1.0697\n",
      "Epoch 2897/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3258\n",
      "Epoch 2897: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3258 - val_loss: 1.0839\n",
      "Epoch 2898/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3255\n",
      "Epoch 2898: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3255 - val_loss: 1.0696\n",
      "Epoch 2899/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3296\n",
      "Epoch 2899: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3296 - val_loss: 1.0844\n",
      "Epoch 2900/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3253\n",
      "Epoch 2900: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3253 - val_loss: 1.0700\n",
      "Epoch 2901/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3297\n",
      "Epoch 2901: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3297 - val_loss: 1.0796\n",
      "Epoch 2902/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3221\n",
      "Epoch 2902: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3221 - val_loss: 1.0731\n",
      "Epoch 2903/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3233\n",
      "Epoch 2903: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3233 - val_loss: 1.0756\n",
      "Epoch 2904/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3205\n",
      "Epoch 2904: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3205 - val_loss: 1.0698\n",
      "Epoch 2905/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3233\n",
      "Epoch 2905: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3233 - val_loss: 1.0809\n",
      "Epoch 2906/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3222\n",
      "Epoch 2906: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3222 - val_loss: 1.0691\n",
      "Epoch 2907/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3253\n",
      "Epoch 2907: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3253 - val_loss: 1.0793\n",
      "Epoch 2908/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3209\n",
      "Epoch 2908: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.3209 - val_loss: 1.0714\n",
      "Epoch 2909/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3219\n",
      "Epoch 2909: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3219 - val_loss: 1.0805\n",
      "Epoch 2910/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3224\n",
      "Epoch 2910: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3224 - val_loss: 1.0669\n",
      "Epoch 2911/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3294\n",
      "Epoch 2911: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.3294 - val_loss: 1.0844\n",
      "Epoch 2912/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3291\n",
      "Epoch 2912: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.3291 - val_loss: 1.0669\n",
      "Epoch 2913/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3350\n",
      "Epoch 2913: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.3350 - val_loss: 1.0820\n",
      "Epoch 2914/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3229\n",
      "Epoch 2914: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3229 - val_loss: 1.0700\n",
      "Epoch 2915/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3242\n",
      "Epoch 2915: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3242 - val_loss: 1.0840\n",
      "Epoch 2916/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3263\n",
      "Epoch 2916: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3263 - val_loss: 1.0691\n",
      "Epoch 2917/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3279\n",
      "Epoch 2917: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3279 - val_loss: 1.0802\n",
      "Epoch 2918/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3248\n",
      "Epoch 2918: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3248 - val_loss: 1.0668\n",
      "Epoch 2919/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3296\n",
      "Epoch 2919: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3296 - val_loss: 1.0811\n",
      "Epoch 2920/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3236\n",
      "Epoch 2920: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3236 - val_loss: 1.0682\n",
      "Epoch 2921/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3262\n",
      "Epoch 2921: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3262 - val_loss: 1.0817\n",
      "Epoch 2922/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3239\n",
      "Epoch 2922: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3239 - val_loss: 1.0677\n",
      "Epoch 2923/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3285\n",
      "Epoch 2923: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3285 - val_loss: 1.0821\n",
      "Epoch 2924/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3236\n",
      "Epoch 2924: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3236 - val_loss: 1.0688\n",
      "Epoch 2925/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3279\n",
      "Epoch 2925: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3279 - val_loss: 1.0829\n",
      "Epoch 2926/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3235\n",
      "Epoch 2926: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3235 - val_loss: 1.0696\n",
      "Epoch 2927/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3272\n",
      "Epoch 2927: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3272 - val_loss: 1.0797\n",
      "Epoch 2928/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3223\n",
      "Epoch 2928: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3223 - val_loss: 1.0703\n",
      "Epoch 2929/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.3229\n",
      "Epoch 2929: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3229 - val_loss: 1.0797\n",
      "Epoch 2930/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3220\n",
      "Epoch 2930: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3220 - val_loss: 1.0694\n",
      "Epoch 2931/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3232\n",
      "Epoch 2931: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3232 - val_loss: 1.0792\n",
      "Epoch 2932/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3212\n",
      "Epoch 2932: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3212 - val_loss: 1.0686\n",
      "Epoch 2933/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3233\n",
      "Epoch 2933: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3233 - val_loss: 1.0794\n",
      "Epoch 2934/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.3214\n",
      "Epoch 2934: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3214 - val_loss: 1.0689\n",
      "Epoch 2935/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3255\n",
      "Epoch 2935: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.3255 - val_loss: 1.0826\n",
      "Epoch 2936/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3246\n",
      "Epoch 2936: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3246 - val_loss: 1.0675\n",
      "Epoch 2937/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3320\n",
      "Epoch 2937: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3320 - val_loss: 1.0818\n",
      "Epoch 2938/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3227\n",
      "Epoch 2938: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3227 - val_loss: 1.0686\n",
      "Epoch 2939/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3281\n",
      "Epoch 2939: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3281 - val_loss: 1.0848\n",
      "Epoch 2940/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3286\n",
      "Epoch 2940: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3286 - val_loss: 1.0689\n",
      "Epoch 2941/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3300\n",
      "Epoch 2941: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.3300 - val_loss: 1.0806\n",
      "Epoch 2942/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3232\n",
      "Epoch 2942: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3232 - val_loss: 1.0677\n",
      "Epoch 2943/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3258\n",
      "Epoch 2943: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3258 - val_loss: 1.0813\n",
      "Epoch 2944/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3237\n",
      "Epoch 2944: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.3237 - val_loss: 1.0678\n",
      "Epoch 2945/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3260\n",
      "Epoch 2945: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3260 - val_loss: 1.0798\n",
      "Epoch 2946/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3211\n",
      "Epoch 2946: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3211 - val_loss: 1.0684\n",
      "Epoch 2947/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3239\n",
      "Epoch 2947: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.3239 - val_loss: 1.0819\n",
      "Epoch 2948/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3249\n",
      "Epoch 2948: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3249 - val_loss: 1.0676\n",
      "Epoch 2949/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3275\n",
      "Epoch 2949: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3275 - val_loss: 1.0815\n",
      "Epoch 2950/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3247\n",
      "Epoch 2950: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3247 - val_loss: 1.0671\n",
      "Epoch 2951/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3315\n",
      "Epoch 2951: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3315 - val_loss: 1.0809\n",
      "Epoch 2952/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.3221\n",
      "Epoch 2952: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.3221 - val_loss: 1.0695\n",
      "Epoch 2953/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3240\n",
      "Epoch 2953: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.3240 - val_loss: 1.0767\n",
      "Epoch 2954/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3208\n",
      "Epoch 2954: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3208 - val_loss: 1.0694\n",
      "Epoch 2955/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3229\n",
      "Epoch 2955: val_loss did not improve from 1.06665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3229 - val_loss: 1.0778\n",
      "Epoch 2956/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3210\n",
      "Epoch 2956: val_loss improved from 1.06665 to 1.06594, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.3210 - val_loss: 1.0659\n",
      "Epoch 2957/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3251\n",
      "Epoch 2957: val_loss did not improve from 1.06594\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.3251 - val_loss: 1.0799\n",
      "Epoch 2958/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3242\n",
      "Epoch 2958: val_loss improved from 1.06594 to 1.06515, saving model to best_model_4.2.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.3242 - val_loss: 1.0651\n",
      "Epoch 2959/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3292\n",
      "Epoch 2959: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3292 - val_loss: 1.0794\n",
      "Epoch 2960/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3235\n",
      "Epoch 2960: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3235 - val_loss: 1.0656\n",
      "Epoch 2961/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3274\n",
      "Epoch 2961: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3274 - val_loss: 1.0800\n",
      "Epoch 2962/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3245\n",
      "Epoch 2962: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3245 - val_loss: 1.0657\n",
      "Epoch 2963/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3288\n",
      "Epoch 2963: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3288 - val_loss: 1.0799\n",
      "Epoch 2964/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3224\n",
      "Epoch 2964: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3224 - val_loss: 1.0678\n",
      "Epoch 2965/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.3245\n",
      "Epoch 2965: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.3245 - val_loss: 1.0784\n",
      "Epoch 2966/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.3202\n",
      "Epoch 2966: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.3202 - val_loss: 1.0692\n",
      "Epoch 2967/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3224\n",
      "Epoch 2967: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3224 - val_loss: 1.0774\n",
      "Epoch 2968/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3197\n",
      "Epoch 2968: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3197 - val_loss: 1.0710\n",
      "Epoch 2969/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3202\n",
      "Epoch 2969: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3202 - val_loss: 1.0788\n",
      "Epoch 2970/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3209\n",
      "Epoch 2970: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.3209 - val_loss: 1.0663\n",
      "Epoch 2971/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3278\n",
      "Epoch 2971: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3278 - val_loss: 1.0834\n",
      "Epoch 2972/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3288\n",
      "Epoch 2972: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3288 - val_loss: 1.0668\n",
      "Epoch 2973/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3318\n",
      "Epoch 2973: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3318 - val_loss: 1.0822\n",
      "Epoch 2974/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3240\n",
      "Epoch 2974: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.3240 - val_loss: 1.0682\n",
      "Epoch 2975/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3265\n",
      "Epoch 2975: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3265 - val_loss: 1.0833\n",
      "Epoch 2976/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3254\n",
      "Epoch 2976: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3254 - val_loss: 1.0687\n",
      "Epoch 2977/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3293\n",
      "Epoch 2977: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.3293 - val_loss: 1.0786\n",
      "Epoch 2978/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3211\n",
      "Epoch 2978: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.3211 - val_loss: 1.0697\n",
      "Epoch 2979/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3228\n",
      "Epoch 2979: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3228 - val_loss: 1.0782\n",
      "Epoch 2980/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3195\n",
      "Epoch 2980: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3195 - val_loss: 1.0730\n",
      "Epoch 2981/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3194\n",
      "Epoch 2981: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3194 - val_loss: 1.0739\n",
      "Epoch 2982/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3192\n",
      "Epoch 2982: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3192 - val_loss: 1.0702\n",
      "Epoch 2983/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.3227\n",
      "Epoch 2983: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3227 - val_loss: 1.0845\n",
      "Epoch 2984/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3282\n",
      "Epoch 2984: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.3282 - val_loss: 1.0673\n",
      "Epoch 2985/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3345\n",
      "Epoch 2985: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.3345 - val_loss: 1.0821\n",
      "Epoch 2986/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3222\n",
      "Epoch 2986: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3222 - val_loss: 1.0693\n",
      "Epoch 2987/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3254\n",
      "Epoch 2987: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3254 - val_loss: 1.0802\n",
      "Epoch 2988/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3233\n",
      "Epoch 2988: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.3233 - val_loss: 1.0659\n",
      "Epoch 2989/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3291\n",
      "Epoch 2989: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3291 - val_loss: 1.0817\n",
      "Epoch 2990/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.3250\n",
      "Epoch 2990: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3250 - val_loss: 1.0663\n",
      "Epoch 2991/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3305\n",
      "Epoch 2991: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3305 - val_loss: 1.0808\n",
      "Epoch 2992/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3221\n",
      "Epoch 2992: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.3221 - val_loss: 1.0680\n",
      "Epoch 2993/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3259\n",
      "Epoch 2993: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3259 - val_loss: 1.0818\n",
      "Epoch 2994/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3239\n",
      "Epoch 2994: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3239 - val_loss: 1.0675\n",
      "Epoch 2995/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3282\n",
      "Epoch 2995: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3282 - val_loss: 1.0775\n",
      "Epoch 2996/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3207\n",
      "Epoch 2996: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.3207 - val_loss: 1.0699\n",
      "Epoch 2997/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3218\n",
      "Epoch 2997: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3218 - val_loss: 1.0756\n",
      "Epoch 2998/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3188\n",
      "Epoch 2998: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3188 - val_loss: 1.0705\n",
      "Epoch 2999/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3196\n",
      "Epoch 2999: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3196 - val_loss: 1.0774\n",
      "Epoch 3000/3000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3210\n",
      "Epoch 3000: val_loss did not improve from 1.06515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3210 - val_loss: 1.0665\n",
      "Restoring model weights from the end of the best epoch: 2998.\n",
      "best epoch =  2958\n",
      "smallest training loss = 0.3187735974788666\n",
      "smallest validation loss = 1.0651452541351318\n"
     ]
    }
   ],
   "source": [
    "#After the compilation of the model, we'll use the fit method with 500 epochs.\n",
    "#I started with epochs value of 100 and then tested the model after training. \n",
    "#The prediction was not that good. Then I modified the number of epochs to 200 and tested the model again. \n",
    "#Accuracy had improved slightly, but figured I'd give it one more try. Finally, at 500 epochs \n",
    "#I found acceptable prediction accuracy.\n",
    "\n",
    "#The fit method takes three parameters; namely, x, y, and number of epochs. \n",
    "#During model training, if all the batches of data are seen by the model once, \n",
    "#we say that one epoch has been completed.\n",
    "\n",
    "# Add an early stopping callback - monitor validation loss\n",
    "es = keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', \n",
    "    mode='min', \n",
    "    patience=100, \n",
    "    restore_best_weights=True, \n",
    "    verbose=1)\n",
    "\n",
    "# Add a checkpoint where validation loss is minimum, and save that model\n",
    "mc = keras.callbacks.ModelCheckpoint(\n",
    "    'best_model_4.2.keras', \n",
    "    monitor='val_loss', \n",
    "    mode='min',  \n",
    "    verbose=1, \n",
    "    save_best_only=True)\n",
    "\n",
    "historyData = model.fit(\n",
    "    xarray, yarray,\n",
    "    validation_data=(xarray_val, yarray_val),\n",
    "    epochs=3000,\n",
    "    callbacks=[es, mc])\n",
    "\n",
    "loss_hist = historyData.history['loss']\n",
    "val_loss_hist = historyData.history['val_loss']\n",
    "#The above line will return a dictionary, access it's info like this:\n",
    "best_epoch = np.argmin(val_loss_hist) + 1\n",
    "print('best epoch = ', best_epoch)\n",
    "print('smallest training loss =', np.min(loss_hist))\n",
    "print('smallest validation loss =', np.min(val_loss_hist))\n",
    "\n",
    "model.save('./best_model_4.2.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "============================================================\n",
      "Training Set Prediction Results\n",
      "============================================================\n",
      "Training MAE - Voltage VL: 14.1989 V\n",
      "Training MAE - Power Wd: 65.1097 W\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Training set predictions\n",
    "\n",
    "train_predictions = model.predict(xarray)\n",
    "\n",
    "# Denormalize predictions\n",
    "train_pred_VL = train_predictions[:, 0] * VLmed\n",
    "train_pred_Wd = train_predictions[:, 1] * Wdmed\n",
    "\n",
    "# Denormalize actual values\n",
    "train_actual_VL = yarray[:, 0] * VLmed\n",
    "train_actual_Wd = yarray[:, 1] * Wdmed\n",
    "\n",
    "# Calculate MAE\n",
    "mae_train_VL = np.mean(np.abs(train_pred_VL - train_actual_VL))\n",
    "mae_train_Wd = np.mean(np.abs(train_pred_Wd - train_actual_Wd))\n",
    "\n",
    "print('============================================================')\n",
    "print('Training Set Prediction Results')\n",
    "print('============================================================')\n",
    "print(f'Training MAE - Voltage VL: {mae_train_VL:.4f} V')\n",
    "print(f'Training MAE - Power Wd: {mae_train_Wd:.4f} W')\n",
    "print('============================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "============================================================\n",
      "Validation Set Prediction Results\n",
      "============================================================\n",
      "Validation MAE - Voltage VL: 36.9721 V\n",
      "Validation MAE - Power Wd: 250.8151 W\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Validation set predictions\n",
    "\n",
    "val_predictions = model.predict(xarray_val)\n",
    "\n",
    "# Denormalize predictions\n",
    "val_pred_VL = val_predictions[:, 0] * VLmed\n",
    "val_pred_Wd = val_predictions[:, 1] * Wdmed\n",
    "\n",
    "# Denormalize actual values\n",
    "val_actual_VL = yarray_val[:, 0] * VLmed\n",
    "val_actual_Wd = yarray_val[:, 1] * Wdmed\n",
    "\n",
    "# Calculate MAE\n",
    "mae_val_VL = np.mean(np.abs(val_pred_VL - val_actual_VL))\n",
    "mae_val_Wd = np.mean(np.abs(val_pred_Wd - val_actual_Wd))\n",
    "\n",
    "print('============================================================')\n",
    "print('Validation Set Prediction Results')\n",
    "print('============================================================')\n",
    "print(f'Validation MAE - Voltage VL: {mae_val_VL:.4f} V')\n",
    "print(f'Validation MAE - Power Wd: {mae_val_Wd:.4f} W')\n",
    "print('============================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved as: task4.2_training_loglog.png\n"
     ]
    }
   ],
   "source": [
    "# (e) Log-log plots of predicted vs actual power output for training set\n",
    "# Create separate plots for each Mode (0, 1, 2)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create 3 subplots for 3 modes\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Mode labels\n",
    "mode_names = ['Mode 0', 'Mode 1', 'Mode 2']\n",
    "\n",
    "for mode_idx in range(3):\n",
    "    ax = axes[mode_idx]\n",
    "    \n",
    "    # Filter data for this mode\n",
    "    mask = xarray[:, 0] == mode_idx\n",
    "    actual = train_actual_Wd[mask]\n",
    "    predicted = train_pred_Wd[mask]\n",
    "    \n",
    "    # Log-log plot\n",
    "    ax.loglog(actual, predicted, 'o', markersize=8, alpha=0.7, label='Predictions')\n",
    "    \n",
    "    # Perfect prediction line (y=x)\n",
    "    if len(actual) > 0:\n",
    "        min_val = min(actual.min(), predicted.min())\n",
    "        max_val = max(actual.max(), predicted.max())\n",
    "        ax.loglog([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect Fit')\n",
    "    \n",
    "    ax.set_xlabel('Actual Power Output (W)', fontsize=11)\n",
    "    ax.set_ylabel('Predicted Power Output (W)', fontsize=11)\n",
    "    ax.set_title(f'Training Set: {mode_names[mode_idx]}', fontsize=12, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3, which='both')\n",
    "    ax.legend(fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('task4.2_training_loglog.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'Figure saved as: task4.2_training_loglog.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Training Set Performance by Mode\n",
      "============================================================\n",
      "Mode 0:\n",
      "  Voltage MAE: 3.8633 V\n",
      "  Power MAE: 19.4646 W\n",
      "  Samples: 12\n",
      "\n",
      "Mode 1:\n",
      "  Voltage MAE: 20.0098 V\n",
      "  Power MAE: 107.1729 W\n",
      "  Samples: 12\n",
      "\n",
      "Mode 2:\n",
      "  Voltage MAE: 20.9858 V\n",
      "  Power MAE: 70.4826 W\n",
      "  Samples: 8\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Additional analysis: Training set performance by Mode\n",
    "\n",
    "# Calculate MAE for each mode\n",
    "modes = [0, 1, 2]\n",
    "print('============================================================')\n",
    "print('Training Set Performance by Mode')\n",
    "print('============================================================')\n",
    "\n",
    "for mode in modes:\n",
    "    mask = xarray[:, 0] == mode\n",
    "    if np.any(mask):\n",
    "        mode_actual_VL = train_actual_VL[mask]\n",
    "        mode_pred_VL = train_pred_VL[mask]\n",
    "        mode_actual_Wd = train_actual_Wd[mask]\n",
    "        mode_pred_Wd = train_pred_Wd[mask]\n",
    "        \n",
    "        mae_VL = np.mean(np.abs(mode_pred_VL - mode_actual_VL))\n",
    "        mae_Wd = np.mean(np.abs(mode_pred_Wd - mode_actual_Wd))\n",
    "        \n",
    "        print(f'Mode {int(mode)}:')\n",
    "        print(f'  Voltage MAE: {mae_VL:.4f} V')\n",
    "        print(f'  Power MAE: {mae_Wd:.4f} W')\n",
    "        print(f'  Samples: {np.sum(mask)}')\n",
    "        print()\n",
    "\n",
    "print('============================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved as: task4.2_validation_loglog.png\n"
     ]
    }
   ],
   "source": [
    "# (f) Log-log plots of predicted vs actual power output for validation set\n",
    "# Create separate plots for each Mode (0, 1, 2)\n",
    "\n",
    "# Create 3 subplots for 3 modes\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Mode labels\n",
    "mode_names = ['Mode 0', 'Mode 1', 'Mode 2']\n",
    "\n",
    "for mode_idx in range(3):\n",
    "    ax = axes[mode_idx]\n",
    "    \n",
    "    # Filter data for this mode\n",
    "    mask = xarray_val[:, 0] == mode_idx\n",
    "    actual = val_actual_Wd[mask]\n",
    "    predicted = val_pred_Wd[mask]\n",
    "    \n",
    "    # Log-log plot\n",
    "    ax.loglog(actual, predicted, 's', markersize=10, alpha=0.7, label='Predictions', color='green')\n",
    "    \n",
    "    # Perfect prediction line (y=x)\n",
    "    if len(actual) > 0:\n",
    "        min_val = min(actual.min(), predicted.min())\n",
    "        max_val = max(actual.max(), predicted.max())\n",
    "        ax.loglog([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect Fit')\n",
    "    \n",
    "    ax.set_xlabel('Actual Power Output (W)', fontsize=11)\n",
    "    ax.set_ylabel('Predicted Power Output (W)', fontsize=11)\n",
    "    ax.set_title(f'Validation Set: {mode_names[mode_idx]}', fontsize=12, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3, which='both')\n",
    "    ax.legend(fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('task4.2_validation_loglog.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'Figure saved as: task4.2_validation_loglog.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Validation Set Performance by Mode\n",
      "============================================================\n",
      "Mode 0:\n",
      "  Voltage MAE: 14.3797 V\n",
      "  Power MAE: 114.5755 W\n",
      "  Samples: 4\n",
      "\n",
      "Mode 1:\n",
      "  Voltage MAE: 45.9497 V\n",
      "  Power MAE: 70.4128 W\n",
      "  Samples: 4\n",
      "\n",
      "Mode 2:\n",
      "  Voltage MAE: 43.7794 V\n",
      "  Power MAE: 409.1360 W\n",
      "  Samples: 8\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Additional analysis: Validation set performance by Mode\n",
    "\n",
    "# Calculate MAE for each mode in validation set\n",
    "print('============================================================')\n",
    "print('Validation Set Performance by Mode')\n",
    "print('============================================================')\n",
    "\n",
    "for mode in modes:\n",
    "    mask = xarray_val[:, 0] == mode\n",
    "    if np.any(mask):\n",
    "        mode_actual_VL = val_actual_VL[mask]\n",
    "        mode_pred_VL = val_pred_VL[mask]\n",
    "        mode_actual_Wd = val_actual_Wd[mask]\n",
    "        mode_pred_Wd = val_pred_Wd[mask]\n",
    "        \n",
    "        mae_VL = np.mean(np.abs(mode_pred_VL - mode_actual_VL))\n",
    "        mae_Wd = np.mean(np.abs(mode_pred_Wd - mode_actual_Wd))\n",
    "        \n",
    "        print(f'Mode {int(mode)}:')\n",
    "        print(f'  Voltage MAE: {mae_VL:.4f} V')\n",
    "        print(f'  Power MAE: {mae_Wd:.4f} W')\n",
    "        print(f'  Samples: {np.sum(mask)}')\n",
    "        print()\n",
    "\n",
    "print('============================================================')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3-11_Keras_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
